---
title: "특이값 분해"
number-sections: true
number-depth : 3
crossref:
  chapters: true
---


## 특이값 분해의 원리

### 특이값

우리는 앞에서 정사각 행렬에 대한 특이값 분해를 알아보았다. 이제 일반적인 행렬에 대한 특이값 분해를 보기로 하자. 여기서는 행렬을 주로 다룰 것이며 지금까지와는 다르게 굵은 글씨체로 하지 않겠다.


::: {.callout-note appearance="simple" icon="false"}
::: {#def-singular_value_of_matrix}

#### 특이값
$A\in \mathcal{M}_{m \times n}(\mathbb{F})$ 에 대해 $\sqrt{A^\ast A}$ 의 고유값을 **특이값(singular value)** 라 한다. $\sqrt{A^\ast A}$ 가 positive 이므로 당연히 모든 특이값은 $0$ 이 아닌 실수이다.
:::
:::

::: {#prp-properties_of_AAast}

$A\in \mathcal{M}_{m \times n}(\mathbb{F})$ 에 대해 다음이 성립한다.

&emsp; ($1$) $A^\ast A$ 는 positive 행렬이다.

&emsp; ($2$) $\ker (A^\ast A) = \ker (A)$.

&emsp; ($3$) $\text{im}(A^\ast A) = \text{im}(A^\ast)$.

&emsp; ($4$) $\text{rank}(A) = \text{rank}(A^\ast) = \text{rank}(A^\ast A)$
 
:::

::: {.proof}

($1$) $(A^\ast A)^\ast = A^\ast A$ 이므로 $A^\ast A$ 는 에르미트 행렬이다. 또한 $\langle A^\ast Au,\, v\rangle = \|Au\|^2\ge 0$ 이므로 $A^\ast A$ 는 positive 이다.

($2$) $u\in \ker(A^\ast A) \implies \langle A^\ast Au,\, v\rangle = \|Au\|^2=0$ 이므로 $u\in \ker (A)$. 역으로 $u\in \ker A$ 이면 $Au=0$ 이므로 $A^\ast A=0$ 이며, 따라서 $u\in \ker (A^\ast A)$. 따라서 $\ker (A^\ast A) = \ker (A)$.

($3$) @thm-kernel_image_of_adjoint_operator 과 ($2$) 로부터 $\text{im}(A^\ast A) = (\ker(A^\ast A))^\perp = (\ker (A))^\perp = \text{im}(A^\ast)$ 임을 안다. 

($4$) @exr-axler_7_A_5 로부터 $\text{rank}(A) = \text{rank}(A^\ast)$. ($3$) 으로부터 $\text{rank}(A^\ast) = \text{rank}(A^\ast A)$. $\square$

:::

</br>

::: {#prp-properties_of_singular_value}

$A\in \mathcal{M}_{m \times n}(\mathbb{F})$ 일 때 다음이 성립한다.

&emsp; ($1$) $A$ 가 단사일 필요충분조건은 $0$ 이 $A$ 의 특이값이 아닌 것이다.

&emsp; ($2$) $A$ 의 0 이 아닌 특이값의 갯수는 반복되는 것도 갯수를 합치면 $\text{rank}(A)$ 와 같다. 

&emsp; ($3$) $A$ 가 전사일 필요충분조건은 $A$ 의 특이값의 갯수가 $n$ 인 것이다. 

:::

::: {.proof}

($1$) $A$ 가 단사 $\iff \ker (A) = \{0\} \iff \ker(A^\ast A)= \{0\}$ 

($2$) $A$ 가 에르미트 이므로 $\dim (A)$ 는 $A$ 의 $0$ 이 아닌 고유값의 갯수(반복되는 것도 포함하여)와 같다. @prp-properties_of_AAast 의 ($4$) 에 따라 $A$ 의 특이값의 갯수는 $\text{rank}(A)$ 와 같다.

($3$) ($2$) 에 의헤 당연하다. $\square$

:::


</br>

::: {#prp-linear_isometry_and_singular_values}


정사각 행렬 $\boldsymbol{S}$ 에 대해 다음은 동치이다.

&emsp; ($1$) $\boldsymbol{S}$ 는 linear isometry 이다.

&emsp; ($2$) $\boldsymbol{S}$ 의 특이값이 $1$ 뿐이다.

:::

::: {.proof}

($1 \implies 2$) $\boldsymbol{S}$ 가 linear isometry 이면 $\boldsymbol{S}^\ast\boldsymbol{S}=\boldsymbol{I}$ 이며 따라서 $\boldsymbol{S}$ 의 특이값은 $1$ 뿐이다.

($2\implies 1$) $\boldsymbol{S}$ 의 특이값이 $1$ 뿐이면 $\boldsymbol{S}^\ast\boldsymbol{S}$ 의 고유값이 $1$ 뿐이므로 $\boldsymbol{S}^\ast\boldsymbol{S} = \boldsymbol{I}$ 이다. 따라서 $\boldsymbol{S}$ 는 linear isometry 이다. $\square$

:::


</br>

### 특이값 분해

::: {#thm-svd_1}

#### 1차 특이값 분해

$\boldsymbol{A}\in \mathcal{M}_{m \times n}(\mathbb{F})$ 가 $M=\text{rank} (\boldsymbol{A}) \ge 1$ 이라고 하자. 이 때 서로 직교하는 열벡터로 구성된 $\boldsymbol{B}\in \mathcal{M}_{m \times M}(\mathbb{F})$ 과 대각행렬 $\boldsymbol{D}\in \mathcal{M}_{M \times M}(\mathbb{F})$ 그리고 역시 서로 직교하는 열벡터로 구성된 $\boldsymbol{C}=\mathcal{M}_{n \times M}(\mathbb{F})$ 에 대해 

$$
\boldsymbol{A} = \boldsymbol{BDC}^\ast
$$

이다.
:::


::: {.proof}

$\boldsymbol{A}$ 의 특이값의 갯수는 $n$ 개이다. 이 가운데 $0$ 이 아닌 것은 @prp-properties_of_singular_value 의 ($2$) 에 따라 $M$ 개이며 이를 $s_1,\ldots,\,s_M$ 이라 하자. 그리고 편의상 $s_{M+1} = \cdots = s_m = 0$ 이라고 하면 $\boldsymbol{A}$ 의 특이값에 대한 수열이 된다. $\boldsymbol{A}^\ast\boldsymbol{A}$ 의 고유값 ${s_i}^2$ 에 대한 정규화된 고유벡터를 $\boldsymbol{e}_i$ 라고 하자. 그리고,

$$
\boldsymbol{f}_j = \dfrac{\boldsymbol{Ae}_j}{s_j},\qquad j=1,\ldots,\,M
$$

이라고 하자. 그렇다면, 

$$
\langle \boldsymbol{f}_j,\, \boldsymbol{f}_i\rangle = \dfrac{1}{s_is_j}\langle \boldsymbol{Ae}_j, \boldsymbol{Ae}_i\rangle = \dfrac{1}{s_is_j}\langle \boldsymbol{A}^\ast\boldsymbol{Ae}_j, \boldsymbol{e}_i\rangle = \dfrac{s_j}{s_i}\langle \boldsymbol{e}_j,\, \boldsymbol{e}_i \rangle = \delta_{ij}
$$

이다. 즉 $\{\boldsymbol{f}_j : j=1,\ldots,\,M\}$ 은 정규직교벡터의 집합이다. $\{\boldsymbol{e}_i\}$ 는 $\mathcal{M}_n(\mathbb{F})$ 의 정규직교기저이므로 $\boldsymbol{v}\in \mathcal{M}_n(\mathbb{F})$ 는

$$
\boldsymbol{v} = \sum_{i=1}^n \langle \boldsymbol{v},\, \boldsymbol{e}_i \rangle \boldsymbol{e}_i
$$

이다. 그렇다면, 

$$
\boldsymbol{Av} =  \sum_{i=1}^n \langle \boldsymbol{v},\, \boldsymbol{e}_i \rangle \boldsymbol{Ae}_i = \sum_{i=1}^M s_i \langle \boldsymbol{v},\, \boldsymbol{e}_i \rangle \boldsymbol{f}_i
$$

이다. 이제 $\boldsymbol{B} = \begin{bmatrix} \boldsymbol{f}_1 & \cdots & \boldsymbol{f}_M\end{bmatrix}$ 라 하고 $\boldsymbol{D}$ 는 $D_{ij}= s_j\delta_{ij}$ 가 되도록 하며 $\boldsymbol{C} = \begin{bmatrix} \boldsymbol{e}_1 & \cdots \boldsymbol{e}_M \end{bmatrix}$ 라고 하자. 

$$
\boldsymbol{BDC}^\ast\boldsymbol{v}= \boldsymbol{BD}\begin{bmatrix} \langle \boldsymbol{v},\,\boldsymbol{e}_1\rangle \\ \vdots \\ \langle \boldsymbol{v},\, \boldsymbol{e}_M\rangle \end{bmatrix} = \boldsymbol{B}\begin{bmatrix} s_1\langle \boldsymbol{v},\,\boldsymbol{e}_1\rangle \\ \vdots \\ s_M\langle \boldsymbol{v},\, \boldsymbol{e}_M\rangle \end{bmatrix} = \sum_{i=1}^M s_i \langle \boldsymbol{v},\, \boldsymbol{e}_i \rangle \boldsymbol{f}_i = \boldsymbol{Av}
$$


이다. 임의의 벡터 $\boldsymbol{v}$ 에 대해 성립하므로 $\boldsymbol{A} = \boldsymbol{BDC}^\ast$ 이다. $\square$
:::

</br>

@thm-svd_1 은 실제 계산에서 잘 사용하지 않으며, 약간 변형된 형태로 많이 사용한다.

</br>


::: {#thm-svd_2}

#### 2차 특이값 분해

$\boldsymbol{A}\in \mathcal{M}_{m \times n}(\mathbb{F})$ 가 $\text{rank} (\boldsymbol{A}) \ge 1$ 이라고 하자. 이 때 서로 직교하는 열벡터로 구성된 $\boldsymbol{U}\in \mathcal{M}_{m \times m}(\mathbb{F})$ 과 대각성분이 1이며 나머지 성분은 0 인 직사각행렬 $\boldsymbol{\Sigma}\in \mathcal{M}_{M \times n}(\mathbb{F})$ 그리고 역시 서로 직교하는 열벡터로 구성된 $\boldsymbol{V}=\mathcal{M}_{n \times n}(\mathbb{F})$ 에 대해 

$$
\boldsymbol{A} = \boldsymbol{U\Sigma V}^\ast
$$

이다.

:::

::: {.proof}

@thm-svd_1 의 $\boldsymbol{B} = \begin{bmatrix} \boldsymbol{f}_1 & \cdots & \boldsymbol{f}_M\end{bmatrix}$ 에서 $\{\boldsymbol{f}_i\}$ 는 직교벡터의 집합이므로 여기에 벡터 $\boldsymbol{f}_{M+1},\ldots,\,\boldsymbol{f}_m$ 을 추가하여 $\{\boldsymbol{f}_1,\ldots,\,\boldsymbol{f}_n\}$ 이 $\mathcal{M}_{m}(\mathbb{F})$ 의 정규직교기저가 되도록 할 수 있다. 이 때 $\boldsymbol{U} = \begin{bmatrix} \boldsymbol{f}_1 & \cdots & \boldsymbol{f}_m\end{bmatrix}$ 이라 하자.

역시 @thm-svd_1 의 증명과정에서 사용한 $\boldsymbol{A}^\ast\boldsymbol{A}$ 의 정규기저벡터 $\{\boldsymbol{e}_j\}$ 에 대해 $\boldsymbol{V}= \begin{bmatrix} \boldsymbol{e}_1 & \cdots \boldsymbol{e}_n\end{bmatrix}$ 라고 하자. 

@thm-svd_1 에서 $\boldsymbol{D}$ 는 $M \times M$ 행렬이며 $M \le \text{min}(m, n)$ 이다. $m \times n$ 행렬 $\boldsymbol{\Sigma}$ 의 1행 1열부터 $M$ 행 $M$ 열 까지를 $\boldsymbol{D}$ 와 같은 값을 갖게 하고 나머지는 $0$ 으로 하자. 그렇다면, 

$$
\begin{aligned}
\boldsymbol{U\Sigma Vv} = 
\boldsymbol{U\Sigma}\begin{bmatrix} \langle \boldsymbol{v},\,\boldsymbol{e}_1\rangle \\ \vdots \\ \langle \boldsymbol{v},\, \boldsymbol{e}_M\rangle \\ \langle \boldsymbol{v},\, \boldsymbol{e}_{M+1}\rangle \\ \vdots \\ \langle \boldsymbol{v},\,\boldsymbol{e}_n \rangle \end{bmatrix} = 
\boldsymbol{U} \begin{bmatrix} s_1\langle \boldsymbol{v},\,\boldsymbol{e}_1\rangle \\ \vdots \\ s_M\langle \boldsymbol{v},\, \boldsymbol{e}_M\rangle \\ 0 \cdot \langle \boldsymbol{v},\, \boldsymbol{e}_{M+1}\rangle \\ \vdots \\ 0 \cdot  \langle \boldsymbol{v},\,\boldsymbol{e}_n \rangle \end{bmatrix} = \sum_{i=1}^M s_i \langle \boldsymbol{v},\, \boldsymbol{e}_i \rangle \boldsymbol{f}_i = \boldsymbol{Av}
\end{aligned}
$$

이다. 즉 $\boldsymbol{A} = \boldsymbol {U\Sigma V}$ 이다. 

:::


많은 경우 @thm-svd_2 의 형태로 특이값 분해를 사용한다.

</br>

## 특이값 분해의 활용

### 행렬의 노름

::: {#prp-norm_of_matrix}

$\boldsymbol{A}\in \mathcal{M}_{m \times n}(\mathbb{F})$ 의 가장 큰 특이값을 $s_M$ 이라고 하면 다음이 성립한다.

$$
\forall \boldsymbol{v}\in \mathcal{M}_n(\mathbb{F}),\qquad \|\boldsymbol{Av}\| \le s_M \|\boldsymbol{v}\|.
$$
:::


::: {.proof}

@thm-svd_2 의 증명과정에서 $\boldsymbol{Av} = \sum_i s_i \langle \boldsymbol{v},\, \boldsymbol{e}_i \rangle \boldsymbol{f}_i$ 임을 알았다. 이를 이용하면

$$
\begin{aligned}
\|\boldsymbol{Av}\|^2 &= \left\| \sum_{i=1}^M s_i \langle \boldsymbol{v},\, \boldsymbol{e}_i \rangle \boldsymbol{f}_i \right\|^2  \le \sum_{i=1}^M  |s_i \langle \boldsymbol{v},\, \boldsymbol{e}_i\rangle|^2 \le {s_M}^2 \sum_{i=1}^M |\langle \boldsymbol{v},\, \boldsymbol{e}_i\rangle|^2 \le {s_M}^2 \|\boldsymbol{v}\|^2
\end{aligned}
$$

이다. 마지막 부등호는 베셀 부등식(@prp-properties_of_orthonormal_vectors ($3$)) 으로부터 성립한다. 따라서 $\|\boldsymbol{Av}\| \le s_M \|\boldsymbol{v}\|$ 이다. $\square$
:::


</br>

@prp-norm_of_matrix 의 최대 특이값 $s_M$ 을 갖는 벡터는 ${s_M}^2$ 의 고유값에 대한 $\boldsymbol{A}^\ast\boldsymbol{A}$ 의 고유벡터이므로 항상 존재한다. $\boldsymbol{v}\ne \boldsymbol{0}$ 에 대해 

$$
\dfrac{\|\boldsymbol{Av}\|}{\|\boldsymbol{v}\|} \le s_M
$$

이므로 $s_M$ 은 선형사상에 의해 증가하는 벡터의 크기의 비율의 상한을 정의한다. 만약 $\|\boldsymbol{v}\|=1$ 이라면 $\|\boldsymbol{Av}\| \le s_M$ 이다. 이제 행렬의 노름을 정의하자. 앞서 설명했던과 같이 동등한 값이 여러개 있지만 그중 다루기 편한 것으로 정의하고 이후 동등한 명제에 대해 설명하기로 한다.₩

</br>


::: {.callout-note appearance="minimal" icon="false"}
::: {#def-norm_of_matrix}

#### 행렬의 노름

$\boldsymbol{A}\in \mathcal{M}_{m \times n}(\mathbb{F})$ 의 노름 $\|\boldsymbol{A}\|$ 는 다음과 같이 정의된다.

$$
\|\boldsymbol{A}\| := \max \{ \|\boldsymbol{Av}\| : \|\boldsymbol{v}\|=1\} 
$$


:::
:::




</br>

::: {#prp-properties_of_matrix_norm}

행렬의 노름 $\|\cdot \|$ 에 대해 다음이 성립한다.

&emsp; ($1$) $\|\boldsymbol{A}\|\ge 0$. 

&emsp; ($2$) $\|\boldsymbol{A}\|=0 \iff \boldsymbol{A} =\boldsymbol{0}$.

&emsp; ($3$) $c\in \mathbb{F}$ 에 대해 $\|c\boldsymbol{A}\| = |c|\|\boldsymbol{A}\|$.

&emsp; ($4$) $\|\boldsymbol{A} +\boldsymbol{B}\| \le \|\boldsymbol{A} \|+\|\boldsymbol{B}\|$. 

&emsp; ($5$) $\|\boldsymbol{A^\ast}\| = \| \boldsymbol{A}\|$. 

:::


::: {.proof}

($1$) 노름의 정의에 의해 자명하다.

($2$) $\boldsymbol{A}=0$ 이면 당연히 $\|\boldsymbol{A}\|=0$ 이다. $\|\boldsymbol{A}\|=0$ 이면 모든 $\boldsymbol{v}$ 에 대해 $\boldsymbol{Av}=\boldsymbol{0}$ 이어야 하므로 $\boldsymbol{A}=\boldsymbol{0}$ 이다.

($3$) $\|c\boldsymbol{Av}\| = |c|\|\boldsymbol{Av}\|$. 

($4$) $\|(\boldsymbol{A}+\boldsymbol{B})\boldsymbol{v}\| = \|\boldsymbol{Av}+\boldsymbol{Bv}\|  \le \|\boldsymbol{Av}\| +\|\boldsymbol{Bv}\|$.
:::

</br>

::: {#prp-anothor_definitions_of_matrix_norm}

행렬 $\boldsymbol{A}$ 에 대해 다음 네 값은 같다.

&emsp; ($1$) $\max \{ \|\boldsymbol{Av}\| : \|\boldsymbol{v}\|=1 \}$

&emsp; ($2$) $\max \{ \|\boldsymbol{Av}\| : \|\boldsymbol{v}\|\le 1 \}$

&emsp; ($3$) $\boldsymbol{A}$ 의 최대 특성값.

&emsp; ($4$) $\max \left\{ \dfrac{\|\boldsymbol{Av}\|}{\|\boldsymbol{v}\|} : \boldsymbol{v} \ne \boldsymbol{0}\right\}$. 

:::

::: {.proof}

($3$) 과 ($4$) 가 같다는 것은 앞에서 설명했다. ($2$) 에서 $\|\boldsymbol{Av}\|$ 를 최대로 하는 값이 $|\boldsymbol{v}\|<1$ 이면 $\boldsymbol{u}=\dfrac{\boldsymbol{v}}{\|\boldsymbol{v}\|}$ 에 대해 $\|\boldsymbol{u}\|=1$ 이며 $|\boldsymbol{Au}\| > \|\boldsymbol{Av}|$ 이므로 모순된다. 따라서 ($2$) $\|\boldsymbol{Av}\|$ 를 최대로 하는 $\|\boldsymbol{v}\|$ 는 $\|\boldsymbol{v}\|=1$ 일 때이다. 따라서 ($1$) 의 값과 ($2$) 의 값은 같다.

($4$) 의 값에 대해 $\dfrac{\|\boldsymbol{Av}\|}{\|\boldsymbol{v}\|} = \left\|\boldsymbol{A} \left(\dfrac{\boldsymbol{v}}{\|\boldsymbol{v}\|}\right) \right\|$ 이므로 ($1$) 의 값과 같다. 따라서 위의 네 값은 같다.

:::

</br>

@prp-anothor_definitions_of_matrix_norm 에 의헤 행렬의 노름에 대해 4가지 동등한 정의가 존재한다.

</br>


### Approximation by Linear Maps with Lower-Dimensional Range

::: {.callout-caution icon="false"}

#### 특이값 열거 순서

특이값은 0이 아닌 실수이므로 순서대로 열거 할 수 있다. 보통 가장 큰 값부터 중복을 허용하여 열거한다. 특이값을 $s_1,\,s_2,\ldots$ 로 표현하면 가장 큰 값이 $s_1$ 이 된다. 

:::


$L\in \mathcal{L}(U,\,V)$ 의 양의 특이값을 $s_1 \ge s_2 \ge \ldots,\ge s_m>0$ 이라고 하자. 이것을 $k<m$ 의 $\text{rank}$ 를 갖는 어떤 선형사상으로 근사(approximation) 하고자 하며, 가장 좋은 근사인 선형사상을 $L_k$ 라고 하자. 이 때 특이값 분해를 사용 할 수 있다.

</br>

::: {#prp-approximation_using_svd}

$\boldsymbol{A} \in \mathcal{M}_{m \times n}(\mathbb{F})$ 가 양의 특이값 $s_1 \ge s_2 \ge \ldots \ge s_m>0$ 을 갖는다고 하자. $k \le m$ 에 대해 다음이 성립한다.

$$
\min \{ \|\boldsymbol{A}-\boldsymbol{B} \| : \boldsymbol{B}\in \mathcal{M}_{m \times n}(\mathbb{F}),\, \text{rank}(\boldsymbol{B})\le k\} = s_{k+1}.
$$

또한 $\|\boldsymbol{A}-\boldsymbol{B}\| = s_{k+1}$ 을 만족하는 그 $\text{rank}$ 가 $k$ 보다 작은 행렬이 존재한다.

:::

::: {.proof}

@thm-svd_2 를 생각하자. $\boldsymbol{v}\in \mathcal{M}_n(\mathbb{F})$ 에 대해 $\boldsymbol{A}=\boldsymbol{U\Sigma V}^\ast$ 이다. 이 때 $\boldsymbol{V}_k = \begin{bmatrix} \boldsymbol{e}_1 & \cdots & \boldsymbol{e}_k & 0 & \cdots & 0\end{bmatrix}$ 라고 하고 $\boldsymbol{A}_k = \boldsymbol{U\Sigma V}_k^\ast$ 라고 하자. 

$$
(\boldsymbol{A}-\boldsymbol{A}_k)\boldsymbol{v} = \boldsymbol{U\Sigma} \begin{bmatrix}  \boldsymbol{0} \\ \langle \boldsymbol{v},\, \boldsymbol{e}_{k+1} \rangle \\ \vdots \\ \langle \boldsymbol{v},\,\boldsymbol{e}_{m} \rangle \\ \boldsymbol{0}\end{bmatrix} =  \sum_{i=k+1}^m s_{i} \langle \boldsymbol{v},\, \boldsymbol{e}_i\rangle \boldsymbol{f}_i
$$


이며, 따라서 $\|(\boldsymbol{A}-\boldsymbol{A}_k)\boldsymbol{v}\|^2 \le {s_{k+1}}^2 \|\boldsymbol{v}\|^2$ 이며 이로부터 

$$
\|\boldsymbol{A}-\boldsymbol{A}_k\| \le s_{k+1}
$$ {#eq-svd_1}

을 얻는다.

이제 임의의 $\boldsymbol{B}\in \mathcal{M}_{m \times n}(\mathbb{F})$, $\text{rank}(\boldsymbol{B})\le k$ 를 생각하자. $\{\boldsymbol{Be}_1,\ldots,\,\boldsymbol{Be}_{k+1}\}$ 벡터의 갯수가 $\text{rank}(\boldsymbol{B})$ 보다 크기 때문에 선형종속이며, 따라서, 

$$
a_1 \boldsymbol{Be}_1 + \cdots + a_{k+1}\boldsymbol{Be}_{k+1} = \boldsymbol{0}
$$

을 만족하는, nontrivial 한 $a_1,\ldots,\,a_{k+1}$ 이 존재한다. 이제 $a_1,\ldots,\,a_{k+1}$ 을 이용하여 다음의 계산을 수행한다. 

$$
\begin{aligned}
(\boldsymbol{A}-\boldsymbol{B})\left(\sum_{j=1}^{k+1}a_j \boldsymbol{e}_j\right) = \boldsymbol{A}\left(\sum_{j=1}^{k+1}a_j \boldsymbol{e}_j\right) = \sum_{j=1}^{k+1} a_j s_j \boldsymbol{f}_j 
\end{aligned}
$$

이로부터 
$$
\begin{aligned}
\left\|(\boldsymbol{A}-\boldsymbol{B})\left(\sum_{j=1}^{k+1}a_j \boldsymbol{e}_j\right)\right\|^2 &= \sum_{j=1}^{k+1} {s_j}^2 |a_j|^2 \\
&\ge {s_{k+1}}^2(|a_1|^2 + \cdots + |a_{k+1}|^2) \\
&= {s_{k+1}}^2 \| a_1\boldsymbol{e}_1 + \cdots + a_{k+1}\boldsymbol{e}_{k+1}\|^2
\end{aligned}
$$

이다. $a_1\boldsymbol{e}_1+\cdots +a_{k+1}\boldsymbol{e}_{k+1} \ne \boldsymbol{0}$ 이므로, 

$$
\|\boldsymbol{A} -\boldsymbol{B}\| \ge s_{k+1}
$$ {#eq-svd_2}

을 얻는다. @eq-svd_1 의 $\boldsymbol{A}_k$ 는 $\text{rank}(\boldsymbol{A}_k) \le k$ 이므로 @eq-svd_2 를 만족해야 한다. 따라서 

$$
\|\boldsymbol{A}-\boldsymbol{A}_k\| = s_{k+1}
$$

이다. 

:::


