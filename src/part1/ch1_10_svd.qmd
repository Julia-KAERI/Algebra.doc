---
title: "특이값 분해"
number-sections: true
number-depth : 3
crossref:
  chapters: true
---

## Positive, Positive definite 행렬과 제곱근 행렬

::: {.callout-note appearance="simple" icon="false"}
::: {#def-pisitive_definite_matrix}

#### Positive Definite 행렬 와 제곱근 행렬

에르미트 행렬 $\boldsymbol{A}$ 이 임의의 벡터 $\boldsymbol{v}$ 에 대해,$\langle \boldsymbol{Av},\, \boldsymbol{v} \rangle > 0$ 일 때 $\boldsymbol{A}$ 를 **positve** 혹은 **positive definite** 라 하고 $\langle \boldsymbol{Av},\, \boldsymbol{v} \rangle \ge 0$ 일 때 $\boldsymbol{A}$ 를 **non-negative** 혹은 **positive semidefinite** 라 한다. $\boldsymbol{A}$ 가 positive 이거나 positive definite 일 때  $\boldsymbol{A}=\boldsymbol{R}^2$ 인 행렬 $\boldsymbol{R}$ 이 존재하면 $\boldsymbol{R}$ 을 $\boldsymbol{A}$ 의 **제곱근 행렬**이고 하고 $\sqrt{\boldsymbol{A}}$ 라고 쓴다. 행렬 $\boldsymbol{A}$ 의 제곱근 행렬이 존재 할 때 $\boldsymbol{A}$ 가 제곱근 행렬을 가진다라고 한다.

:::
:::


</br>

::: {.callout-warning icon="false"}

#### 용어의 혼란을 막기 위해

예를 들어 S. Axler 의 *Linear Algebra Done Right* 의 경우 $\langle \boldsymbol{Av},\,\boldsymbol{v}\rangle \ge 0$ 일 때 $\boldsymbol{A}$ 를 *positive* 라고 정의한다(3rd Ed. pp 225). 그러나 K. Hoffman, R. Kunze 의 *Linear Algebra* 의 경우에는  $\langle \boldsymbol{Av},\,\boldsymbol{v}\rangle > 0$ 일 때 positive 라고 정의한다(2nd Ed. pp 329). 여기서는 더 직관적인 non-negative, positive 라는 용어를 사용하기로 한다.

:::


</br>

### Non-negative 행렬의 성질

<div class="border" style="background-color:#FFF0F5 ;padding:5px;">

::: {#prp-properties_of_posivive_definite_matrix}

$\boldsymbol{A} \in \mathcal{M}_{n \times n}(\mathbb{C})$ 에 대해 다음은 동치이다.

&emsp; ($1$) $\boldsymbol{A}$ 는 non-negative 이다.

&emsp; ($2$) $\boldsymbol{A}$ 는 에르미트행렬이며 모든 고유값은 non-negative 하다

&emsp; ($3$) $\boldsymbol{A}$ 는 대각성분이 모두 음수가 아닌 대각행렬과 닮았다.

&emsp; ($4$) $\boldsymbol{A}$ 의 non-negative positive 제곱근 행렬이 존재한다.

&emsp; ($5$) $\boldsymbol{A}$ 의 에르미트 제곱근 행렬이 존재한다.

&emsp; ($6$) $\boldsymbol{A} = \boldsymbol{R}^\ast \boldsymbol{R}$ 인 행렬 $\boldsymbol{R}$ 이 존재한다.

::: 

</div></br>

::: {.proof}
($1 \implies 2$) $\boldsymbol{A}$ 가 non-negative 이므로 정의에 의해 에르미트 행렬이다. $\lambda$ 가 $\boldsymbol{A}$ 의 고유값이고 $\boldsymbol{v}$ 가 $\lambda$ 에 대한 고유벡터 일 때, $0 \le \langle \boldsymbol{Av},\, \boldsymbol{v}\rangle = \lambda \|\boldsymbol{v}\|^2$ 이므로 $\lambda \ge 0$ 이다.

($2 \implies 3$) $\boldsymbol{A}$ 가 에르미트 행렬이므로 스펙트럼 정리에 의해 $\boldsymbol{U}^\ast\boldsymbol{AU}$ 를 대각행렬 $\boldsymbol{D}$ 로 하는 유니타리 행렬 $\boldsymbol{U}$ 가 존재한다. 대각성분이 고유값이므로 $\boldsymbol{D}$ 의 모든 대각성분은 실수이며 음수가 아니다.

($3 \implies 4$) $\boldsymbol{A}$ 의 고유값 $\lambda_1,\ldots,\,\lambda_n$ 에 대해 $D_{ij} = \lambda_{i}\delta_{ij}$ 일 때, 행렬 $\boldsymbol{S}$ 를 대각행렬 $S_{ij} = \sqrt{D_{ij}}$ 로 정의하자. $\boldsymbol{R} = \boldsymbol{U}^\ast\boldsymbol{SU}$ 라 하면 $\boldsymbol{R}^2 = \boldsymbol{A}$ 이다.

($4 \implies 5$) 위에서 정의한 $\boldsymbol{R}$ 은 $\boldsymbol{R}^\ast = \boldsymbol{U}^\ast \boldsymbol{SU} = \boldsymbol{R}$ 이므로 에르미트 행렬이다.

($5 \implies 6$) 앞서 정의한 $\boldsymbol{R}$ 이다.

($6 \implies 1$) $\boldsymbol{A}=\boldsymbol{R}^\ast \boldsymbol{R}$ 이면 $\boldsymbol{A}^\ast = (\boldsymbol{R}^\ast\boldsymbol{R})^\ast = \boldsymbol{R}^\ast \boldsymbol{R}=\boldsymbol{A}$ 이므로 $\boldsymbol{A}$ 는 에르미트 행렬이다. 또한 임의의 $\boldsymbol{v}\in \mathcal{M}_{n }(\mathbb{C})$ 에 대해 $\langle \boldsymbol{v},\, \boldsymbol{A}\boldsymbol{v}\rangle = \langle \boldsymbol{R}^\ast \boldsymbol{R}\boldsymbol{v},\, \boldsymbol{v} \rangle = \|\boldsymbol{Rv}\|^2\ge 0$ 이므로 $\boldsymbol{A}$ 는 non-negative 이다. $\square$

:::

</br><div class="border" style="background-color:#FFF0F5 ;padding:5px;">

::: {#prp-uniqueness_of_squareroot_matrix}

non-negative 행렬 $\boldsymbol{A}$ 의 non-nagative 한 제곱근 행렬은 유일하다.

:::

</div></br>

:::{.proof}
우리는 앞서 non-negative 행렬 $\boldsymbol{A}$ 에 대한 non-negative 한 제곱근 행렬이 존재함을 보였다. 여기서는 이것이 유일함을 보인다. 행렬 $\boldsymbol{A}$ 에 대한 non-negative 한 제곱근 행렬을 $\boldsymbol{R}$ 이라 하자. 스펙트럼 정리에 의해 $\boldsymbol{R}$ 에 대한 고유값 $\eta_1,\ldots,\,\eta_n$ 과 그에 대한 정규 고유 벡터 $\boldsymbol{u}_1,\ldots,\,\boldsymbol{u}_n$ 이 존재한다. 이 때 $\eta_i \ge 0$ 이다. 임의의 벡터 $\boldsymbol{v} = \sum_i a_i \boldsymbol{u}_i$ 에 대해,

$$
\begin{aligned}
\boldsymbol{R}\boldsymbol{v} &= \sum_i a_i \eta _i \boldsymbol{u}_i \\
\boldsymbol{R}^2\boldsymbol{v}&= \sum_i a_i \eta_i^2 \boldsymbol{u}_i
\end{aligned}
$$

이다. $\boldsymbol{R}^2 = \boldsymbol{A}$ 이므로, $\boldsymbol{v}$ 가 고유값 $\lambda$ 를 갖는 $\boldsymbol{A}$ 의 고유벡터라면

$$
\boldsymbol{A}\boldsymbol{v} = \sum_i a_i \lambda \boldsymbol{u}_i
$$

이며, 따라서 $i=1,\ldots,\,n$ 에 대해 $\eta_i = \sqrt{\lambda}$ 이어야 한다. 즉 $\boldsymbol{A}$ 의 고유벡터는 $\boldsymbol{R}$ 의 고유벡터이어야 하며, 따라서 유일하다. $\square$

:::

</br>

::: {.callout-note appearance="minimal" icon="false"}
::: {#def-square_root_matrix}

#### $\sqrt{\boldsymbol{A}}$

$\boldsymbol{A}$ 가 non-negative 행렬일 때 $\boldsymbol{A}$ 의 non-negative 한 제곱근 행렬을 $\sqrt{\boldsymbol{A}}$ 라고 쓴다.

:::
:::

</br><div class="border" style="background-color:#FFF0F5 ;padding:5px;">

::: {#prp-squareroot_matrix}

임의의 $\boldsymbol{B}\in \mathcal{M}_{m \times n}(\mathbb{F})$ 에 대해 $\boldsymbol{B}^\ast \boldsymbol{B}$ 를 생각 할 수 있다. 이 때 $\boldsymbol{B}^\ast \in \mathcal{M}_{n \times m}(\mathbb{F})$ 이다. $\boldsymbol{B}^\ast \boldsymbol{B}$ 는

&emsp; ($1$) 에르미트이다.

&emsp; ($2$) non-negative 이다.

&emsp; ($3$) $\sqrt{\boldsymbol{B}^\ast \boldsymbol{B}}$ 를 생각 할 수 있다.

:::

</div></br>

::: {.proof}

($1$) $(\boldsymbol{B}^\ast\boldsymbol{B})^\ast = \boldsymbol{B}^\ast\boldsymbol{B}$ 이다.

($2$) $\langle \boldsymbol{B}^\ast\boldsymbol{Bv},\,\boldsymbol{v}\rangle = \|\boldsymbol{Bv}\|^2 \ge 0$.

($3$) @prp-properties_of_posivive_definite_matrix $\square$
:::

</br>


### 연습문제 {.unnumbered}

<div class="border" style="background-color:#F0FFFF  ;padding:5px;">
::: {#exr-axler_5_A_2}

#### Axler 5.A.2

$\boldsymbol{A},\,\boldsymbol{B}\in \mathcal{M}_{n \times n}(\mathbb{F})$ 이고 $\boldsymbol{AB}=\boldsymbol{BA}$ 이면 $\ker \boldsymbol{B}$ 는 $\boldsymbol{A}$ 의 불변부분공간이다.
:::

</div></br>

::: {.solution}

$\boldsymbol{u}\in \ker \boldsymbol{B}$ 라 하자. $\boldsymbol{BAu} =\boldsymbol{ABu} = \boldsymbol{0}$ 이므로 $\boldsymbol{Au}\in \ker \boldsymbol{B}$ 이다.  

:::

</br>

## 특이값 분해의 원리

### 특이값

우리는 앞에서 정사각 행렬에 대한 특이값 분해를 알아보았다. 이제 일반적인 행렬에 대한 특이값 분해를 보기로 하자. 여기서는 행렬을 주로 다룰 것이며 지금까지와는 다르게 굵은 글씨체로 하지 않겠다.


::: {.callout-note appearance="simple" icon="false"}
::: {#def-singular_value_of_matrix}

#### 특이값
$A\in \mathcal{M}_{m \times n}(\mathbb{F})$ 에 대해 $\sqrt{A^\ast A}$ 의 고유값을 **특이값(singular value)** 라 한다. $\sqrt{A^\ast A}$ 가 positive 이므로 당연히 모든 특이값은 $0$ 이 아닌 실수이다. 특이값을 열거할때는 보통 가장 큰 값부터 내림차순으로 열거한다. 따라서 특이값 $s_1,\ldots,\,s_n$ 이라고 하면 $s_1 \ge s_2 \ge \cdots \ge s_n$ 을 의미한다.

:::
:::

</br><div class="border" style="background-color:#FFF0F5 ;padding:5px;">

::: {#prp-properties_of_AAast}

$A\in \mathcal{M}_{m \times n}(\mathbb{F})$ 에 대해 다음이 성립한다.

&emsp; ($1$) $A^\ast A$ 는 positive 행렬이다.

&emsp; ($2$) $\ker (A^\ast A) = \ker (A)$.

&emsp; ($3$) $\text{im}(A^\ast A) = \text{im}(A^\ast)$.

&emsp; ($4$) $\text{rank}(A) = \text{rank}(A^\ast) = \text{rank}(A^\ast A)$
 
:::

</div></br>

::: {.proof}

($1$) $(A^\ast A)^\ast = A^\ast A$ 이므로 $A^\ast A$ 는 에르미트 행렬이다. 또한 $\langle A^\ast Au,\, v\rangle = \|Au\|^2\ge 0$ 이므로 $A^\ast A$ 는 positive 이다.

($2$) $u\in \ker(A^\ast A) \implies \langle A^\ast Au,\, v\rangle = \|Au\|^2=0$ 이므로 $u\in \ker (A)$. 역으로 $u\in \ker A$ 이면 $Au=0$ 이므로 $A^\ast A=0$ 이며, 따라서 $u\in \ker (A^\ast A)$. 따라서 $\ker (A^\ast A) = \ker (A)$.

($3$) @thm-kernel_image_of_adjoint_operator 과 ($2$) 로부터 $\text{im}(A^\ast A) = (\ker(A^\ast A))^\perp = (\ker (A))^\perp = \text{im}(A^\ast)$ 임을 안다. 

($4$) @exr-axler_7_A_5 로부터 $\text{rank}(A) = \text{rank}(A^\ast)$. ($3$) 으로부터 $\text{rank}(A^\ast) = \text{rank}(A^\ast A)$. $\square$

:::

</br><div class="border" style="background-color:#FFF0F5 ;padding:5px;">

::: {#prp-properties_of_singular_value}

$A\in \mathcal{M}_{m \times n}(\mathbb{F})$ 일 때 다음이 성립한다.

&emsp; ($1$) $A$ 가 단사일 필요충분조건은 $0$ 이 $A$ 의 특이값이 아닌 것이다.

&emsp; ($2$) $A$ 의 0 이 아닌 특이값의 갯수는 반복되는 것도 갯수를 합치면 $\text{rank}(A)$ 와 같다. 

&emsp; ($3$) $A$ 가 전사일 필요충분조건은 $A$ 의 특이값의 갯수가 $n$ 인 것이다. 

:::

</div></br>

::: {.proof}

($1$) $A$ 가 단사 $\iff \ker (A) = \{0\} \iff \ker(A^\ast A)= \{0\}$ 

($2$) $A$ 가 에르미트 이므로 $\dim (A)$ 는 $A$ 의 $0$ 이 아닌 고유값의 갯수(반복되는 것도 포함하여)와 같다. @prp-properties_of_AAast 의 ($4$) 에 따라 $A$ 의 특이값의 갯수는 $\text{rank}(A)$ 와 같다.

($3$) ($2$) 에 의헤 당연하다. $\square$

:::

</br><div class="border" style="background-color:#FFF0F5 ;padding:5px;">

::: {#prp-linear_isometry_and_singular_values}

정사각 행렬 $\boldsymbol{S}$ 에 대해 다음은 동치이다.

&emsp; ($1$) $\boldsymbol{S}$ 는 linear isometry 이다.

&emsp; ($2$) $\boldsymbol{S}$ 의 특이값이 $1$ 뿐이다.

:::

</div></br>

::: {.proof}

($1 \implies 2$) $\boldsymbol{S}$ 가 linear isometry 이면 $\boldsymbol{S}^\ast\boldsymbol{S}=\boldsymbol{I}$ 이며 따라서 $\boldsymbol{S}$ 의 특이값은 $1$ 뿐이다.

($2\implies 1$) $\boldsymbol{S}$ 의 특이값이 $1$ 뿐이면 $\boldsymbol{S}^\ast\boldsymbol{S}$ 의 고유값이 $1$ 뿐이므로 $\boldsymbol{S}^\ast\boldsymbol{S} = \boldsymbol{I}$ 이다. 따라서 $\boldsymbol{S}$ 는 linear isometry 이다. $\square$

:::


</br>

### 특이값 분해

<div class="border" style="background-color:#FFF0F5 ;padding:5px;">

::: {#prp-for_svd}

영행렬이 아닌 $\boldsymbol{A}\in \mathcal{M}_{m \times n}(\mathbb{F})$ 의 $0$ 이 아닌 특이값 $s_1,\ldots,\,s_M$ 에 대해 $\mathcal{M}_{n}(\mathbb{F})$ 에 속하는 정규직교벡터 $\{\boldsymbol{e}_1,\,\ldots,\,\boldsymbol{e}_n\}$ 와 $\mathcal{M}_m(\mathbb{F})$ 에 속하는 정규직교벡터 $\{\boldsymbol{f}_1,\ldots,\,\boldsymbol{f}_m \}$ 가 존재하여 $\boldsymbol{v}\in \mathcal{M}_n(\mathbb{F})$ 에 대해

$$
\boldsymbol{Av} = \sum_{j=1}^M s_j \langle \boldsymbol{v},\, \boldsymbol{e}_j\rangle \boldsymbol{f}_j
$$

이다. 

:::

</div></br>

::: {.proof}

$\boldsymbol{A}$ 의 특이값의 갯수는 $n$ 개이다. 특이값을 $s_1,\ldots,\,s_n$ 이라고 하고 관례를 따라 $s_1 \ge \cdots\ge s_n$ 이라고 하면 $s_1 \ge \cdots \ge s_M >0$ 이며 $s_{M+1}= \cdots = s_{n}$ 이다. $\boldsymbol{A}^\ast\boldsymbol{A}$ 의 고유값 ${s_i}^2$ 에 대한 정규화된 $\boldsymbol{A}^\ast\boldsymbol{A}$ 의 고유벡터를 $\{\boldsymbol{e}_i: i=1,\ldots,\,n\}$ 라고 하자. 그리고 $j=1,\ldots,\,M$ 에 대해 

$$
\boldsymbol{f}_j = \dfrac{\boldsymbol{Ae}_j}{s_j},\qquad j=1,\ldots,\,M
$$

이라고 하자. 그렇다면, 

$$
\langle \boldsymbol{f}_j,\, \boldsymbol{f}_i\rangle = \dfrac{1}{s_is_j}\langle \boldsymbol{Ae}_j, \boldsymbol{Ae}_i\rangle = \dfrac{1}{s_is_j}\langle \boldsymbol{A}^\ast\boldsymbol{Ae}_j, \boldsymbol{e}_i\rangle = \dfrac{s_j}{s_i}\langle \boldsymbol{e}_j,\, \boldsymbol{e}_i \rangle = \delta_{ij}
$$

이다. 즉 $\{\boldsymbol{f}_j : j=1,\ldots,\,M\}$ 은 정규직교벡터의 집합이다. 이제 $\{\boldsymbol{f}_j\}$ 를 확장하여 $\mathcal{M}_m(\mathbb{F}$ 의 정규직교기저 $\{\boldsymbol{f}_1,\ldots,\,\boldsymbol{f}_m\}$ 을 만들 수 있다. 

 $\{\boldsymbol{e}_i\}$ 는 $\mathcal{M}_n(\mathbb{F})$ 의 정규직교기저이므로 $\boldsymbol{v}\in \mathcal{M}_n(\mathbb{F})$ 는

$$
\boldsymbol{v} = \sum_{i=1}^n \langle \boldsymbol{v},\, \boldsymbol{e}_i \rangle \boldsymbol{e}_i
$$

이다. 그렇다면, 

$$
\boldsymbol{Av} =  \sum_{i=1}^n \langle \boldsymbol{v},\, \boldsymbol{e}_i \rangle \boldsymbol{Ae}_i = \sum_{i=1}^M s_i \langle \boldsymbol{v},\, \boldsymbol{e}_i \rangle \boldsymbol{f}_i
$$

이다. $\square$ 

:::

</br>

::: {.callout-note appearance="simple" icon="false"}
::: {#def-eigenvector_for_signular_value}

#### 특이벡터

@prp-for_svd 에서 정의된 $\mathcal{M}_n(\mathbb{F})$ 의 정규직교기저벡터 $\boldsymbol{e}_1,\ldots,\,\boldsymbol{e}_n$ 를 행렬 $\boldsymbol{A}$ 에 대한 **오른쪽 특이벡터 (right singular vectors)** 라고 한다. 또한 $\mathcal{M}_m(\mathbb{F})$ 의 정규직교기저벡터 $\boldsymbol{f}_1,\ldots,\,\boldsymbol{f}_m$ 을 **왼쪽 특이 벡터(left singular vectors)** 라고 한다.

:::
:::

</br>

왼쪽과 오른쪽이라는 이름은 특이값 분해에 대해 알게되면 자연스럽다.

</br>
<div class="border" style="background-color:#FFF0F5 ;padding:5px;">

::: {#thm-svd_1}

#### 1차 특이값 분해

$\boldsymbol{A}\in \mathcal{M}_{m \times n}(\mathbb{F})$ 가 $M=\text{rank} (\boldsymbol{A}) \ge 1$ 이라고 하자. 이 때 서로 직교하는 열벡터로 구성된 $\boldsymbol{B}\in \mathcal{M}_{m \times M}(\mathbb{F})$ 과 대각행렬 $\boldsymbol{D}\in \mathcal{M}_{M \times M}(\mathbb{F})$ 그리고 역시 서로 직교하는 열벡터로 구성된 $\boldsymbol{C}=\mathcal{M}_{n \times M}(\mathbb{F})$ 에 대해 

$$
\boldsymbol{A} = \boldsymbol{BDC}^\ast
$$

이다.
:::

</div></br>

::: {.proof}

@prp-for_svd 을 생각하자. 이제 $\boldsymbol{B} = \begin{bmatrix} \boldsymbol{f}_1 & \cdots & \boldsymbol{f}_M\end{bmatrix}$ 라 하고 $\boldsymbol{D}$ 는 $D_{ij}= s_j\delta_{ij}$ 가 되도록 하며 $\boldsymbol{C} = \begin{bmatrix} \boldsymbol{e}_1 & \cdots \boldsymbol{e}_M \end{bmatrix}$ 라고 하자. 

$$
\boldsymbol{BDC}^\ast\boldsymbol{v}= \boldsymbol{BD}\begin{bmatrix} \langle \boldsymbol{v},\,\boldsymbol{e}_1\rangle \\ \vdots \\ \langle \boldsymbol{v},\, \boldsymbol{e}_M\rangle \end{bmatrix} = \boldsymbol{B}\begin{bmatrix} s_1\langle \boldsymbol{v},\,\boldsymbol{e}_1\rangle \\ \vdots \\ s_M\langle \boldsymbol{v},\, \boldsymbol{e}_M\rangle \end{bmatrix} = \sum_{i=1}^M s_i \langle \boldsymbol{v},\, \boldsymbol{e}_i \rangle \boldsymbol{f}_i = \boldsymbol{Av}
$$


이다. 임의의 벡터 $\boldsymbol{v}$ 에 대해 성립하므로 $\boldsymbol{A} = \boldsymbol{BDC}^\ast$ 이다. $\square$
:::

</br>

@thm-svd_1 은 실제 계산에서 잘 사용하지 않으며, 약간 변형된 형태로 많이 사용한다.

</br><div class="border" style="background-color:#FFF0F5 ;padding:5px;">

::: {#thm-svd_2}

#### 2차 특이값 분해

$\boldsymbol{A}\in \mathcal{M}_{m \times n}(\mathbb{F})$ 가 $\text{rank} (\boldsymbol{A}) \ge 1$ 이라고 하자. 이 때 서로 직교하는 열벡터로 구성된 $\boldsymbol{U}\in \mathcal{M}_{m \times m}(\mathbb{F})$ 과 대각성분이 1이며 나머지 성분은 0 인 직사각행렬 $\boldsymbol{\Sigma}\in \mathcal{M}_{M \times n}(\mathbb{F})$ 그리고 역시 서로 직교하는 열벡터로 구성된 $\boldsymbol{V}=\mathcal{M}_{n \times n}(\mathbb{F})$ 에 대해 

$$
\boldsymbol{A} = \boldsymbol{U\Sigma V}^\ast
$$

이다.

:::

</div></br>

::: {.proof}

@prp-for_svd 를 생각하자. $\boldsymbol{U} = \begin{bmatrix} \boldsymbol{f}_1 & \cdots & \boldsymbol{f}_m\end{bmatrix}$ 라 하고 $\boldsymbol{V}= \begin{bmatrix} \boldsymbol{e}_1 & \cdots \boldsymbol{e}_n\end{bmatrix}$ 라고 하자. (@thm-svd_1 의 $\boldsymbol{B},\, \boldsymbol{D}$ 보다 큰데, 왼쪽 특이벡터와 오른쪽 특이벡터 전체를 사용한다.)

@thm-svd_1 에서 $\boldsymbol{D}$ 는 $M \times M$ 행렬이며 $M \le \text{min}(m, n)$ 이다. $m \times n$ 행렬 $\boldsymbol{\Sigma}$ 을 1행 1열부터 $M$ 행 $M$ 열 까지를 $\boldsymbol{D}$ 와 같은 값을 가지며 나머지는 $0$ 인 행렬로 정의하자. 그렇다면, 임의의 $\boldsymbol{v}\in \mathcal{M}_{n}(\mathbb{F})$ 에 대해 

$$
\begin{aligned}
\boldsymbol{U\Sigma V}^\ast \boldsymbol{v} = 
\boldsymbol{U\Sigma}\begin{bmatrix} \langle \boldsymbol{v},\,\boldsymbol{e}_1\rangle \\ \vdots \\ \langle \boldsymbol{v},\, \boldsymbol{e}_M\rangle \\ \langle \boldsymbol{v},\, \boldsymbol{e}_{M+1}\rangle \\ \vdots \\ \langle \boldsymbol{v},\,\boldsymbol{e}_n \rangle \end{bmatrix} = 
\boldsymbol{U} \begin{bmatrix} s_1\langle \boldsymbol{v},\,\boldsymbol{e}_1\rangle \\ \vdots \\ s_M\langle \boldsymbol{v},\, \boldsymbol{e}_M\rangle \\ 0 \cdot \langle \boldsymbol{v},\, \boldsymbol{e}_{M+1}\rangle \\ \vdots \\ 0 \cdot  \langle \boldsymbol{v},\,\boldsymbol{e}_n \rangle \end{bmatrix} = \sum_{i=1}^M s_i \langle \boldsymbol{v},\, \boldsymbol{e}_i \rangle \boldsymbol{f}_i = \boldsymbol{Av}
\end{aligned}
$$

이다. 즉 $\boldsymbol{A} = \boldsymbol {U\Sigma V}$ 이다. 

:::


많은 경우 @thm-svd_2 의 형태로 특이값 분해를 사용한다.

</br><div class="border" style="background-color:#FFF0F5 ;padding:5px;">

::: {#prp-adjoint_of_svd}

$\boldsymbol{A} \in \mathcal{M}_{m\times n}(\mathbb{F})$ 의 오른쪽 특이벡터와 왼쪽 특이벡터는 각각 $\boldsymbol{A}^\ast$ 의 왼쪽 특이벡터와 오른쪽 특이벡터이다. $\boldsymbol{A}$ 가 $0$ 이 아닌 특이값 $s_1 \ge \cdots \ge s_M>0$ 을 가질 때 $\boldsymbol{u}\in \mathcal{M}_m(\mathbb{F})$ 에 대해

$$
\boldsymbol{A}^\ast\boldsymbol{u} = \sum_{j=1}^M s_j\langle \boldsymbol{u},\,\boldsymbol{f}_j\rangle \boldsymbol{e}_j
$$

이다.

:::

</div></br>

::: {.proof}

$\boldsymbol{A}= \boldsymbol{U\Sigma V}^\ast$ 이므로 $\boldsymbol{A}^\ast = \boldsymbol{V\Sigma}^\ast \boldsymbol{U}^\ast$ 이다. 그런데 $\boldsymbol{\Sigma}$ 는 대각성분은 실수이며, 대각성분을 제외한 행렬은 모두 $0$ 이므로  $\boldsymbol{\Sigma}^\ast = \boldsymbol{\Sigma}^T$ 이다. 즉 $\boldsymbol{V\Sigma}^T\boldsymbol{U}^\ast$ 는 $\boldsymbol{A}^\ast$ 의 특이값 분해이다. $\boldsymbol{U} = \begin{bmatrix} \boldsymbol{f}_1 & \cdots & \boldsymbol{f}_m\end{bmatrix}$ 이며 $\{\boldsymbol{f}_j\}$ 는 $\mathcal{M}_m(\mathbb{F})$ 의 정규직교기저이므로 $\boldsymbol{u} = \sum_{j=1}^m \langle \boldsymbol{u},\,\boldsymbol{f}_j\rangle \boldsymbol{f}_j$ 이다. 따라서, 

$$
\boldsymbol{A}^\ast\boldsymbol{u} = \sum_{j=1}^m \langle \boldsymbol{u},\, \boldsymbol{f}_j\rangle \boldsymbol{V\Sigma}^T\boldsymbol{U}^\ast \boldsymbol{f}_j = \sum_{j=1}^M s_j \langle \boldsymbol{u}_j,\, \boldsymbol{f}_j\rangle \boldsymbol{e}_j
$$

이다. $\square$


:::

</br><div class="border" style="background-color:#FFF0F5 ;padding:5px;">

::: {#prp-inverse_matrix_using_svd}

$\boldsymbol{A}$ 가 가역행렬이라고 하자. $\boldsymbol{A}= \boldsymbol{U\Sigma V}^\ast$ 일 때 

$$
\left(\overline{\boldsymbol{\Sigma}}\right)_{ij} = \left\{\begin{array}{ll} 1/\Sigma_{ii} \qquad &\text{if } i=j,\, s_i \ne 0 \\ 0&\text{otherwise} \end{array} \right.
$$

$$
\boldsymbol{A}^{-1} =  \boldsymbol{V\overline{\Sigma} U}^\ast 
$$

이다.

:::

</div></br>

::: {.proof}

$\boldsymbol{A}$ 가 가역행렬이면 정사각 행렬이며, @prp-properties_of_singular_value 에 따라 $\boldsymbol{\Sigma}$ 는 대각성분이 모두 $0$ 이 아닌 대각행렬이며 따라서 $\boldsymbol{\Sigma\overline{\Sigma}} = \boldsymbol{I}$ 이다. 이를 이용하면

$$
\boldsymbol{A}(\boldsymbol{V\overline{\Sigma} U}^\ast)  = (\boldsymbol{U\Sigma V}^\ast)(\boldsymbol{V\overline{\Sigma} U}^\ast)= \boldsymbol{U\Sigma \overline{\Sigma} U}^\ast = \boldsymbol{UU}^\ast = \boldsymbol{I}
$$

이다. $\square$

:::


</br>

## 특이값 분해의 활용

### 행렬의 노름

<div class="border" style="background-color:#FFF0F5 ;padding:5px;">

::: {#prp-norm_of_matrix}

$\boldsymbol{A}\in \mathcal{M}_{m \times n}(\mathbb{F})$ 의 가장 큰 특이값을 $s_M$ 이라고 하면 다음이 성립한다.

$$
\forall \boldsymbol{v}\in \mathcal{M}_n(\mathbb{F}),\qquad \|\boldsymbol{Av}\| \le s_M \|\boldsymbol{v}\|.
$$
:::

</div></br>

::: {.proof}

@thm-svd_2 의 증명과정에서 $\boldsymbol{Av} = \sum_i s_i \langle \boldsymbol{v},\, \boldsymbol{e}_i \rangle \boldsymbol{f}_i$ 임을 알았다. 이를 이용하면

$$
\begin{aligned}
\|\boldsymbol{Av}\|^2 &= \left\| \sum_{i=1}^M s_i \langle \boldsymbol{v},\, \boldsymbol{e}_i \rangle \boldsymbol{f}_i \right\|^2  \le \sum_{i=1}^M  |s_i \langle \boldsymbol{v},\, \boldsymbol{e}_i\rangle|^2 \le {s_M}^2 \sum_{i=1}^M |\langle \boldsymbol{v},\, \boldsymbol{e}_i\rangle|^2 \le {s_M}^2 \|\boldsymbol{v}\|^2
\end{aligned}
$$

이다. 마지막 부등호는 베셀 부등식(@prp-properties_of_orthonormal_vectors ($3$)) 으로부터 성립한다. 따라서 $\|\boldsymbol{Av}\| \le s_M \|\boldsymbol{v}\|$ 이다. $\square$
:::


</br>

@prp-norm_of_matrix 의 최대 특이값 $s_M$ 을 갖는 벡터는 ${s_M}^2$ 의 고유값에 대한 $\boldsymbol{A}^\ast\boldsymbol{A}$ 의 고유벡터이므로 항상 존재한다. $\boldsymbol{v}\ne \boldsymbol{0}$ 에 대해 

$$
\dfrac{\|\boldsymbol{Av}\|}{\|\boldsymbol{v}\|} \le s_M
$$

이므로 $s_M$ 은 선형사상에 의해 증가하는 벡터의 크기의 비율의 상한을 정의한다. 만약 $\|\boldsymbol{v}\|=1$ 이라면 $\|\boldsymbol{Av}\| \le s_M$ 이다. 이제 행렬의 노름을 정의하자. 앞서 설명했던과 같이 동등한 값이 여러개 있지만 그중 다루기 편한 것으로 정의하고 이후 동등한 명제에 대해 설명하기로 한다.₩

</br>


::: {.callout-note appearance="minimal" icon="false"}
::: {#def-norm_of_matrix}

#### 행렬의 노름

$\boldsymbol{A}\in \mathcal{M}_{m \times n}(\mathbb{F})$ 의 노름 $\|\boldsymbol{A}\|$ 는 다음과 같이 정의된다.

$$
\|\boldsymbol{A}\| := \max \{ \|\boldsymbol{Av}\| : \|\boldsymbol{v}\|=1\} 
$$


:::
:::

</br><div class="border" style="background-color:#FFF0F5 ;padding:5px;">

::: {#prp-anothor_definitions_of_matrix_norm}

#### 노름의 다양한 정의

행렬 $\boldsymbol{A}$ 에 대해 다음 네 값은 같다. 즉 행렬의 노름에 대해 4가지 동등한 정의가 존재한다.

&emsp; ($1$) $\max \{ \|\boldsymbol{Av}\| : \|\boldsymbol{v}\|=1 \}$

&emsp; ($2$) $\max \{ \|\boldsymbol{Av}\| : \|\boldsymbol{v}\|\le 1 \}$

&emsp; ($3$) $\boldsymbol{A}$ 의 최대 특이값.

&emsp; ($4$) $\max \left\{ \dfrac{\|\boldsymbol{Av}\|}{\|\boldsymbol{v}\|} : \boldsymbol{v} \ne \boldsymbol{0}\right\}$. 

:::

</div></br>

::: {.proof}

($3$) 과 ($4$) 가 같다는 것은 앞에서 설명했다. ($2$) 에서 $\|\boldsymbol{Av}\|$ 를 최대로 하는 값이 $|\boldsymbol{v}\|<1$ 이면 $\boldsymbol{u}=\dfrac{\boldsymbol{v}}{\|\boldsymbol{v}\|}$ 에 대해 $\|\boldsymbol{u}\|=1$ 이며 $|\boldsymbol{Au}\| > \|\boldsymbol{Av}|$ 이므로 모순된다. 따라서 ($2$) $\|\boldsymbol{Av}\|$ 를 최대로 하는 $\|\boldsymbol{v}\|$ 는 $\|\boldsymbol{v}\|=1$ 일 때이다. 따라서 ($1$) 의 값과 ($2$) 의 값은 같다.

($4$) 의 값에 대해 $\dfrac{\|\boldsymbol{Av}\|}{\|\boldsymbol{v}\|} = \left\|\boldsymbol{A} \left(\dfrac{\boldsymbol{v}}{\|\boldsymbol{v}\|}\right) \right\|$ 이므로 ($1$) 의 값과 같다. 따라서 위의 네 값은 같다.

:::

</br><div class="border" style="background-color:#FFF0F5 ;padding:5px;">

::: {#prp-properties_of_matrix_norm}

행렬의 노름 $\|\cdot \|$ 에 대해 다음이 성립한다.

&emsp; ($1$) $\|\boldsymbol{A}\|\ge 0$. 

&emsp; ($2$) $\|\boldsymbol{A}\|=0 \iff \boldsymbol{A} =\boldsymbol{0}$.

&emsp; ($3$) $c\in \mathbb{F}$ 에 대해 $\|c\boldsymbol{A}\| = |c|\|\boldsymbol{A}\|$.

&emsp; ($4$) $\|\boldsymbol{A} +\boldsymbol{B}\| \le \|\boldsymbol{A} \|+\|\boldsymbol{B}\|$. 

&emsp; ($5$) $\|\boldsymbol{A}\| \|\boldsymbol{v}\| \ge \|\boldsymbol{Av}\|$.

&emsp; ($6$) $\|\boldsymbol{A^\ast}\| = \| \boldsymbol{A}\|$. 

:::

</div></br>

::: {.proof}

($1$) 노름의 정의에 의해 자명하다.

($2$) $\boldsymbol{A}=0$ 이면 당연히 $\|\boldsymbol{A}\|=0$ 이다. $\|\boldsymbol{A}\|=0$ 이면 모든 $\boldsymbol{v}$ 에 대해 $\boldsymbol{Av}=\boldsymbol{0}$ 이어야 하므로 $\boldsymbol{A}=\boldsymbol{0}$ 이다.

($3$) $\|c\boldsymbol{Av}\| = |c|\|\boldsymbol{Av}\|$. 

($4$) $\|(\boldsymbol{A}+\boldsymbol{B})\boldsymbol{v}\| = \|\boldsymbol{Av}+\boldsymbol{Bv}\|  \le \|\boldsymbol{Av}\| +\|\boldsymbol{Bv}\|$.

($5$) @prp-anothor_definitions_of_matrix_norm 의 ($4$) 로 부터 $\|\boldsymbol{A}\| \ge \dfrac{\|\boldsymbol{Av}\|}{\|\boldsymbol{v}\|}$ 이다. 

($6$) $\|\boldsymbol{A}^\ast\boldsymbol{v}\|^2 = \langle \boldsymbol{AA}^\ast\boldsymbol{v},\, \boldsymbol{v}\rangle \le \boldsymbol{v} \le \|\boldsymbol{AA}^\ast\boldsymbol{v}\|\|\boldsymbol{v}\|$ 이며 ($5$) 로 부터 

$$
\|\boldsymbol{AA}^\ast\boldsymbol{v}\| = \|\boldsymbol{A}(\boldsymbol{A}^\ast\boldsymbol{v})\| \le \|\boldsymbol{A}\|\|\boldsymbol{A}^\ast\boldsymbol{v}\|\|\boldsymbol{v}\|
$$

이므로 $\|\boldsymbol{A}^\ast\boldsymbol{v}\|^2 \le \|\boldsymbol{A}^\ast\boldsymbol{v}\|\|\boldsymbol{A}\|\boldsymbol{v}\|$ 이다. 따라서 $\dfrac{\|\boldsymbol{A}^\ast\boldsymbol{v}\|}{\|\boldsymbol{v}\|} \le \|\boldsymbol{A}\|$ 이므로 매트릭스 노름의 정의에 의해 $\|\boldsymbol{A}^\ast\|\le \|\boldsymbol{A}\|$ 이다. 여기에 $(\boldsymbol{A}^\ast)^\ast =\boldsymbol{A}$ 임을 이용하면 $\|\boldsymbol{A}\|\le \|\boldsymbol{A}^\ast\|$ 를 얻는다. 즉 $\|\boldsymbol{A}^\ast\|=\boldsymbol{A}\|$ 이다. $\square$

:::

</br>

### Approximation by Linear Maps with Lower-Dimensional Range

::: {.callout-caution icon="false"}

#### 특이값 열거 순서

특이값은 0이 아닌 실수이므로 순서대로 열거 할 수 있다. 보통 가장 큰 값부터 중복을 허용하여 열거한다. 특이값을 $s_1,\,s_2,\ldots$ 로 표현하면 가장 큰 값이 $s_1$ 이 된다. 

:::


$L\in \mathcal{L}(U,\,V)$ 의 양의 특이값을 $s_1 \ge s_2 \ge \ldots,\ge s_m>0$ 이라고 하자. 이것을 $k<m$ 의 $\text{rank}$ 를 갖는 어떤 선형사상으로 근사(approximation) 하고자 하며, 가장 좋은 근사인 선형사상을 $L_k$ 라고 하자. 이 때 특이값 분해를 사용 할 수 있다.

</br><div class="border" style="background-color:#FFF0F5 ;padding:5px;">

::: {#prp-approximation_using_svd}

$\boldsymbol{A} \in \mathcal{M}_{m \times n}(\mathbb{F})$ 가 양의 특이값 $s_1 \ge s_2 \ge \ldots \ge s_m>0$ 을 갖는다고 하자. $k \le m$ 에 대해 다음이 성립한다.

$$
\min \{ \|\boldsymbol{A}-\boldsymbol{B} \| : \boldsymbol{B}\in \mathcal{M}_{m \times n}(\mathbb{F}),\, \text{rank}(\boldsymbol{B})\le k\} = s_{k+1}.
$$

또한 $\|\boldsymbol{A}-\boldsymbol{B}\| = s_{k+1}$ 을 만족하는 그 $\text{rank}$ 가 $k$ 보다 작은 행렬이 존재한다.

:::

</div></br>

::: {.proof}

@thm-svd_2 를 생각하자. $\boldsymbol{v}\in \mathcal{M}_n(\mathbb{F})$ 에 대해 $\boldsymbol{A}=\boldsymbol{U\Sigma V}^\ast$ 이다. 이 때 $\boldsymbol{V}_k = \begin{bmatrix} \boldsymbol{e}_1 & \cdots & \boldsymbol{e}_k & 0 & \cdots & 0\end{bmatrix}$ 라고 하고 $\boldsymbol{A}_k = \boldsymbol{U\Sigma V}_k^\ast$ 라고 하자. 

$$
(\boldsymbol{A}-\boldsymbol{A}_k)\boldsymbol{v} = \boldsymbol{U\Sigma} \begin{bmatrix}  \boldsymbol{0} \\ \langle \boldsymbol{v},\, \boldsymbol{e}_{k+1} \rangle \\ \vdots \\ \langle \boldsymbol{v},\,\boldsymbol{e}_{m} \rangle \\ \boldsymbol{0}\end{bmatrix} =  \sum_{i=k+1}^m s_{i} \langle \boldsymbol{v},\, \boldsymbol{e}_i\rangle \boldsymbol{f}_i
$$


이며, 따라서 $\|(\boldsymbol{A}-\boldsymbol{A}_k)\boldsymbol{v}\|^2 \le {s_{k+1}}^2 \|\boldsymbol{v}\|^2$ 이며 이로부터 

$$
\|\boldsymbol{A}-\boldsymbol{A}_k\| \le s_{k+1}
$$ {#eq-svd_1}

을 얻는다.

이제 임의의 $\boldsymbol{B}\in \mathcal{M}_{m \times n}(\mathbb{F})$, $\text{rank}(\boldsymbol{B})\le k$ 를 생각하자. $\{\boldsymbol{Be}_1,\ldots,\,\boldsymbol{Be}_{k+1}\}$ 벡터의 갯수가 $\text{rank}(\boldsymbol{B})$ 보다 크기 때문에 선형종속이며, 따라서, 

$$
a_1 \boldsymbol{Be}_1 + \cdots + a_{k+1}\boldsymbol{Be}_{k+1} = \boldsymbol{0}
$$

을 만족하는, nontrivial 한 $a_1,\ldots,\,a_{k+1}$ 이 존재한다. 이제 $a_1,\ldots,\,a_{k+1}$ 을 이용하여 다음의 계산을 수행한다. 

$$
\begin{aligned}
(\boldsymbol{A}-\boldsymbol{B})\left(\sum_{j=1}^{k+1}a_j \boldsymbol{e}_j\right) = \boldsymbol{A}\left(\sum_{j=1}^{k+1}a_j \boldsymbol{e}_j\right) = \sum_{j=1}^{k+1} a_j s_j \boldsymbol{f}_j 
\end{aligned}
$$

이로부터 
$$
\begin{aligned}
\left\|(\boldsymbol{A}-\boldsymbol{B})\left(\sum_{j=1}^{k+1}a_j \boldsymbol{e}_j\right)\right\|^2 &= \sum_{j=1}^{k+1} {s_j}^2 |a_j|^2 \\
&\ge {s_{k+1}}^2(|a_1|^2 + \cdots + |a_{k+1}|^2) \\
&= {s_{k+1}}^2 \| a_1\boldsymbol{e}_1 + \cdots + a_{k+1}\boldsymbol{e}_{k+1}\|^2
\end{aligned}
$$

이다. $a_1\boldsymbol{e}_1+\cdots +a_{k+1}\boldsymbol{e}_{k+1} \ne \boldsymbol{0}$ 이므로, 

$$
\|\boldsymbol{A} -\boldsymbol{B}\| \ge s_{k+1}
$$ {#eq-svd_2}

을 얻는다. @eq-svd_1 의 $\boldsymbol{A}_k$ 는 $\text{rank}(\boldsymbol{A}_k) \le k$ 이므로 @eq-svd_2 를 만족해야 한다. 따라서 

$$
\|\boldsymbol{A}-\boldsymbol{A}_k\| = s_{k+1}
$$

이다. 

:::


</br>

### 극분해

<div class="border" style="background-color:#FFF0F5 ;padding:5px;">

::: {#prp-polar_decomposition}

정사각행렬 $\boldsymbol{A}\in \mathcal{M}_{n \times n}(\mathbb{F})$ 는 어떤 유니타리 행렬 $\boldsymbol{U}$ 에 대해 $\boldsymbol{A}=\boldsymbol{S}\sqrt{\boldsymbol{A}^\ast\boldsymbol{A}}$ 이다.

:::

</div></br>

::: {.proof}

@thm-svd_2 형식의 특이값 분해 $\boldsymbol{A}= \boldsymbol{U\Sigma V}^\ast$ 를 사용한다. $\boldsymbol{A}$ 가 정사각 행렬이므로 $\boldsymbol{U},\,\boldsymbol{\Sigma},\, \boldsymbol{V}$ 모두 정사각 행렬이다. $\boldsymbol{\Sigma}$ 는 실수 성분의 대각행렬이다. $\boldsymbol{A}^\ast\boldsymbol{A} = \boldsymbol{V}\boldsymbol{\Sigma}^2\boldsymbol{V}^\ast$ 이므로, $\sqrt{\boldsymbol{A}^\ast\boldsymbol{A}} = \boldsymbol{V\Sigma V}^\ast$ 이다. 따라서 $\boldsymbol{S}=\boldsymbol{UV}^\ast$ 라고 하면 $\boldsymbol{A} = \boldsymbol{S}\sqrt{\boldsymbol{A}^\ast\boldsymbol{A}}$ 이다. $\square$

:::

</br>

::: {.callout-note appearance="simple" icon="false"}
::: {#def-polar_decomposition}

#### 행렬의 극분해

@prp-polar_decomposition 에 따라 정사각 행렬을 유니타리 행렬과 non-negative 행렬의 곱으로 표현하는 것을 행렬의 **극분해(polar decomposition)** 이라고 한다. 
:::
:::