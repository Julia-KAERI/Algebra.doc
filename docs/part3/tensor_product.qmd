---
title: "텐서곱"
number-sections: true
number-depth : 3
crossref:
  chapters: true
---

## 쌍선형 형식

두 벡터공간을 곱하는 것에 대해 우리는 곱공간 $U \times V$ 를 안다. 여기서는 $U \otimes V$ 로 표기되는 두 벡터공간의 텐서곱에 대해 알아보고자 한다. 이를 위해 @def-k_linear_form 에서의 쌍선형 형식을 이용한다.

::: {#prp-part_3_bilinear_form_is_vector_space}

$\mathbb{F}$-벡터공간 $U\times V$ 에서 정의된 쌍선형 형식의 집합 $\mathfrak{B}(U,\,V)$ 는 벡터공간이다.

:::


::: {.proof}

$T,\,S\in \mathfrak{B}(U,\,V),\, c\in \mathbb{F}$ 라고 하자. $u\in U,\,v\in V,\, a\in \mathbb{F}$ 에 대해

$$
(T+cS)(u,\,v) := T(u,\,v) + cS(u,\,v) 
$$

로 정의하자. 그렇다면, 

$$
\begin{aligned}
(T+cS)(u+au',\,v)&= T(u+au',v) + cS(u+au', v) \\
&= T(u, v)+aT(u', v) +c(S(u, v)+ aS(u', v)) \\
&= (T+cS)(u,\,v) + a(T+cS)(u',\,v)\\
(T+cS)(u,\, v+av') &= (T+cS)(u, v) + a(T+cS)(u, v')
\end{aligned}
$$

이므로 $T+cS \in \mathfrak{B}(U, V)$ 이다. 따라서 $\mathfrak{B}(U, V)$ 는 벡터공간이다. $\square$

:::


</br>


<div class="border" style="background-color:#F2F4F4  ;padding:5px;">

::: {#exm-part3_bilinear_functional}

#### 쌍선형 형식

벡터공간 $U,\,V$ 와 그 쌍대공간 $U^\ast,\, V^\ast$ 를 생각하자. 

1. 정해진 $\phi\in U^\ast$, $\psi \in V^\ast$ 에 대해 $\beta:U \times V \to \mathbb{F}$ 를 $\beta(u,\,v) = \phi(u)\psi(v)$ 로 정의하면 $\beta$ 는 $U\times V$ 에서의 쌍선형 형식이다.

2. 정해진 $u\in U,\,v\in V$ 에 대해 $\beta : U^\ast \times V^\ast \to \mathbb{F}$ 를 $\beta(\phi,\, \psi) = \phi(u)\psi(v)$ 로 정의하면 $\beta$ 는 $U^\ast \times V^\ast$ 에서의 쌍선형 형식이다.

3. $\beta \in \mathfrak{B}(U,\, U^\ast)$ 를 $\beta(u,\, \phi) = \phi(u)$ 로 정의하면 $\beta$ 는 $U \times U^\ast$ 에서의 쌍선형 형식이다.

4. $\psi \in U^\ast$ 에 대해 $\beta \in \mathfrak{B}(U , \mathcal{L}(U))$ 를 $\beta (u,\,L) = \phi (Lu)$ 라고 정의하면 $\beta$ 는 $U \times \mathcal{L}(U)$ 에서의 쌍선형 형식이다.

5. $\beta \in \mathfrak{B}(\mathcal{M}(\mathbb{F})_{m \times n}, \mathcal{M}(\mathbb{F})_{n \times m})$ 를 $\beta (A,\,B) = \textrm{tr}(AB)$ 로 정의하면 $\beta$ 는 $\mathcal{M}(\mathbb{F})_{m \times n} \times \mathcal{M}(\mathbb{F})_{n \times m}$ 에서의 쌍선형 형식이다.


:::

</div>

</br>

::: {#prp-part3_dimension_of_bilinear_functional}

유한차원 벡터공간 $U,\,V$ 에 대해 $\dim(\mathfrak{B}(U,\,V)) = \dim(U) \times \dim(V)$ 이다. 

:::

::: {.proof}

$\mathcal{B}_U=(e_1,\ldots,\,e_m)$ 이 $U$ 의 기저이고 $\mathcal{B}_V=(f_1,\ldots,\,f_n)$ 이 $V$ 의 기저라고 하자. 또한 $\Phi : \mathfrak{B}(U,\,V) \to \mathcal{M}(\mathbb{F})_{m \times n}$ 을

$$
(\Phi (\beta))_{ij} := \beta(e_i, f_j)
$$

로 정의하자. 여기서 $\Phi$ 가 동형사상임을 보이면 된다. $c\in \mathbb{F},\, \beta,\,\gamma \in \mathfrak{B}(U,\,V)$ 에 대해 

$$
(\Phi (\beta + c\gamma))_{ij} = (\beta + c\gamma)(e_i, f_j) = (\Phi(\beta))_{ij} + c (\Phi (\gamma))_{ij}
$$

이므로 $\Phi$ 는 선형사상이다. $\beta \in \ker (\Phi)$ 라고 하자. $e_i\in \mathcal{B}_U,\, f_j\in \mathcal{B}_V$ 에 대해 $\beta (e_i,\,f_j)=0$ 

또한 $\ker (\Phi) = 0 \in \mathcal{M}(\mathbb{F})_{m \times n}$ 이므로 $\Phi$ 는 동형사상이다. $\square$

:::

</br>

## 텐서곱

::: {.callout-note appearance="minimal"}

::: {#def-part3_tensor_product}

#### 벡터공간의 텐서곱

벡터공간 $U,\,V$ 에 대해 $U \otimes V := \mathfrak{B}(U^\ast,\,V^\ast)$ 를 $U,\,V$ 에 대한 **텐서곱 (tensor product)** 라고 한다. $u\in U,\,v\in V$ 에 대해 $u \otimes v : U^\ast \times V^\ast \to \mathbb{F}$ 는 다음과 같이 정의된다.

$$
(u\otimes v)(\phi,\,\psi) :=  \phi (u) \psi(v).
$$

:::

:::

</br>

::: {#prp-part3_dimension_of_tensor_product}

$U,\,V$ 가 유한차원 벡터공간일 때 $\dim(U \otimes V) = \dim(U) \times \dim (V)$ 이다.

:::

::: {.proof}

유한차원 벡터공간일 때 $\dim(U^\ast) = \dim (U)$ 이다. $\square$

:::

</br>

::: {#prp-part3_bilinearity_of_tensor_product}

$u,\, u_1,\,u_2\in U$, $v,\,v_1,\,v_2\in V$, $c\in \mathbb{F}$ 에 대해 다음이 성립한다.

$$
\begin{aligned}
(u_1+u_2)\otimes v &= u_1 \otimes v + u_2 \otimes v, \\[0.2em]
u \otimes (v_1 + v_2) &= u \otimes v_1 + u \otimes v_2.
\end{aligned}
$$


:::

::: {.proof}

$\phi\in U^\ast,\, \psi \in V^\ast$ 에 대해 

$$
\begin{aligned}
((u_1+u_2)\otimes v)(\phi,\, \psi) &= \phi (u_1+u_1) \psi(v) =  \phi (u_1)\psi(v)+ \phi (u_2)\psi(v) \\
&= (u_1 \otimes v + u_2 \otimes v)(\phi,\, \psi).
\end{aligned}
$$

즉 $(u_1+u_2)\otimes v = u_1 \otimes v + u_2 \otimes v$ 이다. 같은 방법으로 $u \otimes (v_1 + v_2) = u \otimes v_1 + u \otimes v_2$ 임을 보일 수 있다. $\square$

:::

위의 @prp-part3_bilinearity_of_tensor_product 는 $u \otimes v$ 가 쌍선형 형식임을 보여준다.


</br>

::: {#thm-part3_basis_of_tensor_product}

$\mathcal{B}_U = \{e_1,\ldots,\,e_m\},\, \mathcal{B}_V=\{f_1,\ldots,\,f_n\}$ 이 각각 벡터공간 $U,\,V$ 의 부분집합이고 $\mathcal{B} = \{e_i \otimes f_j : i=1,\ldots,\,m,\, j=1,\ldots,\,n\}$ 일 때 다음이 성립한다. 

&emsp; ($1$) $\mathcal{B}_U,\,\mathcal{B}_V$ 가 각각 선형독립이면 $\mathcal{B}$ 도 $U\otimes V$ 에서 선형독립이다. 

&emsp; ($2$) $\mathcal{B}_U,\,\mathcal{B}_V$ 가 $U\otimes V$ 의 기저이면 $\mathcal{B}$ 는 $U \otimes V$ 의 기저이다.


:::

::: {.proof}

($1$) $\mathcal{B}_U$ 가 선형독립이면 $\phi_k(e_i)= \delta_{ik}$ 가 되도록 하는 $\phi_k\in U^\ast,\, k=1,\ldots,\,m$ 이 존재한다. 마찬가지로 $\psi_l(f_j) = \delta_{jl}$ 가 되도록 하는 $\psi_l\in V^\ast,\, l=1,\ldots,\,m$ 이 존재한다. 

이제

$$
\sum_{k=1}^m \sum_{l=1}^n a_{kl} (\phi_k \otimes \psi_l)=0
$$

이 되도록 하는 $\{a_{kl}\}$ 을 찾아보자. $(\phi_k \otimes \psi_l)(e_i, f_j)= \delta_{ik}\delta_{jl}$ 이므로 모든 $\{e_i\},\,\{f_j\}$ 에 대해 $0$ 이 되려면 모든 $a_{kl}=0$ 이어야 한다. 즉 $\mathcal{B}$ 는 선형독립이다.

($2$) $\mathcal{B}$ 원소의 갯수는 $m \times n$ 이므로 $\mathcal{B}$ 는 $U \times V$ 의 기저이다. $\square$ 

:::

</br>

::: {#exr-axler_4th_9D_3}

$\{u_1,\ldots,\,u_m\}$ 이 $U$ 에서의 선형독립이며 $\{v_1,\ldots,\,v_m\}\subset V$ 가

$$
u_1 \otimes v_1 + \cdots + u_m \otimes v_m = 0
$$

을 만족한다면 $v_1=\cdots = v_m=0$ 임을 보여라.

:::

::: {.solution}

$\phi_k(u_i)=\delta_{ik}$ 일 때 임의의 $\psi \in V^\ast$ 에 대해 

$$(u_1 \otimes v_1 + \cdots + u_m \otimes v_m)(\phi_1,\,\psi)=0
$$ 

이어야 하므로 $v_1=0$ 이어야 한다. 같은 방법으로 $v_1=\cdots = v_m=0$ 임을 보일 수 있다. 

:::

</br>

::: {#exr-axler_4th_9D_4}

$\dim (U)>1,\, \dim(V)>1$ 일 때 $X=\{u\otimes v : (u,\,v)\in U\times V\}$ 는 $U \otimes V$ 의 부분공간이 아님을 보이시오.

:::

::: {.proof}

선형 독립인 $u_1,\,u_2\in U,\,v_1,\,v_2\in V$ 를 생각하자. $X  \le  (U \otimes V)$ 이려면 $u_1 \otimes v_1 + u_2 \otimes v_2 = u \otimes v$ 인 $u\in U,\, v\in V$ 가 존재해야 한다. $\phi_k (u_i)= \delta_{ik},\,k=1,\,2$ 를 만족하는 $\phi_k\in U^\ast$ 와 $\psi_l (v_j)= \delta_{jl},\, l=1,\,2$ 을 만족하는 $\psi_l \in V^\ast$ 를 생각 할 수 있다. 


$$
(u_1 \otimes v_1 + u_2 \otimes v_2)(\phi_k,\,\psi_l) = (u\otimes v)(\phi_k,\, \psi_l) = \phi_k(u)\psi_l(v)
$$

이어야 한다. 

$$
\phi_1(u)\psi_1(v)=\phi_2(u)\psi_2(v) = 1,\qquad \phi_1(u)\psi_2(v) = \phi_2(u)\psi_1(v) = 0
$$

이어야 하지만 이 조건을 모두 만족시키는건 불가능함을 쉽게 보일 수 있다. 따라서 $X$ 는 $U \otimes V$ 의 부분공간이 아니다.

:::


</br>

## 쌍선형 사상

::: {.callout-note appearance="minimal"}

::: {#def-part3_bilinear_map}

#### 쌍선형 사상
벡터공간 $U,\,V,\,W$ 에 대해 $\Gamma : U \times V \to W$ 가 

&emsp; ($1$) 고정된 $v\in V$ 에 대해 $\chi (u) = \Gamma (u, v) \in \mathcal{L}(U,\,W)$ 이며,

&emsp; ($2$) 고정된 $u\in U$ 에 대해 $\xi (v) = \Gamma (u,\,v) \in \mathcal{L}(V,\,W)$ 이면

$\Gamma$ 를 $U\times V$ 에서 $W$ 로의 **쌍선형 사상(bilinear map)** 이라고 한다. 

:::

:::

</br>

<div class="border" style="background-color:#F2F4F4  ;padding:5px;">

::: {#exm-part3_examples_of_bilinear_map}

1. $\mathfrak{B}(U,\,V)$ 는 $U\times V \mapsto \mathbb{F}$ 인 쌍선형 사상이다.

2. $\Gamma : U \times V \to U\otimes V$ 를 $\Gamma (u,\,v) = u\otimes v$ 로 정의하면 $\Gamma$ 는 $U \times V \mapsto U\otimes V$ 인 쌍선형 사상이다.

3. $\Gamma: \mathcal{L}(V)\times \mathcal{L}(V) \to \mathcal{L}(V)$ 를 $\Gamma(L,\, S) = LS$ 로 정의하면 쌍선형 사상이다.

4. $\Gamma : U \times \mathcal{L}(U,\,V) \to V$ 를 $\Gamma(v,\,,L)= Lv$ 로 정의하면 쌍선형 사상이다. 


:::

</div>

</br>

::: {#thm-part3_bilinear_map_to_linear_map}

유한차원 $\mathbb{F}$-벡터공간 $U,\,V,\,W$ 를 생각하자. 

($1$) 쌍선형 사상 $\Gamma: U\times V \to W$ 에 대해 다음을 만족하는 선형사상 $\hat{\Gamma}: U \otimes W \to U$ 가 유일하게 존재한다.

$$
\forall u\in U,\, v\in V,\qquad \hat{\Gamma}(u \otimes v) = \Gamma (u,v).
$$


($2$) 선형사상 $L:  U\otimes V \to W$ 에 대해 다음을 만족하는 쌍선형 사상 $L^\# : U \times V \to U$ 가 유일하게 존재한다. 

$$
\forall (u,\,v)\in (U, V),\qquad L^\# (u,\,v)= L(u \otimes v)
$$
:::

::: {.proof}

$(e_1,\ldots,\,e_m)$ 이 $U$ 의 기저이고 $(f_1,\ldots,\,f_n)$ 이 $V$ 의 기라고 하자. 

($1$) @prp-linearmap_basis 과 @thm-part3_basis_of_tensor_product ($2$) 에 의해 다음을 만족하는 선형사상 $\hat{\Gamma}(U \otimes V) \to W$ 가 존재한다.

$$
\hat{\Gamma}(e_i \otimes f_j) =  \Gamma(e_i, f_j),\qquad i=1,\ldots,\,m,\,j=1,\ldots,n.
$$

$u\in U,\,v\in V$ 이면 $u=\sum_i a_i e_i,\, v=\sum_j b_j f_j$ 를 만족하는 $\{a_i\},\, \{b_j\}$ 가 유일하게 정해진다. 따라서 다음이 성립한다.

$$
\begin{aligned}
\hat{\Gamma} (u \otimes v) &= \hat{\Gamma} \left(\sum_{i=1}^m \sum_{j=1}^n a_ib_j (e_i\otimes f_j)\right) \\
&= \sum_{i=1}^m \sum_{j=1}^n  a_ib_j\hat{\Gamma}(e_i \otimes f_j) \\
&= \sum_{i=1}^m \sum_{j=1}^n a_ib_j\Gamma (e_i,f_j) = \Gamma (u, v)
\end{aligned}
$$




:::