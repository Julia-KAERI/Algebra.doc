---
title: "내적"
number-sections: true
number-depth : 2
crossref:
  chapters: true
---

## 내적 (Inner product) 과 노름 (norm)

::: {.callout-note appearance="simple" icon="false"}
::: {#def-innerproduct}

#### 내적과 내적 공간

$\mathbb{F}$-벡터공간 $V$ 에서 정의된 $\phi : V \times V \to \mathbb{F}$ 가 모든 $u,\,u',\,v\in V$ 와 $c\in \mathbb{F}$ 에 대해 다음 성질을 만족하면 $\phi$ 를 $V$ 에서 정의된 **내적(Inner product)** 이라 한다.

&emsp; ($1$) $\phi (v,\,v) \ge 0$;

&emsp; ($2$) $\phi (v,\,v) = 0 \iff v = 0$;

&emsp; ($3$) $\phi (u + u', v)  = \phi (u,\, v) + \phi (u',\, v)$;

&emsp; ($4$) $\phi (cu,\,v) = c \phi (u,\,v)$;

&emsp; ($5$) $\phi (v,\, u) = \overline{\phi (u,\,v)}$.

[$x,\,y \in \mathbb{R}$ 에 대해 복소수 $z=x+iy$ 의 켤레복소수 $\overline{z}$ 는 $x-iy$ 이다. 즉 $\overline{x+iy}= x-iy$ 이다.]{.aside}

이것을 만족하는 함수는 어떤 것이든 내적이 될 수 있으며, 내적이 정의된 벡터공간을 **내적 벡터 공간(Inner product vector space)** 혹은 **내적 공간(Inner product space)**라 한다. 필드를 명시할 경우 $\mathbb{F}$-**내적 벡터 공간** 이라고 한다.흔히 두 백터의 내적을 $\langle u,\,v\rangle$ 로 쓰며 그 정의는 위의 $\phi$ 함수에 대해 $\langle u,\, v\rangle = \phi (u,\,v)$ 이다. 
:::
:::


</br>

대표적인 내적 벡터 공간으로는 다음과 같은 것들이 있다.

::: {#exm-innerproduct_R1_C1}
$\mathbb{C}^1$, 즉 1차원 복소벡터공간에서의 내적을

$$
\langle c_1,\, c_2\rangle = c_1\overline{c_2}
$$

로 정의 할 수 있다. $\mathbb{R}^1$ 에서는

$$
\langle r_1,\, r_2 \rangle = r_1r_2
$$

로 정의할 수 있다.
:::

</br>

::: {#exm-euclidean_innerproduct}

#### 유클리드 공간 (Euclidean sapce)

$\mathcal{M}_n(\mathbb{R})$ 에서의 내적을 $\langle \boldsymbol{x},\, \boldsymbol{y} \rangle =  \sum_{i=1}^n x_i y_i$ 로 정의할 수 있으며 이렇게 내적이 정의된 공간을 유클리드 공간이라고 한다. 
:::

</br>

::: {#exm-innerproduct_definded_by_intergration_in_R}

$[0,\,1]$ 구간에서 연속인 실함수로 이루어진 벡터공간에서의 내적을 아래와 같이 정의 할 수 있다.
$$
\langle f,\,g \rangle = \displaystyle \int_0^1 f(x)g(x)\, dx
$$
:::


</br>

::: {#prp-basic_properties_of_inner_product}

$V$ 가 $\mathbb{F}$-내적벡터공간이며 $u,\,v,\,w \in V,\, c \in \mathbb{F}$ 일 때 다음이 성립한다.

&emsp; ($1$) 정해진 $u\in V$ 에 대해 $T(v) = \langle v,\,u \rangle$ 는 선형사상이다.

&emsp; ($2$) $\langle 0,\, u\rangle = 0 = \langle u,\,0\rangle$.

&emsp; ($3$) $\langle u,\, v+w \rangle = \langle u,\, v\rangle + \langle u,\, w \rangle$.

&emsp; ($4$) $\langle u,\,c v\rangle = \overline{c} \langle u,\, v \rangle$.

&emsp; ($5$) $\langle u,\, v \rangle = \overline{\langle v,\, u\rangle}$.
:::

</br>


::: {.callout-note appearance="simple" icon="false"}
::: {#def-orthogonality_of_vector}

#### 벡터의 직교

두 벡터의 내적이 $0$ 일 때 두 벡터는 서로 **직교한다(be orthogonal, be perpendicular)** 고 한다. $\{v_1,\ldots,\,v_n\}$ 의 서로 다른 두 벡터가 모두 직교한다면 $\{v_1,\ldots,\,v_n\}$ 을 직교하는 벡터의 집합이라고 한다. 
:::
:::



</br>

::: {#prp-orthogonal_linearity}
내적벡터 공간 $V$ 에서의 영벡터가 아닌 벡터의 집합 $\{v_1,\ldots,\,v_n\}$ 이 직교하는 벡터의 집합이면 선형 독립이다.
:::
 
::: {.proof}
$\sum_i c_i v_i = 0$ 이라 하자. 선택된 $v_j$ 에 내적을 취하면,

$$
0 = \left\langle \sum c_i v_i,\, v_j \right\rangle = \sum_i c_i \langle v_i,\,v_j \rangle = c_j \langle v_j,\,v_j\rangle
$$

이다. $\langle v_j,\, v_j\rangle >0$ 이므로 $c_1=\cdots = c_n = 0$ 이다. 즉 $\{v_1,\ldots,\,v_n\}$ 은 선형독립이다. $\square$
:::

</br>

이로부터 다음 명제가 자연스럽게 나온다.

::: {#cor-number_of_orthogonal_vectors}
유한차원 내적벡터공간에서 직교하는 벡터의 갯수는 그 차원보다 많을 수 없다.
:::

:::{.proof}
@lem-number_of_basis 를 보라.
:::


</br>

::: {.callout-note appearance="simple" icon="false"}
::: {#def-norm}
#### 노름 (norm)

내적벡터공간에서 벡터의 노름 $\|v\|$ 는 다음과 같이 정의된다.

$$
\|v\| = \sqrt{\langle v,\,v \rangle}
$$
:::
:::


</br>

::: {#prp-properties_of_norm}

내적벡터공간의 norm 에 대해 다음이 성립한다.

&emsp; ($1$) $\|v\|=0 \iff v=0$,

&emsp; ($2$) $\|\lambda v\| = |\lambda | \|v\|$

:::



</br>

### 피타고라스 정리, 코시 슈바르츠 부등식, 삼각 부등식, 평행사변형 공식

::: {#prp-pythagorian}

내적 백터공간 $V$ 의 두 벡터 $u,\,v$ 에 대해 다음이 성립한다. 

&emsp; ($1$) 피타고라스 정리 : $\langle u,\,v \rangle = 0 \implies \|u + v\|^2 = \|u\|^2 + \|v\|^2$.

&emsp; ($2$) 코시-슈바르츠 부등식 :$|\langle u,\,v \rangle | \le \|u\| \|v\|$.

&emsp; ($3$) 삼각부등식 : $\|u+v\| \le \|u\|+ \|v\|$.

&emsp; ($4$) 평행사변형 공식 : $\|u+v\|^2+\|u-v\|^2 = 2\|u\|^2+2\|v\|^2$.
:::

::: {.proof}
($1$) $\|u+v\|^2= \|u\|^2+\|v\|^2+\langle u,\, v\rangle + \langle v,\, u\rangle$ 이므로 $\langle u,\, v\rangle = 0$ 이면 $\|u + v\|^2 = \|u\|^2 + \|v\|^2$ 이다.

($2$) $\|v\|=0$ 일 때는 자명하게 성립한다. $\|v\|\ne 0$ 에 대해

$$
0\le \dfrac{1}{\|v\|^2} {\large \|} \|v\|^2 u - \langle v,\, u\rangle v {\large \|}^2 = \|u\|^2\|v\|^2 -|\langle u,\,v \rangle |^2
$$

이다.

($3$) 코시 슈바르츠 부등식에 따라,
$$
\begin{aligned}
(\|u\|+\|v\|)^2-\|u+v\|^2 = 2(\|u\|\|v\|-\langle u,\, v\rangle) \ge 0 
\end{aligned}
$$

이다. 

($4$) 쉽게 보일 수 있다.
$\square$
:::

</br>

## 정규직교기저

### 기저와 내적

내적벡터공간 $V$ 의 기저 $\{h_i\}$ 를 생각하자. 두 벡터 $u=\sum_i u_i h_i,\, v= \sum_j v_j h_j$ 의 내적은 다음과 같다.

$$
\begin{aligned}
\langle u,\, v\rangle &= \left\langle \sum_i u_i h_i, \sum_j v_j h_j \right\rangle \\
&= \sum_i u_i\left\langle h_i,\, \sum_j v_j h_j \right \rangle \\
&= \sum_{i, j} u_i \overline{v_j} \langle h_i,\, h_j \rangle .
\end{aligned} 
$$ {#eq-innerproduct}


즉 각각의 기저의 쌍에 대한 내적을 알면 벡터의 내적을 계산 할 수 있다. 그런데 만약 서로 다른 두 기저벡터의 내적이 $0$ 이라면, 즉 기저들이 직교한다면 $\|h_i\|^2$ 만을 생각해도 되기 때문에 계산이 쉬워질 것이다. 거기에 더하여 기저벡터의 노름이 모두 1 이라면 더욱 쉬워질 것이다. 이것을 만족하는 기저를 정규직교기저라고 한다.

</br>

### 정규직교기저

::: {.callout-note appearance="simple" icon="false"}

::: {#def-orthonormal_Basis}

#### 정규직교기저 (Orthonormal basis)

내적벡터공간의 벡터의 집합 $\{v_1,\ldots,\,v_n\}$ 의  직교하는 벡터의 집합이며 벡터의 노름이 모두 $1$ 일 때, 즉 $\langle v_i,\,v_j\rangle = \delta_{ij}$ 일 때 **정규직교벡터 (orthonormal vectors)** 라 한다. 정규직교기저벡터가 선형독립임은 @prp-orthogonal_linearity 에서 보았다. 정규직교벡터가 벡터공간의 기저일 때 이 기저를 **정규직교기저 (orthonormal basis)** 라 한다. 
:::
:::


</br>

### 정규직교기저에서의 벡터의 표현

$\{e_1,\ldots,\,e_n\}$ 이 내적벡터공간 $V$의 정규직교기저라고 하자. $v\in V$ 를 이 기저의 선형결합으로 표현하면 아래와 같다고 하자.

$$
v=\sum_i^n c_i e_i
$$

 여기서

$$
\langle v,\,e_j\rangle  = \sum_{i=1}^n c_i \langle e_i,\,e_j\rangle = c_j
$$

이므로,

$$
v =\sum_{i}^n \langle v,\,e_i \rangle e_i
$$

이다.

</br>

### 정규직교기저와 내적



$\mathcal{B}=(e_i)$ 가 내적벡터공간 $V$ 의 정규직교기저이고 두 벡터 $u,\,v$ 가 $u= \sum_i u_i e_i,\, v=\sum_j v_j e_j$ 라 하자. 이 때 두 벡터의 내적은 

$$
\langle u,\, v\rangle = \sum_i \sum_j \langle u_i e_i,\, v_j e_j \rangle = \sum_i \sum_j u_i \overline{v_j} \langle e_i,\, e_j\rangle= \sum_i u_i \overline{v_j}
$$

이다. 이것을 @eq-innerproduct 와 비교해보면 얼마나 간단해졌는지 느낄 수 있을 것이다. 정규직교기저인 $\mathcal{B}$ 에서의 행렬표현은 $\boldsymbol{u}=[u]_\mathcal{B}= \begin{bmatrix} u_1 \\ \vdots \\ u_n\end{bmatrix}$ $\boldsymbol{v} = [v]_\mathcal{B}= \begin{bmatrix} v_1 \\ \vdots \\ v_n\end{bmatrix}$ 이며 이때의 내적은 $\boldsymbol{v}^\ast \boldsymbol{u}$ 이다. $V$ 가 $\mathbb{R}$-벡터공간 일 때 내적은 $\boldsymbol{v}^T\boldsymbol{u}$ 이다.

</br>

### 정규직교기저벡터에 대한 연산자의 행렬 표현

$T\in \mathcal{L}(V)$ 라 하자. $\mathcal{B}=(e_i)$ 이 정규직교기저벡터일 때 $T$ 는

$$
T(e_j) = \sum_{k=1}^n A_{kj}e_k
$$

라 하자.

$$
\langle T(e_j),\, e_i\rangle = \sum_{k=1}^n \langle A_{kj}e_k,\, e_i\rangle = \sum_{k=1}^n A_{kj} \langle e_k,\, e_i\rangle = A_{ij}
$$

이다. 즉,

$$
A_{ij} = \langle T(e_j),\, e_i \rangle
$$

이다.

</br>


정규직교기저를 이용하면 내적이나 행렬 계산을 포함한 많은 것이 편해진다. 그렇다면 당연한 질문을 던질 수 있다. 어떤 조건에서 정규직교기저를 얻을 수 있는가? 답은 언제나이다. 내적벡터공간에서는 어떤 기저든 한 기저를 구했다면 그 기저를 바탕으로 정규직교기저를 얻을 수 있다. 한 기저에서 정규직교기저를 구하는 방법은 여러가지가 있지만 그중에서 한가지를 알아보도록 하자.


</br>

## 그람-슈미트 과정과 정규직교기저


### 벡터에 대한 정사영 (Projection)

두 벡터의 내적이 $0$ 일 때 두 벡터는 직교한다(be perpendicular)고 하며, 한 벡터가 다른 벡터의 스칼라곱일 때 두 벡터가 **평행하다(be parallel)** 고 한다. 내적벡터공간 $V$ 의 두 벡터 $u,\,v$ 가 주어졌다고 하자. 이 때 $v$ 의 $v$ 에 대한 사영연산자 $\text{Proj}_u v$ 를 아래와 같이 정의하자.

$$
\text{Proj}_{u}v = \dfrac{\langle v,\, u\rangle}{\langle u,\, u\rangle} u
$$

$\text{Proj}_u v$ 는 $u$ 에 평행하며 ($u$ 의 스칼라곱이니 당연하다), $v-\text{Proj}_u v$ 는 $v$ 에 직교한다. 즉

$$
\langle  v , \,v-\text{Proj}_{u} v \rangle  = 0
$$

이다. $v = \text{Proj}_u v + (v - \text{Proj}_u v)$ 이므로 $v$ 를 $u$ 에 대해 수직한 벡터와 평행하는 벡터의 합으로 표현 할 수 있다.

</br>

### 그람-슈미트 과정 (Gram-Schmidt Process)

그람-슈미트 과정을 통해 유한차원 내적 벡터공간에서 주어진 독립 벡터를 이용하여 같은 갯수의 정규 직교 벡터를 얻을 수 있다. $n$ 차원 내적 벡터 공간 $V$ 에서 $m$ 개의 독립벡터 $\{v_1,\ldots,v_m\}$ 이 주어졌다고 하자. (당연히 $m \le n$ 이다). 정규직교벡터의 집합 $\{e_1,\ldots,\,e_m\}$ 을 그람-슈미트 과정을 수행하여 얻을 수 있다. 그람-슈미트 과정을 귀납적으로 표현하면 다음과 같다.

::: {.callout-tip title="그람-슈미트 과정" appearance="minimal"}
$1$. 우선 $u_1 =  v_1$, $e_1 = \dfrac{u_1}{\|u_1\|}$ 라 한다.

$2$. 우리가 $u_1,\ldots,\,u_{k-1}$ 을 얻었을 때 (즉, $e_1,\ldots,e_{k-1}$ 을 얻었을 때) $u_k$ 와 $e_k$ 는 다음과 같이 얻는다.  

$$
u_k = v_{k} - \sum_{j=1}^{k-1} \text{Proj}_{e_j} v_k = v_k-\sum_{j=1}^{k-1} \left\langle v_k,\, e_j \right\rangle e_j,\qquad e_k = \dfrac{u_k}{\|u_k\|} \;.
$$

:::


</br>

이제 이렇게 해서 얻은 $\{e_1,\ldots,\,e_m\}$ 이 정규직교벡터의 집합이라는 것을 보이자.

</br>

::: {#lem-gram_schmidt}
위 과정을 통해 얻은 $\{e_1,\ldots,\,e_m\}$ 은 orthonomal 하다. 즉, $\langle e_i,\, e_j\rangle = \delta_{ij}$ 이다.
:::

::: {.proof}
$e_k = \dfrac{u_k}{\|u_k\|}$ 로 정의되었으므로 $\|e_k\|^2=1$ 이다. 따라서 $i\ne j$ 일 때 $\langle e_i,\, e_j\rangle = 0$ 임을 보이면 된다. 수학적 귀납법을 통해 보일 것이며 우선 $\langle u_2,\,u_1\rangle = 0$ 임을 보이자.

$$
\begin{aligned}
\langle u_2,\, u_1 \rangle &= \langle v_2- \langle v_2,\, e_1\rangle e_1,\, v_1 \rangle  = \langle v_2,\,v_1\rangle - \langle v_2,\,e_1 \rangle \langle e_1,\, v_1\rangle \\
&= \langle v_2,\,v_1\rangle - \dfrac{1}{\|v_1\|} \langle v_2,\,v_1\rangle \|v_1\| = 0
\end{aligned}
$$

이다. 이제 $u_{k}$ 는 $u_1,\ldots,\,u_{k-1}$ 와 모두 직교한다고 가정하자. 임의의 $j\le k$ 에 대해,

$$
\begin{aligned}
\langle u_{k+1},\, u_j\rangle  &= \left\langle v_{k+1}- \sum_{i=1}^{k} \langle v_{k+1},\, e_i\rangle e_i,\, \|u_j\|e_j \right\rangle \\
&= \|u_j\| \langle v_{k+1},\, e_j\rangle  - \|u_j\| \sum_{i=1}^k \langle v_{k+1},\, e_i \rangle \langle e_i,\, e_j\rangle \\
&= \|u_j\| \langle v_{k+1},\,e_j\rangle -\|u_j\|\sum_{i=1}^{k} \langle v_{k+1},\, e_i\rangle \delta_{ij} \\
&= \|u_j\| \langle v_{k+1},\,e_j\rangle -\|u_j\| \langle v_{k+1},\,e_j\rangle  = 0.
\end{aligned}
$$

이다. 따라서 $\{e_1,\ldots,\,e_m\}$ 은 orthonormal 하다. $\square$
:::


</br>

이제 우리는 다음의 중요한 결론을 얻는다.

::: {#thm-orthonormal_basis}
$V$ 가 유한차원 내적벡터공간이며 $\mathcal{B}_V= (v_i)$ 가 $V$ 의 기저일 때 $\mathcal{B}_V$ 로부터 정규직교기저를 얻을 수 있다.
:::


::: {.proof}
$\mathcal{B}_V$ 는 선형독립이므로 Gram-Schmidt 과정을 통해 얻은 정규직교벡터는 $V$ 의 정규직교기저이다. $\square$

:::

</br>

그람-슈미트 과정은 내적벡터공간에 기저가 주어지면 이 기저의 선형결합으로 정규직교기저를 얻을 수 있음을 보장한다. 우리는 앞서 @thm-uppertriangular_matrix_complex_field 에서 유한차원 $\mathbb{C}$-벡터공간에서의 모든 연산자는 어떤 기저에서 상삼각 행렬로 표현된다는 것을 보였다. 유한차원 $\mathbb{C}$-내적벡터공간에서는 정규직교기저에대해 상삼각 행렬로 표현되는 것을 보이자.

</br>


::: {#thm-schure}

#### 슈어 정리 (Schur's Theorem)

유한차원 $\mathbb{C}$-내적벡터공간 $V$ 에서 정의된 연산자 $T\in \mathcal{L}(V)$ 는 어떤 정규직교기저에서 상삼각행렬로 표현된다.
:::

::: {.proof}
$V$ 를 $n$ 차원 $\mathbb{C}$-내적벡터공간이라 하자. @thm-uppertriangular_matrix_complex_field 에서 $T\in \mathcal{L}(V)$ 는 어떤 기저 에서 상삼각행렬로 표현된다는 것을 보였다. 이 기저를 $\mathcal{B}_V = \{v_1,\ldots,\,v_n\}$ 이라 하고, 그람-슈미트 과정을 통해 얻은 정규직교기저를 $\{e_1,\ldots,\,e_n\}$ 이라 하자. 즉 $e_i \in \text{span}(v_1,\ldots,\,v_i)$ 이다. 그렇다면, 그람 슈미트 과정으로부터

$$
\text{span}(e_1,\ldots,\,e_j) = \text{span}(v_1,\ldots,\,v_j), \quad j=1,\ldots, n
$$

임을 안다. $T$ 가 $\mathcal{B}_V$ 에서 상삼각 행렬로 표현되므로 $T(v_i) \in \text{span}(v_1,\ldots,\,v_i)$ 이며, 따라서

$$
T(v_i) \in \text{span}(v_1,\ldots,\,v_i) = \text{span}(e_1,\ldots,\,e_i)
$$

이다. 즉 $T$ 는 정규직교기저에서 상삼각 행렬로 표현된다. $\square$
:::

</br>

::: {.callout-important}

내적벡터공간에서 항상 정규직교기저를 구할 수 있으며, 정규직교기저에서 여러 계산이 편해지기 때문에 정규직교기저를 가정하고 문제를 푸는 경우가 많다.

:::

<br>



::: {#thm-Reisz_representaion_theorem}
### Riesz 의 표현 정리 (Reisz Representation theorem)

유한차원 내적벡터공간 $V$ 에서 정의된 선형 범함수 $\varphi$ 는 어떤 벡터 $u\in V$ 에 대한 내적으로 표현 될 수 있다. 즉,

$$
\varphi (v) = \langle v,\, u\rangle
$$

이다.
:::

::: {.proof}
$\{e_1,\ldots,\,e_n\}$ 이 $V$ 의 정규직교기저라 하자. 그렇다면,

$$
\begin{aligned}
\varphi (v) &= \varphi \left(\sum_i a_i e_i\right) = \sum_i a_i \varphi(e_i) = \sum_i \langle v_i,\,e_i\rangle  \varphi(e_i) \\ 
&= \sum_i \langle v_i,\, \overline{\varphi (e_i)}e_i \rangle \\ 
&= \left\langle v_i,\, \sum_i \overline{\varphi(e_i)} \, e_i \right\rangle
\end{aligned}
$$

이므로, $u = \sum_i \overline{\varphi (e_i)}e_i$ 로 잡으면 된다. $\square$

:::

</br>


## 직교 여공간 (Orthogonal complement) 과 Orthogonal projection

::: {.callout-note appearance="simple" icon="false"}
::: {#def-orthogonal_complement}

#### 직교 여공간

벡터공간 $V$ 의 부분집합 $U$ 에 대해 $U$ 전체 원소에 대해 수직인 벡터의 집합은 벡터공간을 이루며 이를 $U$ 에 대한 **직교 여공간 (orthogonal complement)** 이라 하고 $U^\perp$ 라 쓴다. 즉,

$$
U^\perp = \{ v\in V : \langle v,\, u\rangle = 0 \text{ for every }u\in U\}
$$

이다.
:::
:::

</br>

다음은 쉽게 보일 수 있다.

::: {#prp-orthogonal_complement_is_a_vector_space}
$V$ 의 부분집합 $U$ 에 대해 $U^\perp$ 는 $V$ 의 부분벡터공간이다.
:::

</br>

직교 여공간의 중요한 성질은 다음과 같다.

::: {#prp-properties_of_orthogonal_complement}
직교 여공간에 대해서는 다음이 성립한다.

&emsp; ($1$) $\{0_V\}^\perp = V$,

&emsp; ($2$) $V^\perp = \{0_V\}$,

&emsp; ($3$) $U \cap U^\perp  \subset \{0\}$,

&emsp; ($4$) $U\subset W \implies W^\perp \subset U^\perp$,

&emsp; ($5$) $(U^\perp)^\perp = \langle U \rangle$.
:::

::: {.proof}
($4$) 에 대해서만 증명한다 $v\in W^\perp$ 이면 $v$ 가 모든 $W$ 의 집합에 대해 수직하므로 $U\subset W$ 인 모든 $u\in U$ 에 대해서도 수직하다. 따라서 $v \in U^\perp$ 이다. 즉 $W^\perp \subset U^\perp$ 이다. $\square$
:::

</br>

@sec-generated_subspace 에서 다뤘던 생성된 부분공간 $\langle U \rangle$ 를 생각하자. 우리는 다음을 보일 수 있다.

::: {#prp-generated_subspace_and_orthogonal_compliment}

유한차원 벡터공간 $V$ 의 부분집합 $U$ 에 의해 생성된 부분공간 $\langle U \rangle$ 에 대해 다음이 성립한다.

&emsp; ($1$) $\langle U \rangle \cap U^\perp = \{0_V\}$, 

&emsp; ($2$) $V = \langle U \rangle \oplus U^\perp$,

&emsp; ($3$) $\dim (V) = \dim (\langle U \rangle) + \dim (U^\perp)$

:::


::: {.proof}
$\langle U\rangle$ 의 정규직교기저를 찾아 $\{e_1,\ldots,\,e_n\}$ 이라 하고 이 기저를 확장하여 나머지 정규직교기저를 $\{f_1,\ldots,\, f_m\}$ 이라 하자. $\{f_1,\ldots,\,f_m\}$ 의 선형결합은 $U$ 와 직교하므로 $U^\perp$ 에 포함된다. $U^\perp$ 의 어떤 벡터가 $\{e_i\}$ 기저 성분을 포함한다면 $U$ 와 직교할수 없다. 따라서 $U^{\perp} = \text{span} (f_1,\ldots,f_m)$ 이다. 이를 이용하면 세가지를 모두 보일 수 있다. $\square$
:::

</br>

### Orthogonal projection


::: {.callout-note appearance="simple" icon="false"}
::: {#def-projection_operator}

#### Projection

연산자 $P\in \mathcal{L}(V)$ 가 $P^2=P$ 일 때 $P$ 를 **projection** 이라 한다.

:::
:::

예를 들어 $T\in \mathcal{L}(\mathbb{R}^2)$ 이 $T(x,\,y) = (x, 0)$ 으로 정의되었다고 하자. $T$ 는 선형사상이며 $T^2(x,\,y)= (x,\,0) = T(x,\,y)$ 이므로 $T$ 는 projection 이다. 이처럼 projectiion 은 우리가 기하학적으로 생각하는 그 projection 을 추상화 한 것이다.

</br>

::: {#prp-uniqueness_of_orthogonal_decomposition}

유한차원 벡터공간 $V$ 가 부분공간 $U$ 에 대해 $V=U \oplus U^\perp$ 이다. 이 때 $v\in V$ 는 어떤 $u\in U$ 와 $w\in U^\perp$ 에 대해 $v = u+w$ 로 나타낼 수 있으며, 이를 만족하는 $u,\,w$ 는 유일하다.

:::

::: {.proof}
@prp-generated_subspace_and_orthogonal_compliment 의 증명에서 보인 대로 $U$ 의 정규직교기저 $\{e_1,\ldots,\,e_n\}$ 과 $U^\perp$ 의 정규직교 기저 $\{f_1,\ldots,\,f_m\}$ 에 대해 $u = \sum_i a_i e_i + \sum_j b_j f_j$ 를 만족하는 $a_i,\, b_j$ 가 존재한다. $u= \sum_i a_i e_i$ 이며 $w=\sum_j b_j f_j$ 이다. 이 때 $u,\,w$ 가 유일하게 정해진다는 것은 자명하다. $\square$

:::

</br>

@prp-uniqueness_of_orthogonal_decomposition 에서 보인 것처럼 $v\in V$ 가 $u+w$ 라면 $P_U(v)=u$ 인 함수를 생각 할 수 있다. 이 $P_U$ 는 잘 정의되는 함수이며 선형연산자이다.

::: {#exr-orthogonal_projection_linear_operator}
위에서 정의된 함수 $P_U : V \to V$ 가 선형연산자임을 보이고, projection 임을 보여라. 그리고 $\text{im}(P_U)= U$ 임을 보여라.
::: 

::: {.proof}
$v_1,\,v_2\in V$ 에 대해 $v_1 = u_1+w_1,\, v_2=u_2+w_2$, $u_1,\, u_2\in U$, $w_1,\,w_2 \in U^\perp$ 라 하자. 

$$
P_U(v_1+\lambda v_2) = u_1+ \lambda u_2 = P_U (v_1)+ \lambda P_U (v_2)
$$

이므로 선형연산자이다. 또한

$$
P_U^2 (v_1) = P_U(u_1)= u_1 = P_U (v_1)
$$

이므로 $P$ 는 projection 이다.

$P_U$ 의 정의에 의해 $\text{im}(P_U) \subset U$ 이다. 임의의 $u\in U \le V$ 에 대해 $P_U (u)=u$ 이므로 $U \subset \text{im}(P_U)$ 이다. 따라서 $\text{im}(P_U) = U$ 이다. $\square$ 

:::

</br>

::: {.callout-note appearance="simple" icon="false"}
::: {#def-orthogonal_projection}
#### Orthogonal projection

@prp-uniqueness_of_orthogonal_decomposition 에서 정의된 $P_U$ 를 $V$ 에 대한 $U$ 로의 **orthogonal projection** 이라 한다.

:::
:::

</br>

::: {#prp-properties_of_orghogonal_projection}
$U$ 가 $V$ 의 유한차원 부분벡터공간 일 때 다음이 성립한다. 증명은 쉬우므로 생략한다.

&emsp; ($1$) $u \in U \implies P_U (u) = u$.

&emsp; ($2$) $w \in U^\perp \implies P_U(w) = 0$.

&emsp; ($3$) $\ker (P_U) = U^\perp, \,\text{im}(P_U) = U$.

&emsp; ($4$) $v-P_U (v) \in U^\perp$.

&emsp; ($5$) $P_U^2 = P_U$.

&emsp; ($6$) $\|P_U (v) \| \le \|v\|$.
:::

</br>

### 부분공간까지의 거리

$U$ 가 $V$ 의 부분공간일 때 $v\in V$ 로부터 $U$ 까지의 거리 $\|v-U\|$ 는

$$
\|v-U\| = \min \{\|v-u\|,\, u\in U\} 
$$

로 정의된다.

</br>

::: {#prp-distance_to_subspace}
$V$ 가 유한차원 내적벡터공간이고 $v\in V$, 이며 $U$ 가 $V$ 의 부분공간일 때, $v$ 에서 $U$ 까지의 거리는 $v$ 에서 $P_U (v)$ 까지의 거리와 같다. 즉, 

$$
\|v-U\| = \|v-P_U(v)\|
$$

이다.
:::

::: {.proof}

임의의 $u\in U$ 에 대해 $\|v-P_U (v)\| \le \|v-u\|$ 임을 보이면 된다. $\|P_Uv - u\| \ge 0$ 이므로,

$$
\begin{aligned}
\|v-P_U (v) \|  &\le \|v-P_U (v) \| +\|P_U(v) - u\| \qquad & &; \|P_U(v) - u\| \ge 0\\
&\le\|v-u\| & &; \text{Triangle inequality}
\end{aligned}
$$

이다. $\square$
:::

</br>

## 연습문제

::: {#exr-axler_6_A_5}
#### Axler 6.A.5

$T\in \mathcal{L}(V)$ 이며 모든 $v\in V$ 에 대해 $\|T(v)\|\le \|v\|$ 이다. 이 때 $T-\sqrt{2}I$ 는 가역임을 보여라.

:::

::: {.solution}

$(T-\sqrt{2}I)(v)=0_V$ 라 하자. $v\ne 0_V$ 이면 $\|\sqrt{2}I(v)\|=\sqrt{2}\|v\| > \|v\| \ge \|T(v)\|$ 이므로 성립하지 않는다. $\ker (T-\sqrt{2}I)=\{0_V\}$ 이므로 가역이다.
::: 

</br>

::: {#exr-axler_6_A_6}
#### Axler 6.A.6

$u,\,v\in V$ 일 때 $\langle u,\,v\rangle=0$ 일 필요충분조건은 모든 $a\in \mathbb{F}$ 에 대해 $\|u\| \le\|u+av\|$ 임을 보여라.

:::

::: {.solution}
$\langle u,\,v\rangle =0$ 이면 $\|u+av\|^2-\|u\|^2 = |a|^2\|v\|^2 \ge 0$ 이다.  따라서 $\|u+av\| \ge \|u\|$ 이다.

모든 $a\in \mathbb{F}$ 에 대해 $\|u\|\le \|u+av\|$ 라고 하자.

$$
\|u+av\|^2-\|u\|^2 = a\langle v,\,u\rangle + \overline{a}\langle u,\,v\rangle + |a|^2 \|v\|^2 \ge 0
$$

이어야 한다. $u,\,v$ 에 대해 $a=t\|v\|\langle u,\,v\rangle$ 이라 놓을 수 있다. 이 때 $t\in \mathbb{R}$ 이라 하자.

$$
0\le \|u+av\|^2-\|u\|^2 = (2t\|v\| - t^2\|v\|^2) |\langle u,v\rangle |^2
$$

이어야 하는데 $t > \|v\|$ 이면 위배된다. 따라서 $\langle u,\,v\rangle = 0$ 이어야 한다. 

:::

</br>

::: {#exr-axler_6_A_9}

#### Axler 6.A.9

$u,\,v\in V$ 이고 $\|u\|\le 1$ 이며 $\|v\|\le 1$ 이면 다음이 성립함을 보여라.

$$
\sqrt{1-\|u\|^2}\sqrt{1-\|v\|^2} \le 1-|\langle u,\,v\rangle |.
$$

:::

::: {.solution}

우선 $\|u\|^2+\|v\|^2 \ge 2\|u\|\|v\|$ 임을 안다. 또한 $\|u\|\|v\| \ge |\langle u,\,v\rangle|$ 임을 안다.

$$
\begin{aligned}
(1-\|u\|)^2 (1-\|v\|^2) &= 1-\|u\|^2-\|v\|^2 + \|u\|^2\|v\|^2  \\
&\le 1-2\|u\|\|v\| + \|u\|^2\|v\|^2 \\
&= (1-\|u\|\|v\|)^2 \le (1-|\langle u,\,v\rangle |)^2.
\end{aligned}
$$

:::


</br>

::: {#exr-axler_6_A_11}

#### Axler 6.A.11

양수 $a,\,b,\,c,\,d$ 에 대해 다음이 성립함을 보여라.

$$
16 \le (a+b+c+d) \left( \dfrac{1}{a}+\dfrac{1}{b}+\dfrac{1}{c}+\dfrac{1}{d} \right)
$$

:::

::: {.solution}

$x,\,y\in \mathbb{R}^4$ 이며 $x=(\sqrt{a},\,\sqrt{b},\,\sqrt{c},\,\sqrt{d})$, $y=(1/\sqrt{a},\,1/\sqrt{b},\,1/\sqrt{c}\,1/\sqrt{d})$ 라 하면, $|\langle x,\,y\rangle|^2 \le \|a\|^2\|b\|^2$ 이므로, 

$$
4^2=16 \le  (a+b+c+d) \left( \dfrac{1}{a}+\dfrac{1}{b}+\dfrac{1}{c}+\dfrac{1}{d} \right).
$$

:::

</br>

::: {#exr-axler_6_A_18}

#### Axler 6.A.18

$p>0$ 라고 하자. $\mathbb{R}^2$ 에서 노름이 $\|(x,\,y)\| = (x^p+y^p)^{1/p}$ 가 되도록 하는 노름은 $p=2$ 일 때만 존재함을 보여라.

:::

::: {.solution}

$u=(1, 0), v=(0, 1)$ 이라 하자. $\|u+v\|^2+\|u-v\|^2 = 2\|u\|^2+2\|v\|^2$ 이므로, $2 + (1+(-1)^p)^{2/p}= 4$ 이어야 한다. 즉 $1+(-1)^p = 2^{2/p}$ 이어야 하며, 이를 만족하는 $p$ 는 $2$ 뿐이다.

:::

</br>

::: {#exr-axler_6_a_21}

#### Axlwer 6.A.21

벡터공간에서의 노름 함수 $\|\,\| : U \to [0,\infty)$ 는 $u,\,v\in U,\,a\in \mathbb{F}$ 에 대해 다음의 성질을 만족하는 함수이다.

- $\|u\| = 0 \iff u=0_U$, 
- $\|a u\| = |a|\|u\|$, 
- $\|u+v\| \le \|u\| + \|v\|$
  
만약 노름함수가 평행사변형 공식 $\|u+v\|^2+\|u-v\|^2=2\|u\|^2+2\|v\|^2$ 를 만족한다면 노름에 상응하는 내적이 존재함을 보여라. 즉 어떤 내적이 존재하여 $\langle u,\,u\rangle = \|u\|^2$ 를 만족한다.

:::

::: {.solution}

$U$ 가 $\mathbb{R}$-벡터 공간일 때만 보이기로 한다. 함수 $\phi : U \times U \to \mathbb{F}$ 를 

$$
\phi (u, v)= \dfrac{\|u+v\|^2-\|u-v\|^2}{4}
$$

로 정의하고 @def-innerproduct 의 5가지 성질을 만족함을 보이자.

($1$) $\phi (u, u)=\|u\|^2 \ge 0$ 이다.

($2$) $\phi(u, u)=\|u\|^2=0 \iff u=0_U$ 이다.

($3$) $\phi (u+u',v)=\phi (u, v) + \phi (u', v)$ 임을 보이자. 우선 평행사변형 공식으로 부터

$$
\|u-v\|^2 = 2\|u\|^2+2\|v\|^2-\|u+v\|^2
$$ 

임을 안다. 이를 이용하면

$$
\begin{aligned}
\phi(u+u',v) &= \dfrac{1}{4} \left[\|u+u'+v\|^2 -\|u+u'-v\|^2\right]\\
&=  \dfrac{1}{4} \left[ -\|u-u'+v\|^2+2\|u+v\|^2+2\|u'\|^2 - \|u+u'-v\|^2\right]\\
&=  \dfrac{1}{4} \left[ -2\|u\|^2 -2\|u'-v\|^2 +2\|u+v\|^2+2\|u'\|^2 \right] \\
&= \dfrac{1}{2} \left[ \|u+v\|^2 + \|u'+v\|^2-\|u\|^2-\|u'\|^2 -2\|v \|^2\right] \\
\phi(u,v) + \phi(u', v) &=\dfrac{1}{4} \left[\|u+v\|^2-\|u-v\|^2+\|u'+v\|^2-\|u'-v\|^2\right] \\
&= \dfrac{1}{4} \left[2\|u+v\|^2 - 2\|u\|^2-2\|v\|^2 + 2\|u'+v\|^2 -2\|u'\|^2-2\|v\|^2\right]\\
&= \dfrac{1}{2} \left[ \|u+v\|^2 +\|u'+v\|^2 -\|u\|^2 -\|u'\|^2 - 2\|v\|^2\right] \\
\end{aligned}
$$

이므로 $\phi (u+u',v) = \phi(u,v)+\phi(u', v)$ 이다. 


($4$) 이제 $c\in \mathbb{R}$ 에 대해 $\phi(cu,v)= c\phi(u, v)$ 임을 보이자. 우선 $c\in \mathbb{Z}_+$ 일 때 induction 을 통해 보인다. $c=1$ 일 때는 자명하다. $c$ 일 때 성립함을 가정하면 ($3$) 의 결과를 이용해 

$$
\phi((c+1)u, v) = \phi (cu, v)+ \phi (u, v)  = c\phi (u, v)+ \phi (u, v)= (c+1)\phi(u, v)
$$

임을 안다. 즉 $c\in \mathbb{Z}_+$ 일 때 $\phi (cu, v)=c\phi (u, v)$ 이다.

:::