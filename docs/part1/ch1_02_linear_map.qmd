---
title: "선형사상"
number-sections: true
number-depth : 3
crossref:
  chapters: true
---

우리는 앞서 벡터공간과 기저, 차원에 대해 알아보았다. 이제 벡터공간에 대한 함수가운데 가장 기본적이며 중요한 함수인 선형사상에 대해 알아보려 한다.

</br>

## 선형사상의 정의과 기본적인 성질

### 선형사상

::: {.callout-note appearance="simple" icon="false"}
::: {#def-linear_map}
#### 선형사상/선형변환

$\mathbb{F}$-벡터공간 $U,\,V$ 에 대해 정의된 함수 $L: U \to V$ 이 모든 $u_1,\,u_2\in U,\, c\in \mathbb{F}$ 에서 다음을 만족하면 $L$ 을 $U$ 에서 $V$ 로의 **선형 사상(linear map)** 혹은 **선형 변환 (linear transformation)** 이라 한다. 

$$
L(u_1+ c u_2) = L(u_1) + c L(u_2).
$$

또한 $\mathbb{F}$-벡터공간 $U,\,V$ 에 대해 $U\mapsto V$ 인 선형사상의 집합을 $\mathcal{L}(U,\,V)$ 라고 쓴다.
:::
:::


</br>

::: {#exm-zero_map}

함수 $L:U \to V$ 가 모든 $u\in U$ 에 대해 $L(u)=0_V$ 일 때 이 $L$ 를 **영사상(zero map)** 이라 부르며 $0(u)$ 와 같이 표기한다. 영사상이 선형사상임을 보여라.

:::

</br>

::: {#exm-T_zero}
$L\in \mathcal{L}(U,\,V)$ 일 때 $L(0_U) = 0_V$ 임을 보여라.
:::

</br>

::: {#exm-negative_map}

$L\in \mathcal{L}(U,\,V)$ 에 대해 $L(u)=v$ 이면 $L(-u)=-v$ 임을 보여라.

:::

</br>

::: {.callout-note appearance="simple" icon="false"}
::: {#def-operator}
#### 연산자
자기 자신으로의 선형변환은 특별히 **선형 연산자(Linear operator)** 혹은 **연산자(Operator)** 라 하며 벡터공간 $V$ 에서의 선형 연산자의 집합을 $\mathcal{L}(V)$ 라 쓴다.
:::
:::

</br>

::: {#exm-derivative_integral_as_operator}

실수 전체 구간에서 무한번 미분 가능한 $\mathbb{R} \mapsto \mathbb{R}$ 실함수의 집합을 $C_\mathbb{R}^{\infty}$ 라고 한다. $C_\mathbb{R}^\infty$ 는 $\mathbb{R}$-벡터공간임을 쉽게 보일 수 있다. $f\in C_\mathbb{R}^{\infty}$ 에 대한 미분연산자를 $\mathcal{D}$ 라고 하자. 즉 $(\mathcal{Df})(x)= f'(x)$ 이다. $f,\,g\in C_\mathbb{R}^\infty,\, c\in \mathbb{R}$ 에 대해 $\mathcal{D}(f+cg) = f'+cg'\in C_\mathbb{R}^\infty$ 이므로 $\mathcal{D} \in \mathcal{L}(C_\mathbb{R}^\infty)$ 이다. 또한 $\mathcal{I}:C_\mathbb{R}^\infty \to C^\infty$ 를 $(\mathcal{I}f)(x)=\int_{0}^x f(x)\,dx$ 로 정의하자. $\mathcal{I}\in \mathcal{L}(C_\mathbb{R}^\infty)$ 임을 알 수 있다.

:::



</br>

보통 두 집합 $A,\,B$ 사이의 함수 $f:A\to B$ 가 정의된다는 것은 모든 $a\in A$ 에 대해 $f(a) \in B$ 가 잘 정의된다는 것을 뜻한다. 그러나 벡터공간에서 정의된 선형 사상은 모든 벡터에 대해 알 필요 없이 기저에 대해서만 함수값을 알면 그 함수가 정의된다. 다음 명제는 그것을 증명한다.

</br>

::: {#prp-linearmap_basis}

유한차원 벡터공간 $U$ 의 기저 $\{u_1,\ldots,\,u_n\}$ 와 벡터공간 $V$ 를 생각하자. $v_1,\ldots,\,v_n\in V$ 에 대해 

$$
L(u_i) = v_i
$$

를 만족하는 선형사상 $L:U \to V$ 는 존재하며 유일하다.
:::

::: {.proof}
$u\in U$ 는 $\{u_1,\ldots,u_n\}$ 의 선형결합으로 유일하게 표현된다. $u= a_1 u_1 + \cdots + a_n u_n$ 와 $\{v_1,\ldots,\,v_n\}\subset V$ 에 대해 함수 $L:U \to V$ 를 다음과 같이 정의하자.

$$
L(u)=L(a_1u_1 + \cdots + a_n u_n) = a_1v_1 + \cdots + a_n v_n
$$

이 함수 $L$ 은 잘 정의된다. 즉 $u\in U$ 가 정해진다면 $L(u)$ 도 확실하게 정해진다. 이제 $L$ 이 선형사상임을 보이자. $u' = b_1 u_1 + \cdots + b_n u_n \in U,\, c\in \mathbb{F}$ 일 때

$$
\begin{aligned}
L(u+ c u') &= L((a_1 + c b_1)u_1 + \cdots + (a_n + c b_n) u_n) \\
&= (a_1+c b_1)v_1 + \cdots + (a_n + c b_n)v_n \\ 
&= a_1v_1 + \cdots a_n v_n + c (b_1 v_1 + \cdots + b_n v_n) \\
&= L(u) + c L(u') \\ 
\end{aligned}
$$

이므로 $L$ 는 선형사상이다. 이제 유일하게 존재함을 보이자. $K\in \mathcal{L}(U,\,V)$ 가 $K(u_i)=v_i$ 라 하자. $K$ 가 선형사상이므로

$$
K(a_1u_1 + \cdots + a_n u_n) = a_1 v_1 + \cdots + a_n v_n
$$

이다. 즉 $L=K$ 이므로 주어진 조건을 만족하는 선형사상은 유일하다. $\square$
:::

</br>


::: {#exm-identity_operator}

#### 항등사상
$I_U\in \mathcal{L}(U)$ 일 때 모든 $u\in u$ 에 대해 $I_U(u) = u$ 이면 $I_U$ 를 벡터공간 $U$ 에서의 **항등 사상 (identity operator)** 이라고 한다. 항등사상은 선형사상임을 보여라. 또한 $L\in \mathcal{L}(U)$ 일 때 다음 두 명제가 동치이다.

&emsp; ($1$) $L$ 은 항등사상이다.

&emsp; ($2$) $U$ 의 기저 $\{u_i\}$ 에 대해 $L(u_i) = u_i,\, i=1,\,2,\ldots$ 이다.

:::

</br>

::: {.callout-note appearance="simple" icon="false"}
::: {#def-restriction}

#### 한정 사상

$L\in \mathcal{L}(V,\,W)$ 이고 $U \le V$ 라 하자. 이 때 $L$ 의 정의역(domain) 을 $U$ 로 제한하는 $L|_U\in \mathcal{L}(U,\,W)$ 를 생각할 수 있다. 즉, $L|_U(u)=L(u)$ 이며 이것을 **한정 사상(restriction)** 이라 한다.

:::
:::

</br>

### 선형사상의 합과 스칼라곱

앞서 벡터공간 $U,\,V$ 사이의 선형사상의 집합을 $\mathcal{L}(U,\,V)$ 로 표기한다고 하였다. 어떤 특별한 이름이나 표기법을 사용한다는 것은 그것이 매우 중요하다는 것을 뜻한다. $\mathcal{L}(U,\,V)$ 는 왜 이런 특별한 표기를 할까? 그것은 $\mathcal{L}(U,\,V)$ 에 적절한(혹은 합리적인, 납득할만한) 덧셈과 스칼라곱 규칙을 부여하면 [뭔가](ch1_01_vectorspace.qmd#벡터공간과 벡터)가 되기 때문이다. 

</br>

::: {.callout-note appearance="simple" icon="false"}
::: {#def-sum_prod_linear_map}
#### 선형사상의 합과 스칼라곱

$\mathbb{F}$-벡터공간 $U,\,V$ 와 $L,\,K\in \mathcal{L}(U,\,V),\, u\in V,\, c \in \mathbb{F}$ 에 대해, 선형사상의 합과 스칼라곱은 다음과 같이 정의된다.

$$
\begin{aligned}
(L+K)(u) & := L(u) + K(u)\\
(c L)(u) & := c (L(u))
\end{aligned}
$$

:::
:::

</br>

우리는 이것으로부터 간단하게 선형사상의 아주 중요한 성질을 알 수 있다.

::: {#prp-LUV_vector_space}

#### $\mathcal{L}(U,\,V)$ 는 벡터공간이다 

$U,\,V$ 가 $\mathbb{F}$-벡터공간일 때, 위에서 정의된 선형사상의 합과 스칼라곱에 의해 $\mathcal{L}(U,\,V)$ 는 $\mathbb{F}$-벡터공간이다.
:::

::: {.proof}
$L,\,K\in \mathcal{L}(U,\,V)$, $a,\,b\in \mathbb{F}$ 라 하자. $u_1,\,u_i \in U$ 에 대해 $L(u_1) = v_1$, $L(u_2) = v_2$, $K(u_1) = v'_1$, $K(u_2) = v'_2$ 라 하자.
$$
\begin{aligned}
(L+K)(u_1 + b u_2) &= L(u_1 + b u_2) + K(u_1+ b u_2) \\
&= v_1+ b v_2 +v'_1+ b v'_2  \\ 
& = (L+K)(u_1) + b  (L+K)(u_2) \\ 
(c L)( u_1 + b u_2) &= c (L(u_1+ b u_2))= c (v_1 + b v_2) \\ 
&= c v_1 + cb v_2  \\ 
&= c L(u_1) + b \left(c L (u_2)\right)
\end{aligned}
$$

즉 $L+K\in \mathcal{L}(U,\,V),\, c L \in \mathcal{L}(U,\,V)$ 이다. 영사상 즉 모든 $u\in U$ 에 대해 $L_0(u)=0_V\in V$ 인 $L_0$ 는 $\mathcal{L}(U,\,V)$ 에서의 덧셈의 항등원이다. 벡터공간에 대한 나머지의 증명은 쉽게 할 수 있으므로 생략한다. $\square$ 

:::


</br>


### 선형사상의 합성

선형사상은 함수이므로 함수의 합성처럼 선형사상의 합성을 정의 할 수 있다. $\mathbb{F}$-벡터공간 $U,\,V,\,W$ 와 $L: \in \mathcal{L}(U,\,V),\, K\in\mathcal{L}(V,\,W)$ 에 대해 

$$
(L\circ K)(u) = L(K(u))
$$

이다. 

</br>

::: {#prp-product_map}
선형사상의 합성도 선형사상이다.
:::


::: {.proof}
$\mathbb{F}$-벡터공간 $U,\,V,\,W$ 와 $c\in \mathbb{F}$ 를 생각하자. $L \in \mathcal{L}(U,\,V),\, K\in\mathcal{L}(V,\,W)$ 에 대해 
$$
\begin{aligned}
(L\circ K)(u_1 + c u_2) &= L(K(u_1+ c u_2)) = L(K(u_1)+ K(c u_2)) \\ 
&= (L\circ K)(u_1) + c (L\circ K)(u_2)\\
\end{aligned}
$$

이므로 $L\circ K\in \mathcal{L}(U, W)$ 이다. $\square$
:::

</br>

::: {#prp-product_map}

선형사상에 대해서는 다음이 성립한다.
$$
\begin{aligned}
(L_1 \circ L_2) \circ L_3 &= L_1 \circ  (L_2 \circ L_3) \\
(L_1+L_2) \circ K &= L_1 \circ K + L_2  \circ K \\
L\circ (K_1 +K_2) &= L \circ K_1 + L \circ K_2
\end{aligned}
$$

:::

::: {.proof}
증명은 생략한다.
:::

</br>

### 쌍대 기저 {#sec-dual_basis_pre}

우리는 $\mathbb{F}$ 가 1차원 벡터공간임을 안다. 따라서 $\mathbb{F}$-벡터공간 $V$ 에 대해 $V\mapsto \mathbb{F}$ 인 선형사상을 생각 할 수 있다.  우리는 @prp-linearmap_basis 에서 $V$ 의 기저에 대해서만 값을 알면 선형사상이 유일하게 정해진다는 것을 보였다. 이제 $V$ 의 기저 $(v_i)$ 에 대해 다음과 같이 정의된 $\varphi_j \in \mathcal{L}(V, \mathbb{F})$ 를 생각 할 수 있다.

$$
\varphi_j (v_i) = \delta_{ij} 
$$

$V$ 와 그 기저 $\{v_1,\ldots,\,v_n\}$ 에 대해 이렇게 정의된 선형사상의 집합 $\{\varphi_1,\ldots,\,\varphi_n\}$ 을 **쌍대 기저 (dual basis)** 라고 한다. 자세한 것은 [쌍대공간과 쌍대 사상](../part3/dual_space.qmd) 에서 자세히 다룬다.


</br>


## 선형사상의 행렬표현과 행렬의 연산

우리는 앞서 벡터를 행렬로 표현하는 것에 대해 알아보았다. 선형사상도 행렬로 표현할 수 있으며, 선형사상의 합, 스칼라곱, 합성에 맞게 행렬의 연산도 정의 할 수 있다.

</br>

### 선형사상의 행렬표현

$\mathbb{F}$-벡터공간 $U,\,V$ 에 대해 $L\in \mathcal{L}(U,\,V)$ 라 하자. $\dim (U) = n$, $\dim (V) = m$ 이며 $\mathcal{B}_U=(u_j),\,\mathcal{B}_V=(v_i)$ 를 각각 $U$ 와 $V$ 의 순서기저라 하자. $u\in U$ 에 대해 $L(u)$ 는 $V$ 의 벡터이므로 $(v_i)$ 의 선형결합으로 표현된다. 따라서 $L(u_j)$ 를 $(v_i)$ 의 선형결합으로 아래와 같이 표현 할 수 있다.

$$
L(u_j) = A_{1j}v_1 + \cdots + A_{nj} v_n = \sum_{i=1}^m A_{ij} v_i
$$

$u \in U$ 는 $(u_j)$ 의 선형결합이므로 $u= \sum_j a_j u_j$ 라 하면,

$$
\begin{aligned}
L(u) &= T \left( \sum_{j=1}^n a_j u_j \right) = \sum_{j=1}^n a_j L(u_j) = \sum_{j=1}^n \sum_{i=1}^m a_j A_{ij} v_i = \sum_{i=1}^m \left(\sum_{j=1}^n A_{ij}a_j\right)v_i
\end{aligned}
$$

이다. $b_i = \displaystyle \sum_{j} A_{ij}a_j$ 라 하면 $L(u) = \sum_i b_i v_i$ 이므로

$$
\left[L\left( \sum_j a_j u_j \right)\right]_{\mathcal{B}_V} = \begin{bmatrix} b_1 \\ \vdots \\ b_n\end{bmatrix}=  \begin{bmatrix} \sum_j A_{1j}a_j \\ \vdots \\ \sum_{j} A_{nj}a_j\end{bmatrix}
$$

임을 안다. 선형사상 $L$ 를 기저 $\mathcal{B}_U,\,\mathcal{B}_V$ 에 대해 행렬로 표현한 것을 $[L]_{\mathcal{B}_U,\mathcal{B}_V}$ 라 하고 다음과 같이 표현하자.

$$
[L]_{\mathcal{B}_U,\mathcal{B}_V} = \begin{bmatrix} A_{11} & \cdots & A_{1j} & \cdots &A_{1n} \\ \vdots & & \vdots & & \vdots  \\ A_{i1} & \cdots  & A_{ij} & \cdots & A_{in} \\\vdots & & \vdots & & \vdots  \\ A_{m1} & \cdots & A_{mj} & \cdots & A_{mn}\end{bmatrix} .
$$

우리는 $[u]_{\mathcal{B}_U} = \begin{bmatrix} a_1 \\ \vdots \\a_m \end{bmatrix}$ 임을 안다. 만약 우리가 $m \times n$ 행렬 $\boldsymbol{A}$ 와 $n \times l$ 행렬 $\boldsymbol{B}$ 의 행렬의 곱을 다음과 같이 정의한다고 하자.

$$
(\boldsymbol{AB})_{ij} := \sum_{k=1}^n A_{ik}B_{kj}
$$

그렇다면, $[L]_{\mathcal{B}_U,\mathcal{B}_V}$ 와 $[u]_{\mathcal{B}_U}$ 의 곱은 $m \times 1$ 행렬이 되며,

$$
\left([L]_{\mathcal{B}_U,\mathcal{B}_V} [u]_{\mathcal{B}_U}\right)_{i1} = \sum_{j=1}^n A_{ij}a_j = \left(\left[L\left( \sum_j a_j u_j \right)\right]_{\mathcal{B}_V}\right)_{i1}  
$$

이 된다. 즉, 

$$
\left[L(u)\right]_{\mathcal{B}_V} = [L]_{\mathcal{B}_U,\mathcal{B}_V} [u]_{\mathcal{B}_U}
$$

이다. 행렬의 곱셈을 위와 같이 정의하여 특정 기저에서의 행렬과 벡터의 곱이 선형사상에 맞춰 자연스럽게 정해졌다. 선형 연산자의 경우, 즉 $U=V$ 인 경우는 $\mathcal{B}_U=\mathcal{B}_V$ 일 수 있다. 이경우는 $[L]_{\mathcal{B}_U}$ 로 쓰기로 하자. 기저가 이미 정해져서 아는 경우, 혹은 어떤 기저라도 상관 없는 경우에는 행렬 표현을 $[L]$ 나 $[v]$ 와 같이 줄여서 사용하기로 한다. 

::: {.callout-note appearance="simple" icon="false"}
::: {#def-multiplication_of_matrix}

$m \times n$ 행렬 $\boldsymbol{A}$ 와 $n \times l$ 행렬 $\boldsymbol{B}$ 의 곱 $\boldsymbol{AB}$ 는 다음과 같이 정의된다.

$$
(\boldsymbol{AB})_{ij} := \sum_{k=1}^n A_{ik}B_{kj} 
$$ {#eq-multiplication_of_matrix}
:::
:::



</br>

### 선형사상의 합의 행렬표현

$L,\,K \in \mathcal{L}(U,\,V)$ 이고 $U,\,V$ 의 기저 $\mathcal{B}_U,\,\mathcal{B}_V$ 에 대해 $\boldsymbol{L}=[L]_{\mathcal{B}_U,\mathcal{B}_V}$, $\boldsymbol{K} =[K]_{\mathcal{B}_U,\mathcal{B}_V}$ 라 하자. $(L+K)(u)= L(u)+ K(u)$  이므로,

$$
\begin{aligned}
(L+K)\left( \sum_j a_j u_j \right) &= L\left( \sum_j a_j u_j \right) + K\left( \sum_j a_j u_j \right) \\ 
&= \sum_j a_j L(u_j) + a_j K(u_j) \\
&= \sum_i \left(\sum_j (L_{ij}+K_{ij})a_j  \right) v_i
\end{aligned}
$$

이다. 이로부터 $(\boldsymbol{L}+\boldsymbol{K})_{ij} = L_{ij} + K_{ij}$ 로 정의하는 것이 자연스럽다는 것을 알 수 있다.

</br>

### 선형사상의 합성의 행렬표현

$L\in \mathcal{L}(U,\, W),\, K \in \mathcal{L}(W, V)$ 라 하자. $U,\,V,\,W$ 의 한 기저를 $\mathcal{B}_U =(u_j),\,\mathcal{B}_V = (v_i),\,\mathcal{B}_W = (w_k)$ 라 하자. 이 기저에서의 $L$ 와 $K$ 의 행렬표현을 $\boldsymbol{L},\,\boldsymbol{K}$ 라 하고, $(L\circ K)\in \mathcal{L}(U, V)$ 에 대한 행렬표현 $\boldsymbol{M}$ 를 알아보자.

$$
\begin{aligned}
L(u_j) &= \sum_{k} L_{kj}w_k \\
K(w_k) &= \sum_{i} K_{ik}v_i
\end{aligned}
$$

이므로,

$$
\begin{aligned}
(K \circ L)(u_j) & = K\left( \sum_k L_{kj} w_k\right) = \sum_k L_{kj} K(w_k) \\
&= \sum_k L_{kj} \sum_i K_{ik} v_i = \sum_i \left(\sum_k K_{ik}L_{kj}\right)v_i \\
\end{aligned}
$$

이다. @def-multiplication_of_matrix 에 의해 선형사상의 합성은 각 선형사상의 행렬표현의 곱임을 알 수 있다. $\boldsymbol{K}$ 가 $K\in \mathcal{L}(W,\,V)$ 의 행렬표현이며, $\boldsymbol{L}$ 가 $L\in \mathcal{L}(U,\,W)$ 의 행렬표현이므로 $\boldsymbol{K}$ 의 열의 갯수와 $\boldsymbol{L}$ 의 행의 갯수는 $\text{dim}(W)$ 와 같아야 한다. 

</br>

### 선형 사상의 스칼라곱

$\mathbb{F}$-벡터공간 $U,\,V$ 에 대해 $L \in \mathcal{L}(U,\,V)$ 일 때 $[L]_{\mathcal{B}_U,\mathcal{B}_V} = \boldsymbol{L}$ 이며 $c\in \mathbb{F}$ 라 하자.

$$
(c L)(u_i) = c \left( L(u_i)\right) = \sum_j c L_{ji}v_j
$$

이므로 $(c \boldsymbol{L})_{ij} = c L_{ij}$ 임을 알 수 있다.

</br>

### 항등사상과 항등행렬
::: {.callout-note appearance="simple" icon="false"}
::: {#def-identity_matrix}

#### 항등 행렬 (identity matrix)

벡터공간 $V$ 에 대해 $I\in \mathcal{L}(V)$ 가 $I(v)=v$ 일 때, 즉 $I$ 가 항등사상일 때 이에 대한 행렬표현 $\boldsymbol{I}=[I]$ 를 항등행렬이라 한다. 어떤 기저 $\mathcal{B}_V = \{v_i\}$ 에 대해서도 $I(v_i) = v_i$ 이므로 $(\boldsymbol{I})_{ij} = \delta_{ij}$ 이다. 
:::
:::

</br>

### 행렬의 행벡터와 열벡터

$\mathcal{M}_{1\times n}(\mathbb{F})$ 과 $\mathcal{M}_{n \times 1}(\mathbb{F})=\mathcal{M}_n(\mathbb{F})$ 이 벡터공간임을 안다. 행렬 $\boldsymbol{A}$ 의 $i,\,j$ 성분을 $A_{ij}$ 혹은 $A_{i,j}$  로 표현할 수 있듯이 $\boldsymbol{A}$ 의 $i$ 번째 행을 $\boldsymbol{A}_{i,:}$ 혹은 $\boldsymbol{A}_{i:}$ 라 쓰고 $j$ 번째 열을 $\boldsymbol{A}_{:,j}$ 혹은 $\boldsymbol{A}_{:j}$ 라 쓰기로 하자. 각각의 $\boldsymbol{A}_{:i}$ 와 $\boldsymbol{A}_{j:}$ 를 행벡터와 열벡터로 간주한다. 즉 $m\times n$ 행렬의 경우 $\boldsymbol{A}_{:i}\in \mathcal{M}_m(\mathbb{F})$ 이며 $\boldsymbol{A}_{i:}\in \mathcal{M}_{1 \times n}(\mathbb{F})$ 이다. 많은 경우 계산을 하는데 도움이 된다.

**1.** $m \times n$ 행렬 $\boldsymbol{A}$ 과 $n \times p$ 행렬 $\boldsymbol{B}$ 를 생각하자. 이 때,

$$
(\boldsymbol{AB})_{ij} = \sum_k A_{ik}B_{kj} = \boldsymbol{A}_{i:}\boldsymbol{B}_{:j}
$$ 

임을 알 수 있다. 또한, 

$$
\begin{aligned}
(\boldsymbol{AB})_{:i} &= \boldsymbol{A}(\boldsymbol{B})_{:i} \\
(\boldsymbol{AB})_{j:} & = (\boldsymbol{A})_{j:}\boldsymbol{B}
\end{aligned}
$$

이다. 즉, 

$$
\boldsymbol{AB} =  \begin{bmatrix} \boldsymbol{AB}_{:1} & \cdots & \boldsymbol{AB}_{:n} \end{bmatrix} =  \begin{bmatrix} \boldsymbol{A}_{1:}\boldsymbol{B} \\ \vdots \\ \boldsymbol{A}_{m:} \boldsymbol{B} \end{bmatrix}
$$

이다. 위의 개념은 많은 경우 편리하게 사용된다.

**2.** $m\times n$ 행렬 $\boldsymbol{A}$ 와 $n \times 1$ 행렬 $\boldsymbol{c}$ 를 생각하자. $c_i$ 를 $\boldsymbol{c}$ 의 $i$ 번째 성분이라 하면,

$$
\boldsymbol{Ac} = c_1 \boldsymbol{A}_{:1} + \cdots + c_n\boldsymbol{A}_{:n}
$$

이다. 즉 $\boldsymbol{Ac}$ 는 $\boldsymbol{A}$ 의 열벡터들의 선형결합이다.

</br>

## 선형사상의 kernel, image, rank, nullity

### 선형사상의 kernel 과 image

::: {.callout-note appearance="simple" icon="false"}

::: {#def-ker_range}

#### $\text{ker}$ 와 $\text{im}$

$L\in \mathcal{L}(U,\,V)$ 에 대해 $L$ 의 kernel ($\ker (T)$) 과 image ($\text{im}(T)$) 는 다음과 같이 정의된다.

$$
\begin{aligned}
\ker (L) &:= \{ u\in U : L(u) = 0_V\} ,\\
\text{im}(L) &:= \{L(u) : u \in U\}.
\end{aligned}
$$

:::
:::

</br>

::: {#lem-ker_range_subspace}

$L\in \mathcal{L}(U,\,V)$ 일 때, $\ker (L)$ 는 $U$ 의 부분공간이며 $\text{im} (L)$ 는 $V$ 의 부분공간이다.

:::

::: {.proof}
$\ker (L) \subset U$ 임은 자명하다. $L(0_U)=0_V$ 이므로 $0_U \in \ker (L)$ 이다. $u_1,\,u_2\in \ker (L),\, c \in \mathbb{F}$ 일 때, 

$$
L(u_1 + c u_2) = L(u_1)+ c L(u_2) = 0_V
$$

이므로 $\ker (L)$ 는 $U$ 의 부분공간이다. 같은 방법으로 $\text{im}(L)$ 가 $V$ 의 부분공간임을 보일 수 있다. $\square$

:::

</br>

$\ker (L)$ 와 $\text{im}(L)$ 가 각각 부분공간이기 때문에 차원을 정의 할 수 있다. 

::: {.callout-note appearance="simple" icon="false"}

::: {#def-nullity_rank}

#### **nullity** 와 **rank**

$L\in \mathcal{L}(U,\,V)$ 에서 $\ker (L)$ 의 차원을 $\text{nullity}(L)$ 라 하고 $\text{im}(L)$ 의 차원을 $\text{rank}(L)$ 라 한다. 즉,

$$
\begin{aligned}
\text{nullity}(L) &:= \dim (\ker (L)), \\
\text{rank}(L) &:= \dim (\text{im}(L)),
\end{aligned}
$$

이다.
:::
:::


</br>

### Rank-nullity 정리

::: {#thm-rank_nullity}

#### Rank-nullity 정리

유한차원 벡터공간 $U,\,V$ 에서의 선형사상 $L\in \mathcal{L}(U,\,V)$ 에 대해 다음이 성립한다.

$$
\dim (U) = \text{nullity} (L) + \text{rank}(L)
$$

:::

::: {.proof}
$\ker (L)$ 는 $U$ 의 부분공간이다(@lem-ker_range_subspace). $\text{nullity}(L)=m$ 이라 하고 $\ker (L)$ 의 기저를 $(u_1,\ldots,u_m )$ 이라 하자. 이 기저를 확장하여 $U$ 의 기저를 이루는 벡터 $(u_1,\ldots,\,u_m,\,w_1,\ldots,w_n)$ 를 구할 수 있다(@lem-basis_expansion). 그렇다면 $\dim (U) = m + n$ 이다. 이제 $\text{rank}(L)=n$ 임을 보이면 된다.

임의의 $v = a_1 u_1 + \cdots a_m u_m + b_1 w_1 + \cdots + b_n w_n$ 에 대해 $L(v)=a_1 L(w_1) + \cdots + a_n L(w_n)$ 이다. 즉 $\{L(w_1),\ldots,L(w_n)\}$ 이 $\text{im}(L)$ 를 span 한다. 이제 $\{L(w_1),\ldots,L(w_n)\}$ 이 선형 독립임을 보이자. $c_1 L(w_1) + \cdots + c_n L(w_n) = 0_V$ 인 $c_1,\ldots,c_n \in \mathbb{F}$ 를 찾자. $c_1 L(w_1) + \cdots + c_n L(w_n) = 0_V$ 라면 $L(c_1 w_1 + \cdots + c_n w_n) = 0_V$ 이므로 $c_1T(w_1) + \cdots + c_n T(w_n) \in \ker (T)$ 이어야 한다. 따라서,

$$
c_1 w_1 + \cdots + c_n w_1 = d_1 u_1 + \cdots +d_m u_m
$$

인 $d_1,\ldots,\,d_m \in \mathbb{F}$ 가 존재해야 한다. 그런데 $\{u_1,\ldots,\,u_m,\,w_1,\ldots,\,w_n\}$ 이 선형독립이므로, $c_1=\cdots =c_n = d_1 = \cdots =d_m = 0$ 이다. 따라서 $\{L(w_1),\ldots,\, L(w_n)\}$ 은 선형독립니다. 즉 $n= \text{rank}(L)$ 이므로 위의 식이 성립한다. $\square$

:::

</br>

아래의 명제는 위의 증명과정에서 보였지만 별도로 언급할 가치가 있다.

::: {#cor-range_independence}
선형사상 $L\in \mathcal{L}(U,\,V)$ 에 대해 $\{u_1,\ldots,\,u_m\}\subset U$ 가 선형독립이며 $L(u_i)\ne 0_V\, (i=1,\ldots,\,m)$ 이라 하자. 이 때 $\{L(u_1),\ldots,\, L(u_m)\}$ 은 선형독립이다.
:::


</br>

## 동형사상과 선형연산자의 기본 정리

### 동형사상과 동형

선형사상은 벡터에 대한 함수이므로 역함수를 생각 할 수 있으며 선형사상이 전단사 함수라면 당연히 역함수, 즉 역사상(inverse map)이 존재한다. 

::: {.callout-note appearance="simple" icon="false"}
::: {#def-isomorphism_in_vector_space}

#### 가역사상/동형사상 

$L\in \mathcal{L}(U,\,V)$ 에 대한 역사상은 $T^{-1}$ 로 표기하며, 역변환이 존재하는 선형 사상을 **가역 사상(invertible map)** 혹은 **동형사상(isomorphism)** 이라 한다. 그리고 두 벡터공간 사이에 가역인 사상이 존재하면 두 벡터공간이 **동형(isomorphic)** 이라고 한다. 두 벡터공간 $U,\,V$ 가 동형일 때 $U \cong V$ 라고 쓴다.

:::
:::


::: {.callout-warning appearance="simple" icon="false"}

#### 가역사상과 동형사상

원래 집합 $A$ 에서 집합 $B$ 로의 함수 $f:A \to B$ 에 대해 $f$ 가 가역함수라는 것은 $f$ 가 전단사 함수라는 뜻과 동일하고 동형사상은 훨씬 강한 제약조건을 요구하는 함수이지만 벡터공간과 선형사상의 특징으로 인해 벡터공간에서의 선형사상에서는 가역사상과 동형사상이 동치이다.
:::

</br>

::: {#prp-condition_of_injectivity}

선형사상 $L\in \mathcal{L}(U,\,V)$ 가 단사(injection) 일 필요충분조건은 $\text{nullity} (L) = 0$ 이다.

:::

::: {.proof}
$L$ 이 단사라 하자. $L(u)=0_V$ 인 $u$ 는 $0_U$ 뿐이므로 $\ker (L) = \{0_U\}$ 이다. 따라서 $\text{nullity} (L) = 0$ 이다. 

$\text{nullity}(L)=0$ 이면 $\ker (L)=\{0_U\}$ 이다. $L(u_1)=L(u_2)$ $\implies$ $L(u_1-u_2)=0_V$ 이므로 $u_1 =u_2$ 이다. 즉 $L$ 는 단사이다. $\square$
:::

<br>

::: {#prp-same_dim_vs}
두 유한차원 벡터공간 $U,\,V$ 에 대해 다음은 동치이다.

&emsp; ($1$) $\dim (U) = \dim (V)$, 

&emsp; ($2$) $U \cong V$.

:::


::: {.proof}
$m=\dim (U),\, n = \dim (V)$ 이며 $(u_i),\,(v_j)$ 가 각각의 기저라 하자. 

(1 $\implies$ 2) $L\in \mathcal{L}(U,\,V)$ 를 $L({u_i}) =v_i, \, i=1,\ldots, m=n$ 로 정의하면,  $\ker (L) = \{0_U\}$ 이므로 단사이고, $\text{im}(L) = V$ 이므로 전사이다. 따라서 $U \cong V$ 이다. 

(2 $\implies$ 1) $L\in \mathcal{L}(U,\,V)$ 가 동형사상이면 $L$ 가 전사이므로 $\text{im}(L) = V$ 이어야 하며, $L$ 가 단사이므로 $\text{nullity} (L) = 0$ 이어야 한다. 선형사상의 기본정리(@thm-rank_nullity) 에 의해

$$
\dim (U) = \text{nullity} (L) + \text{rank}(L) = 0 + \dim (V) = \dim (V)
$$

이다. $\square$ 

:::

</br>


</br>

이로부터 자연스럽게 아래의 결론이 나온다.



::: {#cor-isomorphism_U_F}
$n$ 차원 $\mathbb{F}$-벡터공간 $U$ 와 $\mathcal{M}_{n}(\mathbb{F})$, $\mathcal{M}_{1 \times n}(\mathbb{F})$ 은 동형이다.

:::

</br>

::: {#lem-linearity_of_inverse_map}

$L\in \mathcal{L}(U,\,V)$ 가 동형사상일 때 $L^{-1}$ 도 동형사상이다.

:::

::: {.proof}

우선 $L\in \mathcal{L}(U,\,V)$ 가 동형사상이면 $L^{-1}$ 이 선형사상임을 보이자. $u_1,\,u_2 \in U$ 에 대해 $v_1 = L(u_1),\, v_2 = L(u_2)$ 이며 $c \in \mathbb{F}$라 하자. $L$ 이 선형사상이므로 $L(u_1 + c u_2) = v_1 +c v_2$ 이다. 즉,

$$
\begin{aligned}
L^{-1}(v_1 + c v_2) &= u_1 + c u_2 = L^{-1}(u_1) + c L^{-1}(u_2)
\end{aligned}
$$

이다. 즉 $L^{-1}$ 은 선형사상이다. $(L^{-1})^{-1}=L$ 이므로 $L^{-1}$ 도 동형사상이다. $\square$ 
:::

</br>

::: {#thm-basis-tranformations}

#### 가역사상과 기저의 변환

$L\in \mathcal{L}(V,\,W)$ 에 대해 다음 두 조건은 동치이다. 

&emsp; ($1$) $L$ 는 동형사상이다.

&emsp; ($2$) $L$ 는 $V$ 의 기저를 $W$ 의 기저로 변환한다.

:::

::: {.proof}

(1 $\implies$ 2) $V$ 의 기저 $\{v_1,\ldots,\,v_m\}$ 에 대해 $\text{nullity} (L) = 0$ 이므로 @cor-range_independence 에 따라 $\{L(v_1),\ldots,\, L(v_m)\}$ 은 선형독립이다. $L$ 이 전사이므로  $\{L(v_1),\ldots,\, L(v_m)\}$ 는 역시 $V$ 의 기저이다.

(2 $\implies$ 1) $L$ 가 $V$ 의 기저를 $W$ 로 기저로 변환하므로 $\text{im}\, (L)=W$ 이다. 따라서 $L$ 은 전사이다. $V$ 의 기저 벡터중 $L$ 에 의해 영벡터가 되는 것이 없으므로 (영벡터를 포함하는 벡터의 집합은 무조건 선형종속이므로 기저가 될 수 없다) $\text{nullity}(L) = 0$ 이다. 따라서 $L$ 은 단사이다. 즉 $L$ 는 동형사상이다. $\square$

:::

</br>

### 선형사상공간의 차원

우리는 $\mathbb{F}$-벡터공간 $U,\,V$ 에 대해 $\mathcal{L}(U,\,V)$ 가 벡터공간이라는 것을 안다(@prp-LUV_vector_space). 또한 $\mathbb{F}$ 의 원소를 성분으로 갖는 $m \times n$ 행렬의 집합 $\mathcal{M}_{m \times n}(\mathbb{F})$ 도 벡터공간이라는 것을 안다 (@exm-vectorspace_matrix). $n = \dim (U),\, m = \dim (V)$ 이고 $\mathcal{B}_U = (u_i)$, $\mathcal{B}_V = (v_j)$ 가 각각 $U,\,V$ 의 기저라고 하자. $L\in \mathcal{L}(U,\,V)$ 의 행렬표현 $[L]_{\mathcal{B}_U,\,\mathcal{B}_V}$ 를 생각하면 $[-]_{\mathcal{B}_U,\,\mathcal{B}_V}$ 는 $\mathcal{L}(U,\,V) \mapsto\mathcal{M}_{\dim V \times \dim U}(\mathbb{F})$ 함수이다. $L,\, K\in \mathcal{L}(U,\,V)$, $c \in \mathbb{F}$ 에 대해

$$
\left[ L + c K \right]_{\mathcal{B}_U, \mathcal{B}_V} = [L]_{\mathcal{B}_U, \mathcal{B}_V} + [c K]_{\mathcal{B}_U, \mathcal{B}_V} = [L]_{\mathcal{B}_U, \mathcal{B}_V} + c [K]_{\mathcal{B}_U, \mathcal{B}_V}
$$

이므로 $[-]_{\mathcal{B}_U,\mathcal{B}_V}$ 는 선형사상이다. 즉 우리는 다음을 증명했다.


::: {#lem-MM_linearmap}

$\mathbb{F}$ 에서 정의된 유한차원 벡터공간 $U,\,V$ 와 그 순서기저 $\mathcal{B}_U,\, \mathcal{B}_V$ 에 대해 $[L] = [L]_{\mathcal{B}_U,\,\mathcal{B}_V}$ 는 $\mathcal{L}(U,\,V) \to \mathcal{M}_{\dim V \times \dim U}(\mathbb{F})$ 인 선형사상이다.

:::

</br> 

이제 우리는 어쩌면 선형대수학의 가장 중요한 결론을 내야 할 시간이 왔다.



::: {#thm-isomorphic}
$n$ 차원 벡터공간 $U$ 와 $m$ 차원 벡터공간 $V$ 에 대해 $\mathcal{L}(U,\,V)$ 는 $\mathcal{M}_{m\times n}(\mathbb{F})$ 와 동형이다.
:::

::: {.proof}
$U,\,V$ 의 기저를 각각 $\mathcal{B}_U = (u_i),\,\mathcal{B}_V = (v_j)$ 라 할 때 $\Phi: \mathcal{L}(U,\,V) \to \mathcal{M}_{m \times n}(\mathbb{F})$ 를 $\Phi(L) = [L]_{\mathcal{B}_U, \mathcal{B}_V}$ 로 정의한다. @lem-MM_linearmap 으로부터 $\Phi$ 는 선형사상임을 안다. $\ker (\Phi) = \{0_U\}$ 이므로 단사(injective)이다. 모든 $\mathcal{M}_{m \times n}(\mathbb{F})$ 에 대해 상응하는 $L$ 가 존재하므로 전사(surjective)이다. 즉 $\Phi$ 는 동형사상이다. $\square$

:::

</br>

위의 정리와 @prp-same_dim_vs 로부터 다음을 알 수 있다.

::: {#cor-dimension_of_LUV}

유한차원 벡터공간 $U,\,V$ 에 대해 다음이 성립한다.

$$
\dim (\mathcal{L}(U, V)) = \dim (\mathcal{M}_{\dim (V) \times \dim (U)}(\mathbb{F})) = \dim (V)\times \dim (U)
$$

:::

</br>

다시 한번 유한 차원 $\mathbb{F}$-벡터공간에 대한 선형연산자의 집합 $\mathcal{L}(U, V)$ 를 생각해보자. $n = \dim U$, $m = \dim V$ 일 때

&emsp; $1$. $U \cong \mathcal{M}_{n}(\mathbb{F})$, $V \cong \mathcal{M}_{m}(\mathbb{F})$

&emsp; $2$. $\mathcal{L}(U,\,V) \cong  \mathcal{M}_{m \times n}(\mathbb{F})$

임을 안다. 또한 $U$ 와 $V$ 의 각각의 기저 $\mathcal{B}_U$, $\mathcal{B}_V$ 에 대해, 

$$
L(u)=v \iff [L]_{\mathcal{B}_U, \mathcal{B}_V}[u]_{\mathcal{B}_U} = [v]_{\mathcal{B}_V}
$$

라는 것도 안다. 이것은 근본적으로 선형사상과 행렬이 같은것이며, 벡터와 열벡터가 같은것임을 말해준다. 


</br>

### 선형연산자의 기본정리

::: {#thm-fundamental_theorem_linaar_map}

#### 선형 연산자의 기본 정리

유한차원 벡터공간 $V$ 에서의 선형 연산자 $L\in \mathcal{L}(V)$ 에 대해 다음 세 명제는 동치이다.

&emsp; ($1$) $L$ 는 가역이다.

&emsp; ($2$) $L$ 는 단사이다.

&emsp; ($3$) $L$ 는 전사이다.

:::

::: {.proof}
함수가 가역이면 전단사이고, 전단사 이면 가역이다. 따라서 $L$ 가 전사라는 것과 단사라는 것이 동치임을 보이면 된다. Rank-nullity 정리(@thm-rank_nullity)로부터

$$
\dim (V) = \text{nullity}(L)  + \text{rank}(L)
$$

임을 안다. 이로부터 다음을 보일 수 있다.

$$
\begin{aligned}
L \text{ 이 전사} &\iff \text{rank} (L) = \dim V \\ 
& \iff \text{nullity} (L) = 0  \\ 
& \iff L \text{ 는 단사} & 
\end{aligned}
$$

즉, 유한차원 벡터공간에서의 선형연산자는 전사와 단사라는 조건이 동치이다. $\square$

:::

</br>



위의 명제로부터 자연스럽게 아래의 명제가 성립한다는 것을 알 수 있다.

::: {#cor-basis_transformation}

유한차원 벡터공간 $V$ 에서의 선형연산자 $L\in \mathcal{L}(V)$ 에 대해 다음은 동치이다.

&emsp; ($1$) $L$ 은 동형이다.

&emsp; ($2$) $\{v_1,\ldots,\,v_m\}$ 이 $V$ 의 기저일 때, $\{L(v_1),\ldots,\,L(v_m)\}$ 도 $V$ 의 기저이다.
:::

</br>

### 곱공간

우리는 앞서 데카르트곱에 대해 알아보았다. 이제 벡터공간의 데카르트곱이 벡터공간이 되도록 확장하는 것을 알아보도록 하자.

</br>


::: {.callout-note appearance="simple" icon="false"}
::: {#def-product_space}

#### 곱공간

$V_1,\ldots,\,V_m$ 이 각각 $\mathbb{F}$-벡터공간일 때 **곱공간(product space)** $V_1 \times \cdots \times V_m$ 은 다음과 같이 집합과 덧셈과 스칼라곱이 정의된 집합이다.

**1.** 집합의 정의

$$
\begin{aligned}V_1 \times \cdots \times V_m = \{(v_1,\ldots,v_m): v_1\in V_1,\ldots,\,v_m \in V_m\} \\
\end{aligned}
$$

**2.** 덧셈의 정의
$u = (u_1,\ldots,\,u_m) \in V_1 \times \cdots \times V_m,\, v=(v_1,\ldots,\,v_m)\in V_1 \times \cdots \times V_m$ 에 대해 $u+v$ 을 다음과 같이 정의한다. 
$$
(u_1,\ldots,\,u_m)+ (v_1,\ldots,\,v_m) = (u_1+v_1, \ldots,\, u_m+v_m)
$$

**3.** 스칼라곱의 정의

$v=(v_1,\ldots,\,v_m)\in V_1 \times \cdots \times V_m,\, c \in \mathbb{F}$ 에 대해 스칼라곱을 다음과 같이 정의한다. 
$$
c(v_1,\ldots,\,v_m) = (c v_1,\ldots,\,c v_m)
$$

</br>

$v\in V_1 \times \cdots \times V_m$ 일 때 $v$ 는 $(v_1,\ldots,\,v_m)$ 이며 각각의 $v_i \in V_i, (i=1,\ldots,\,m)$ 이다. 


:::
:::

</br>

우리는 다음 명제를 쉽게 증명할 수 있다.

::: {#prp-product_space}
곱공간은 벡터공간이다.
:::

</br>


우리는 $\mathbb{F}$ 가 벡터공간임을 안다. 위의 @def-product_space 의 정의에 따라 곱공간 $\mathbb{F}^n$ 을 벡터공간으로 볼 수 있다. 실제로 우리가 수학 및 여러 다양한 분야에서 사용하는 $\mathbb{F}^n$ 은 벡터공간으로서의 $\mathbb{F}^n$ 이며 실제로는 앞으로 배울 내적이 정의된 내적벡터공간으로서의 $\mathbb{F}^n$ 이다.

</br>

::: {#prp-dimension_of_product_space}

$V_1,\ldots,\,V_m$ 이 유한차원 벡터공간일 때,
$$
\dim (V_1 \times \cdots \times V_m) = \dim V_1 + \cdots + \dim V_m 
$$
이다.

:::

::: {.proof}

$(v^{(i)}_1,\ldots,\,v^{(i)}_{m_i})$ 를 $V_i$ 의 기저라고 하면 $\dim (V_i)=m_i$ 이다. $v\in V_1 \times \cdots \times V_m$ 의 $i$ 번째 성분을 기술하는데 $m_i$ 개의 기저벡터가 필요하므로 $V_1 \times \cdots \times V_m$ 를 기술하는 데는 $\dim V_1 + \cdots + \dim V_m$ 개의 벡터가 필요하다. $\square$ 

:::


</br>

::: {#prp-map_product_space}

$U_1,\ldots,\,U_m$ 이 $\mathbb{F}$-벡터공간 $U$ 의 부분공간일 때 다음과 같이 정의된 함수 $\Phi :  U_1 \times \cdots \times U_m  \to  U_1 + \cdots + U_m$ 는 선형사상이다.

$$
\Phi(u_1,\ldots,u_m) = u_1 + \cdots + u_m
$$
:::

::: {.proof}
$U = U_1 \times \cdots \times U_m$ 에 대해 $u,\,u'\in U,\, c \in \mathbb{F}$ 일 때 $\phi (u+c u') = \phi(u) + c\phi (u')$ 인 것을 쉽게 보일 수 있다. $\square$
:::

</br>

::: {#prp-product_space_and_direct_sum}
위에서 정의된 $\Phi$ 가 단사인 것의 필요충분조건은 $U_1+ \cdots +U_m$ 이 [직합(direct sum)](#직합) 인 것이다.
:::

::: {.proof}

@thm-directsum 에 의해 $U_1 + \cdots + U_m$ 이 직합일 필요충분조건은 $0$ 을 각각의 $u_i\in U_i$ 의 합으로 나타내는 방법이 모든 $u_i=0$ 인 것 뿐이다. 따라서, 

$$
\begin{aligned}
U_1 + \cdots + U_m \text{ 이 직합} & \iff  u_1 + \cdots + u_m = 0 \implies  u_1 = \cdots = u_m =0\\ 
& \iff \ker \phi =\{(0,\ldots,\,0)\} \\ 
& \iff  \Phi \text{ 가 단사.}\qquad \square
\end{aligned}
$$

:::

</br>

::: {#prp-directsum_condition}
유한차원 벡터공간 $U$ 의 부분공간 $U_1,\ldots,\,U_m$ 에 대해 $U_1 + \cdots + U_m$ 이 직합일 필요충분조건은
$$
\dim (U_1 + \cdots + U_m) = \dim U_1 + \cdots + \dim U_m
$$

이다.
:::

::: {.proof}
@prp-map_product_space 에서 정의된 $\Phi$ 를 생각한다. @prp-product_space_and_direct_sum 에 의해 $U_1+\cdots + U_m$ 이 직합일 필요충분조건이 $\Phi$ 가 단사인 것이며, $U_1 \times \cdots \times U_m$ 과 $U_1 + \cdots + U_m$ 이 유한차원 벡터공간이므로 $\Phi$ 가 단사인 것의 필요충분조건은 
$$
\dim (U_1 + \cdots + U_m) = \dim U_1 + \cdots + \dim U_m
$$
이다. $\square$
:::

</br>

</br>

### 가역사상과 역행렬

$L\in \mathcal{L}(U,\,V)$ 가 가역사상이라고 하자. 이 때 임의의 $u\in U,\, v\in V$ 에 대해 $(L^{-1}\circ T )(u)=u$ 이고 $(L \circ L^{-1}) (v)= v$ 이다. $\mathcal{B}_U,\,\mathcal{B}_V$ 가 각각 $U,\,V$ 의 기저라고 하자. $\boldsymbol{L}=[L]_{\mathcal{B}_U, \mathcal{B}_V}$ 에 대해 $[L^{-1}]_{\mathcal{B}_V,\mathcal{B}_U} =\boldsymbol{L}^{-1}$ 이라고 쓰는 것은 자연스럽다. 또한 $\boldsymbol{LL}^{-1} = \boldsymbol{L}^{-1}\boldsymbol{L} = \boldsymbol{I}$ 라는 것을 알 수 있다. 이 때 $\boldsymbol{L}^{-1}$ 을 $\boldsymbol{L}$ 의 **역행렬 (inverse matrix)** 라 한다.

</br>

### 기저의 변화에 따른 행렬의 변화 {#sec-matrix_transform_by_basis_transform}

$U$ 가 $n$ 차원 $\mathbb{F}$-벡터공간이며 $\mathcal{B}_1 = (u_1,\ldots,u_n)$ 이 $U$ 의 기저라고 하자. $P\in \mathcal{L}(U)$ 가 가역이면 @cor-basis_transformation 에서 보았듯이 $\mathcal{B}_2= (T(u_1),\ldots, T(u_n) )$ 도 $U$ 의 기저이다. $v_i = T(u_i)$ 라고 할 때 $P$ 가 다음과 같이 정의된다고 하자.

$$
P(u_i) = \sum_{j=1}^n P_{ji}u_j = v_i
$$

그렇다면 $u_i = P^{-1}(P(u_i)) = P^{-1}(v_i)$ 이다. $\boldsymbol{u}_i=[u_i]_{\mathcal{B}_1}$, $\boldsymbol{v}_i = [v_i]_{\mathcal{B}_1}$, $\boldsymbol{P}=[P]_{\mathcal{B}_1}$ 라면 $\boldsymbol{v}_i = \boldsymbol{Pu}_i$ 이다. 그런데 $\boldsymbol{u}_i =[u_i]_{\mathcal{B}_1}$ 은 표준기저 $\boldsymbol{e}_i$ 이므로 $\boldsymbol{v}_i$ 는 $\boldsymbol{P}$ 의 $i$ 번 째 열 $\boldsymbol{P}_{:i}$ 이다. 이것은 앞으로도 매우 중요하므로 뒤에 별도로 다시 언급하겠다.

</br>

이제 $\mathcal{B}_2$ 기저에서 $u_i$ 와 $v_i$ 를 표현해보자. $[v_i]_{\mathcal{B}_2} = \boldsymbol{e}_i$ 임은 자명하다. 

$$
\begin{aligned}
u_i &= \sum_j \delta_{ji}u_j = \sum_j (\boldsymbol{P}\boldsymbol{P}^{-1})_{ji}u_j \\
&= \sum_j \sum_k P_{jk}P^{-1}_{ki}u_j = \sum_k P^{-1}_{ki} \left(\sum_{j} P_{jk}u_j\right) \\
&= \sum_k P_{ki}^{-1} v_k 
\end{aligned}
$$

이므로 $[u_i]_{\mathcal{B}_2} = \boldsymbol{P}^{-1}[v_i]_{\mathcal{B}_2}$ 이다. 즉 $[u_i]_{\mathcal{B}_2}$ 는 $\boldsymbol{P}^{-1}$ 의 $i$ 번째 열이다.


이제 연산자 $T\in \mathcal{L}$ 이 $T(u_i) = \sum_j A_{ij}u_j$ 로 정의되었으며 이 연산자의 $\mathcal{B}_1$ 기저에서의 행렬표현을 $\boldsymbol{A}$ 라 하자. 즉 $\boldsymbol{A} = [T]_{\mathcal{B}_1}$ 이다. 이 때,

$$
\begin{aligned}
T(v_i) &= T(P(u_i)) = T \left( \sum_{k=1}^n  P_{ki}u_k\right) = \sum_{k=1}^n P_{ki} T(u_k) \\
&= \sum_k P_{ki} \left(  \sum_l A_{lk}u_l \right)= \sum_k P_{ki}\left(\sum_l A_{lk} \sum_{j} (P^{-1})_{jl} v_j\right) \\
&= \sum_j \left( \sum_l \sum_k (P^{-1})_{jl} A_{lk} P_{ki}\right) v_j
\end{aligned}
$$

이다. 이로부터 $[T]_{\mathcal{B}_2} = \boldsymbol{P}^{-1}\boldsymbol{AP}$ 임을 알 수 있다. 즉 두 기저 $\mathcal{B}_1 =\{u_i\}$, $\mathcal{B}_2 = \{P(u_i)\}$ 사이에,

$$
[T]_{\mathcal{B_1}} = \boldsymbol{A} \iff [T]_{\mathcal{B}_2} = \boldsymbol{P}^{-1}\boldsymbol{AP}
$$

의 관계가 성립한다. 즉 어떤 기저와 그 기저에서의 선형변환을 나타내는 행렬을 안다면, 변화된 기저에서의 선형변환을 나타내는 행렬도 알 수 있다. 이런 기저의 변환을 행렬의 닮음 변환 (similarity transformation) 이라 한다.

</br>


::: {.callout-note appearance="simple" icon="false"}
::: {#def-similarity_transformation_of_linear_operator}

#### 연산자의 닮음과 닮음변환

벡터공간 $V$ 에서 정의된 두 연산자 $L,\,K\in \mathcal{L}(V)$ 에 대해 어떤 가역 연산자 $P\in \mathcal{L}(V)$ 가 존재하여 $K=P^{-1}\circ L \circ P$ 라면 두 연산자 $L$ 과 $K$ 는 닮았다고 하며 $P^{-1}\circ L \circ P$ 를 $L$ 의 **닮음변환 (similarity transfroamtion)** 이라고 한다.

:::
:::


$K=P^{-1}\circ L \circ P$ 라면 그 행렬표현도 $[K] = [P^{-1}][L][P]$ 일 것이다. 연산자에 대한 것도 행렬에 대해 똑같이 정의 할 수 있다. 


::: {.callout-note appearance="simple" icon="false"}
::: {#def-similarity_transformation}

#### 행렬의 닮음과 닮음변환

행렬 $\boldsymbol{A},\,\boldsymbol{B}\in \mathcal{M}_{n\times n}(\mathbb{F})$ 에 대해 어떤 가역행렬 $\boldsymbol{P}\in \mathcal{M}_{n\times n}(\mathbb{F})$ 이 존재하여 $\boldsymbol{A}=\boldsymbol{P}^{-1}\boldsymbol{BP}$ 가 성립할 때 두 행렬 $\boldsymbol{A}$ 와 $\boldsymbol{B}$ 는 닮았다고 하며 $\boldsymbol{P}^{-1}\boldsymbol{AP}$ 를 $\boldsymbol{A}$ 의 **닮음변환(similarity transformation)** 이라고 한다. 

:::
:::

</br>

::: {#prp-basis_transoframtion_by_similarity_transformation}
$\boldsymbol{P}$ 가 가역행렬일 때 $\boldsymbol{P}$ 의 각 열은 표준기저가 이 변환에 의해 변환된 새로운 기저이다.
:::

::: {.proof}
표준기저 $\{\boldsymbol{e}_i\}$ 에 대해 $\boldsymbol{Pe}_i = \boldsymbol{P}_{:i}$ 이다. $\boldsymbol{P}$ 가 가역행렬이므로 열벡터의 집합은 선형독립이다. $\square$ 
:::

</br>

::: {#exm-similarity_equivalence}

두 정사각 행렬 $\boldsymbol{A},\,\boldsymbol{B}$ 가 닮았을 때 $\boldsymbol{A} \sim \boldsymbol{B}$ 라 표현한다고 하자. 이 때 다음이 성립함을 보여라.

1. $\boldsymbol{A} \sim \boldsymbol{A}$ 이다.

2. $\boldsymbol{A} \sim \boldsymbol{B}$ 이면 $\boldsymbol{B} \sim \boldsymbol{A}$ 이다.

3. $\boldsymbol{A} \sim \boldsymbol{B}$ 이고 $\boldsymbol{B} \sim \boldsymbol{C}$ 이면 $\boldsymbol{C} \sim \boldsymbol{A}$ 이다.

:::


</br>

선형사상의 기저 변환은 선형대수학에서 매우 중요하다. 예를 들어 선형사상이 어떤 기저에서 대각성분을 제외한 성분이 $0$ 이 된다면, 이 선형사상에 대해 매우 다루기 쉬워진다. 벡터공간의 기저를 바꾸는 것은 그 표현만 바뀌는 것일 뿐 벡터공간 자체가 바뀌는 것은 아니기 때문에 이 기저의 변환을 원할 때 원하는 만큼 사용 할 수 있다.

</br>

## 연습문제

::: {#exr-linear_map_1}

$V$ 가 유한차원 벡터공간이고 $L\in \mathcal{L}(V, W)$ 이다. $V$ 의 어떤 부분공간 $U$ 는 $U \cap \ker (L)=\{0\}$ 이며 $\text{im}\,(L)=\{L(u) : u \in U\}$ 임을 보이시오.
:::

::: {.solution}

$\ker (L)$ 의 기저 $(v_1,\ldots,\,v_m)$ 을 확장하여 $V$ 의 기저 $(v_1,\ldots,\,v_m,\,u_1,\ldots,\,u_n)$ 을 구성 할 수 있다(@lem-basis_expansion). $U=\text{span}(u_1,\ldots,\,u_n)$ 이라 놓으면 된다. 

:::


</br>

::: {#exr-dimension_and_injectivity_surjectivity}
$U,\,V$ 가 유한차원 벡터공간일 때 다음을 보여라.

&emsp; ($1$) $U \mapsto V$ 로의 단사인 선형사상이 존재할 필요충분조건은 $\dim(U)\le \dim(V)$ 이다.

&emsp; ($2$) $U \mapsto V$ 로의 전사인 선형사상이 존재할 필요충분조건은 $\dim(U) \ge \dim (V)$ 이다.

:::

::: {.solution}
($1$) $L\in \mathcal{L}(U,\,V)$ 라고 하자. $\dim(V) \ge \text{rank}\,(L) = \dim(U)-\text{nullity}\, (L)$ 임을 안다. $L$ 이 단사이면 $\text{nullity}\,(L)=0$ 이므로 $\dim(V) \ge \dim (U)$ 이다. $n=\dim (V)\ge \dim (U)=m$ 이라고 하자. $V$ 의 기저 $(v_1,\ldots,\,v_n)$ 과 $U$ 의 기저 $(u_1,\ldots,\,u_m)$ 에 대해 $L(u_i)=v_i$, $i=1,\ldots,\,m$ 는 단사인 선형사상이다.

($2$) $L$ 이 전사이면 $\dim(V) = \text{rank}\, (L) = \dim(U) - \text{nullity}\,(L)$ 에 따라 $\dim(U) \ge \dim(V)$ 이다. $m = \dim(U) \ge \dim(V) = n$ 이라 하면 $V$ 의 기저 $(v_1,\ldots,\,v_n)$ 과 $U$ 의 기저 $(u_1,\ldots,\,u_m)$ 에 대해 

$$
L(u_i)=\left\{\begin{array}{ll} v_i \qquad &i=1,\ldots,\,n \\ 0_V & i > n\end{array}\right.
$$

는 전사인 선형사상이다. 
:::

</br>

::: {#exr-inverse_image_of_linear_map}

$L\in \mathcal{L}(U,\,V)$ 이며 어떤 $u\in U$ 에 대해 $L(u)=v$ 일 때 다음을 보여라.

&emsp; ($1$) $L^{-1}(\{v\}) = \{u+x: x\in \ker (L)\}$ 이다.

&emsp; ($2$) $L^{-1}(\{v\})$ 와 $\ker (L)$ 사이에 전단사 함수가 존재한다.

:::

::: {.solution}

($1$) $A = \{u+x: x\in \ker (L)\}$ 라 하자.  $y \in A$ 에 대해 $L(y) = v$ 이므로 $A \subset L^{-1}(\{v\})$ 이다. $y\in U - A$ 에 대해 $y-u\not\in \ker{L}$ 이므로 $L(y)\ne v$ 이다. 따라서 $L^{-1}(\{v\}) = A$ 이다.

($2$) $f:A \to \ker (T)$ 를 $f(y) = y-u$ 로 정의하자. 임의의 $x\in \ker (T)$ 에 대해 $u+x\in A$ 이므로 $f$ 는 전사이다. $y_1-u=y_2-y \implies y_1 = y_2$ 이므로 $f$ 는 단사이다. 

:::

</br>

::: {#exr-axler_3_B_24}

$W$ 가 유한차원 벡터공간이고 $L,\,K\in \mathcal{L}(V, W)$ 일 때 다음은 동치임을 보여라. 

&emsp; ($1$) $\ker (L) \subset \ker (K)$,  

&emsp; ($2$) $K= S L$ 가 되도록 하는 어떤 $S\in \mathcal{L}(W)$ 가 존재한다.

:::

::: {.solution}

($1 \implies 2$) $\text{im}(L)\le W$ 이므로 $\text{im}(L)$ 은 유한차원이다. $(w_1,\ldots,\,w_m)$ 을 $\text{im}(L)$ 의 기저라고 하자. 각각의 $L^{-1}(\{w_i\})$ $(i=1,\ldots,\,m)$ 에서 하나의 벡터를 골라 $v_i$ 라고 하자. $0_V = c_1v_1 + \cdots c_m v_m$ 이라고 하면 $0_W = \sum_{i=1}^m c_i L(v_i) = \sum_{i=1}^m c_i w_i$ 이므로 $c_1=\cdots =c_m=0$ 이다. 즉 $\{v_1,\ldots,\,v_m\}$ 은 선형독립이다. 

이제 $v\in V$ 는 $v=\sum_{i=1}^m c_iv_i + u,\,u\in \ker (L)$ 로 쓸 수 있다. $\ker (L)\subset \ker (K)$ 이므로, $K(v) = \sum_{i=1}^m c_i K(v_i)$ 이다. 

이제 $(w_1,\ldots,\,w_m)$ 을 확장하여 $(w_1, \ldots, w_m, w_{m+1}, \ldots, \,w_n)$ 이 $W$ 의 기저라고 하자. $S\in \mathcal{L}(W)$ 를, 

$$
S(w_i) = \left\{\begin{array}{ll} K(v_i)\qquad &;i \le m \\ 0 &; i>m\end{array} \right.
$$

로 놓으면 $SL = K$ 이다. 

($2 \implies 1$) $v \in \ker (L)$ 이면 $K (v) = SL(v)=0_W$ 이므로 $v\in \ker (K)$ 이다. 즉 $\ker (L)\subset \ker (K)$ 이다.

:::

</br>

::: {#exr-axler_3_B_25}

$V$ 가 유한차원벡터공간이고 $L,\,K\in \mathcal{L}(V,W)$ 일 때 다음은 동치임을 보여라.

&emsp; ($1$) $\text{im}(L) \subset \text{im}(K)$, 

&emsp; ($2$) $L = KS$ 가 되도록 하는 어떤 $S\in \mathcal{L}(V)$ 가 존재한다.

:::

::: {.solution}

($1\implies 2$ ) $\text{im}(L)$ 의 기저 $(w_1,\ldots,\,w_m)$ 을 생각하자. $L^{-1}(\{w_i\})$ 에서 하나의 벡터를 선택하여 $v_i$ 라고 하면 $(v_1,\ldots,\,v_m)$ 은 선형 독립임을 안다(@exr-axler_3_B_24). $(w_1,\ldots,\,w_m)$ 을 확장하여 $(w_1,\ldots,w_m,\, w_{m+1},\ldots, w_{n})$ 이 $\text{im}(K)$ 의 기저가 되도록 하고 $L$ 에서와 같은 방법으로 $(u_1,\ldots,u_m, u_{m+1}, \ldots, u_{n})$ 을 얻는다. 또한 선형독립인 이 벡터를 확장하여 $(v_1,\ldots,\,v_m,\ldots,\,v_n, \ldots,v_N)$ 이 $V$ 의 기저가 되도록 할 수 있다. 이제

$$
S(v_i) = \left\{\begin{array}{ll} u_i, \qquad &;\text{if } i \le m, \\ 0 &;\text{if }i > m. \end{array}\right.
$$

로 놓으면 된다.

($2 \implies 1$) 자명하다.

:::

</br>

::: {#exr-axler_3_B_28}

$L\in \mathcal{L}(V, W)$ 이고 $(w_1,\ldots\,w_m)$ 이 $\text{im}(L)$ 의 기저라고 하자. 어떤 $\varphi_1,\ldots,\,\varphi_m \in \mathcal{L}(V, \mathbb{F})$ 가 존재하여 모든 $v\in V$ 에 대해

$$
L(v) = \varphi_1 (v) w_1 + \cdots + \varphi_m (v)w_n
$$

을 만족함을 보여라.

:::

::: {.solution}

$L^{-1}(\{w_j\})$ 가운데 하나의 벡터를 선택하여 $v_1$ 이라고 하면 $\{v_1,\ldots,\,v_m\}$ 은 선형 독립이다(@exr-axler_3_B_24). 이를 확장하여 $V$ 의 기저 $(v_1,\,v_2,\ldots)$ 를 얻을 수 있다. $\phi_i \in \mathcal{L}(V, \mathbb{F})$, $(i=1,\ldots,\,m)$ 를 다음과 같이 정의하자.

$$
\varphi_i (v_j) = \delta_{ij}
$$

그렇다면 $v=\sum_i c_i v_i$ 에 대해 

$$
\varphi_i (v) = \varphi_i \left( \sum_j c_j v_j\right) = \sum_{i=1}^m c_j \delta_{ij} = c_i 
$$

이며, 

$$
L(v) = L\left(\sum_i c_i v_i\right) = \sum_{i=1}^m \varphi_i (v) L(v_i) = \sum_{i=1}^m \varphi_i (v) w_i
$$

이다.

:::

</br>

::: {#exr-axler_3_B_29}

$\varphi \in \mathcal{L}(V, \mathbb{F}),\, \varphi \ne 0$ 에 대해 $u \in V- \ker(\varphi)$ 일 때, 

$$
V = \ker (\varphi) \oplus \{au : a\in \mathbb{F}\}
$$

임을 보여라.

:::

::: {.solution}

$U=\{au:a\in \mathbb{F}\}$ 라고 하자. $\ker (\varphi) \cap U=\{0_V\}$ 이므로 $\ker (\varphi) + U = \ker (\varphi)\oplus U$ 이다. $\varphi \ne 0$ 이므로 $\text{rank}(\varphi)=1$ 이며 따라서 $u$ 의 스칼라곱이 아닌 벡터는 모두 $\ker (\varphi)$ 에 포함된다. 즉 $V = \ker (\varphi)\oplus U$ 이다.

:::


</br>

::: {#exr-axler_3_B_30}

$\varphi_1,\,\varphi_2 \in \mathcal{L}(V,\mathbb{F})$ 이며 $\ker (\varphi_1) = \ker (\varphi_2)$ 라면 어떤 $c\in \mathbb{F}$ 에 대해 $\varphi_1 = c\varphi_2$ 임을 보여라.

:::

::: {.solution}

$u\notin \ker (\varphi_2) \iff u \not\in \ker (\varphi_2)$ 이며 @exr-axler_3_B_29 에 의해 $\text{im}(\varphi_1) =  \text{im}(\varphi_2) = \{au\}$ 이다. 따라서 $\varphi_1 = c\varphi_2$ 를 만족하는 $c\in \mathbb{F}$ 가 존재한다. 

:::


</br>

::: {#exr-axler_3_8_9}

유한차원 벡터공간 $U$ 에서 정의된 연산자 $K,\,L\in \mathcal{L}(U)$ 에 대해 $K,\,L$ 이 각각 가역일 필요충분조건은 $KL$ 이 가역인것임을 보이시오.

:::

::: {.solution}

$K,\,L$ 이 전사이면 $KL$ 도 전사이다. $KL$ 이 전사이면 $K, L$ 도 각각 전사이다. 유한차원 벡터공간에서의 연산자므로 전사이면 전단사이다.

:::

</br>


::: {#exr-axler_3_8_10}

유한차원 벡터공간 $U$ 에서 정의된 연산자 $K, L\in \mathcal{L}(U)$ 에 대해 $KL=I$ 일 필요충분조건은 $LK=I$ 인것임을 보이시오.
:::


::: {.solution}

($\implies$) $KL=I$ 임을 가정하자. @exr-axler_3_8_9 에 의해 $K,\,L$ 도 가역이다. 모든 $u\in U$ 에 대해 $KL(u)=u$ 이며 $K$ 가 가역이므로 $K(v)=u$ 인 $v\in V$ 가 유일하게 정해지며 따라서 $L(u)=v$ 이다. $LK(v) = v$ 이므로 $LK=I$ 이다.

($\,\Longleftarrow\,$) $K,\,L$ 을 바꿔서 위의 증명을 그대로 쓸 수 있다.
:::

</br>

::: {#exr-axler_3_8_11}

유한차원 벡터공간 $U$ 에 대해 $R, S, T = \mathcal{L}(U)$ 일 때 $RST=I$ 이면 $S$ 는 가역이며 $S^{-1}= TR$ 임을 보여라. $U$ 가 유한차원이라는 조건이 없다면 성립하지 않을 수도 있음을 보여라.

:::

::: {.solution}

$U$ 가 유한차원 벡터공간이고 $RST=I$ 이면 $RST$ 모두 가역이며, $S=R^{-1}T^{-1}$ 이므로 $S^{-1}= TR$ 이다. 

이제 $U = \mathbb{R}^\infty$ 라고 하자. 

$$
\begin{aligned}
R(x_1, x_2, x_3,\ldots) &= (x_2, x_3, x_4, \ldots), \\
S(x_1, x_2, x_3, \ldots)  &= (0, x_1, x_2, x_3, \dots,), \\
T & = I
\end{aligned}
$$


라고 하면 $RST=I$ 이지만 $S$ 는 전사가 아니다.

::: 

</br>

::: {#exr-axler_3_D_3}

$V$ 가 유한차원 벡터공간이고 $U \le V$ 이며 $S\in \mathcal{L}(U, V)$ 일 때 다음이 동치임을 보이시오.

&emsp; ($1$) $S$ 는 단사이다.

&emsp; ($2$) 모든 $u\in U$ 에 대해 $T(u) = S(u)$ 를 만족하는 가역인 $T\in \mathcal{L}(V)$ 가 존재한다.

:::

::: {.solution}

($1 \implies 2$) $U$ 의 기저 $\{ u_1,\ldots,\,u_m \}$ 에 대해 $S(u_i) = v_i$ 라고 하자. $S$ 가 동형이므로 $\{v_1,\ldots,\,v_m \}$ 도 선형 독립이다. $\{u_1,\ldots,\,u_m\}$ 을 확장하여 $V$ 의 기저 $\{u_1,\ldots,\,u_m,\,u_{m+1}, \ldots, v_n\}$ 을 구성 할 수 있으며, $\{v_1,\ldots,\,v_m\}$ 을 확장하여 $V$ 의 기저 $\{v_1,\ldots,\,v_m,\,v_{m+1}, \ldots, v_m\}$ 을 구성 할 수 있다. 이 때 $T\in \mathcal{L}(V)$ 를 $T(u_i) = v_i$ $(i=1,\ldots,\,m)$ 으로 정의하면 된다.

($2 \implies 1$) $T$ 가 가역이므로 $T$ 는 단사이다. $S$ 가 단사가 아니라면 $T$ 도 단사가 아니므로 $S$ 는 단사이다. 
:::

</br>

::: {#exr-axler_3_D_4}

$W$ 가 유한차원벡터공간이며 $L,\,K\in \mathcal{L}(V, W)$ 일 때 다음이 동치임을 보여라.

&emsp; ($1$) $\ker (L) = \ker (K)$, 

&emsp; ($2$) $L = SK$ 가 되도록 하는 가역연산자 $S\in \mathcal{L}(W)$ 가 존재한다.

:::

::: {.solution}

($1 \implies 2$) @exr-axler_3_B_24 로 부터 $K = S_1L$, $L = S_2K$ 를 만족하는 $S_1,\,S_2\in \mathcal{L}(W)$ 가 존재하며 $K = S_1S_2K$ 이므로 $S_1S_2$ 는 가역이다. 따라서 $S_1,\,S_2$ 각각 가역이다.

($2 \implies 1$) 자명하다.

:::

</br>

::: {#exr-axler_3_D_5}

$V$ 가 유한차원 벡터공간이며 $L,\,K\in \mathcal{L}(V, W)$ 일 때 다음이 동치임을 보여라.

&emsp; ($1$) $\text{im}(L) = \text{im}(K)$, 

&emsp; ($2$) $L = KS$ 를 만족하는 가역연산자 $S\in \mathcal{L}(V)$ 가 존재한다.
:::

::: {.solution}
($1 \implies 2$) @exr-axler_3_B_25 로부터 $L = KS_2$, $K = LS_1$ 이 되도록 하는 $S_1,\,S_2\in \mathcal{L}(V)$ 가 존재함을 안다. $L = L S_1S_2$ 이므로 $S_1S_2$ 는 가역이다. 따라서 $S_1, S_2$ 는 각각 가역이다.

($2 \implies 1$) 자명하다.

:::

</br>

::: {#exr-axler_3_D_6}

$V, W$ 가 유한차원 벡터공간이며 $L,\,K\in \mathcal{L}(V, W)$ 일 때 다음이 동치임을 보여라.

&emsp; ($1$) $\text{nullity}(L) = \text{nullity}(K)$.

&emsp; ($2$) $L = SKR$ 을 만족하는 가역연산자 $S\in \mathcal{L}(W),\, R\in \mathcal{L}(V)$ 가 존재한다. 

:::

::: {.solution}

($1 \implies 2$) $\ker (L)$ 을 $\ker (K)$ 로 변환하는 연산자 $R\in \mathcal{L}(V)$ 가 존재한다. 즉 $\ker (K) =  \ker (KR)$ 이다. @exr-axler_3_D_4 에 의해 $L = SKR$ 을 만족하는 $\in \mathcal{L}(W)$ 가 존재한다.

($2 \implies 1$) 자명하다.

:::

</br>

::: {#exr-axler_3_D_16}

유한차원 벡터공간 $V$ 에 대해 $L\in \mathcal{L}(V)$ 이 모든 $S\in \mathcal{L}(V)$ 에 대해 $SL=LS$ 이면 $L$ 은 항등사상 $I$ 의 스칼라곱임을 보여라. 즉 어떤 스칼라 $c$ 에 대해 $L=cI$ 임을 보여라.

:::

::: {.solution}
$V$ 의 기저 $(v_1,\ldots,\,v_n)$ 을 생각한다. $S_j (v_k) = \delta_{jk}v_k$ 는 선형연산자이다. 그리고 $L(v_i) = \sum_{k=1}^n A_{ki} v_k$ 라고 하자. 

$$
\begin{aligned}
S_jL(v_i) &= A_{ji}v_j ,\\
LS_j (v_i) &= L(\delta_{ij}v_i)=\delta_{ij}\left(\sum_{k=1}^n A_{ki}v_k\right),
\end{aligned}
$$

이며, $S_jT = TS_j$ 로부터 $i\ne j$ 에 대해 $A_{ij}=0$ 이라는 것을 알 수 있다. 즉 $L(v_i) = c_i v_i$ 이다. 이제 $S_{ij} \in \mathcal{L}(V)$ 를 다음과 같이 정의하자.

$$
S_{ij}(v_k) =\left\{\begin{array}{ll} v_i, \qquad &;\text{if } k = j \\ v_j, &; \text{if } k = i, \\ 0 &;\text{otherwise}. \end{array}\right.
$$

그렇다면, 

$$
\begin{aligned}
S_{ij}L(v_i) &= S_{ij}(c_iv_i)= c_iv_j, \\
LS_{ij}(v_j) &= L(v_j) = c_j v_j
\end{aligned}
$$

이므로 $c_i = c_j$ 이다. 따라서 $T=cI$ 꼴이어야 한다.

:::


