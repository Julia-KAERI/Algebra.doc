---
title: "벡터와 벡터공간"
number-sections: true
number-depth : 3
crossref:
  chapters: true
---

{{< include ../../latexmacros.qmd >}}

</br>

## 기본적인 개념

### 스칼라 (Scalar)

실수의 집합 $\mathbb{R}$ 이나 복소수의 집합 $\mathbb{C}$ 는 수학적으로 체(field) 라고 불리는 사칙연산이 잘 정의된 집합이다. $\mathbb{R},\,\mathbb{C}$ 이외에도 체가 존재하지만 여기서는 이 둘만 다루기로 한다. 체의 원소를 **스칼라(scalar)** 라 한다. $\mathbb{F}$ 는 $\mathbb{R}$ 과 $\mathbb{C}$ 를 같이 생각하는 경우 사용한다.

복소수의 경우 $x,\, y\in \mathbb{R}$ 일 때 $z=x+yi$ 로 표현 할 수 있다. 이 때 $x$ 를 복소수 $z$ 의 실수부, $y$ 를 허수부라고 하며 $\text{Re}(z)=x$, $\text{Im}(z)=y$ 이다. $z=x+iy,\, x,\,y\in \mathbb{R}$ 에 대해 $z$ 의 켤레복소수 $\overline{z}$ 는 $\overline{z}=x-iy$ 로 정의된다.

</br>

### 행렬 (Matrix)

수(Number), 기호, 수식 등의 수학적 대상을 2차원 격자에 배치한 것을 **행렬(matrix)** 이라고 한다. $m\times n$ 행렬은 세로로 $m$ 칸, 가로로 $n$ 칸의 격자에 배치한 행렬이다. 예를 들어, 

$$
\boldsymbol{A} = \begin{bmatrix} 1 & 2 & 3 \\ 4 & 5 & 6\end{bmatrix}
$$

은 $2 \times 3$ 행렬이다. 행렬에서 가로로 된 한 줄을 행이라 하고, 세로로 된 한 줄을 열이라 한다. 행렬 $\boldsymbol{A}$ 에서 $\begin{bmatrix} 1 & 2 & 3\end{bmatrix}$ 는 행이고, $\begin{bmatrix} 1 \\ 4 \end{bmatrix}$ 는 열이다. 행렬을 이루는 각각의 수학적 대상을 **원소(element)** 혹은 **성분(entry)** 이라 한다. 행렬 $\boldsymbol{A}$ 는 $1$, $2$, $3$, $4$, $5$, $6$ 의 $6$ 개의 성분을 가지며, 보통 $m\times n$ 행렬은 $mn$ 개의 성분을 가진다. 

$(\boldsymbol{A})_{ij}$ 혹은 기울어진 일반글씨체의 $A_{ij}$ 는 행렬 $\boldsymbol{A}$ 의 $i$ 번째 행, $j$ 번째 열을 지칭한다. 행은 위부터 $1,\,2,\ldots$ 순서로 세며, 열은 왼쪽부터 $1,\,2,\ldots$ 의 순서로 센다. 즉 $A_{11}=1$ 이며 $A_{23}=6$ 이다. 

::: {.callout-warning appearance="simple" icon="false"}
여기서 행렬을 표기할때는 $\boldsymbol{A}$ 와 같은 기울어진 굵은 글씨체 대문자를 쓰지만, 행렬의 성분을 표기할때는 편의에 따라 $(\boldsymbol{A})_{ij},\, \boldsymbol{A}_{ij}$ 나, 혼동의 여지가 없다고 판단될 경우 $A_{ij}$ 와 같이 일반글씨체 대문자를 사용하도록 하겠다.
:::

실수 성분을 갖는 $m \times n$ 행렬 전체의 집합을 $\mathcal{M}_{m \times n}(\mathbb{R})$ 으로 표기한다. 마찬가지로 복소수 성분을 갖는 $m \times n$ 행렬 전체의 집합을 $\mathcal{M}_{m \times n}(\mathbb{C})$ 으로 표기하도록 한다.


</br>

### 순서집합 (Ordered set)
::: {.callout-note appearance="simple" icon="false"}

::: {#def-ordered_set}

### 순서집합

일반적으로 $\{y_1,\,y_2,\ldots\}$ 처럼 기술되는 집합은 집합 내의 원소를 나열하는 순서가 중요하지 않다. 하지만 그 순서가 중요한 경우가 있는데 이 경우 집합에 순서를 부여하여 $(x_1,\,x_2,\,x_3,\ldots)$ 와 같이 $(\quad)$ 안에 나열하여 표현한다. 즉, $\{a,\,b\} = \{b,\,a\}$ 이지만 $(a,\,b) \ne (b,\,a)$ 이다. 순서집합의 대표적인 경우가 수열이다.

:::
:::
</br>

### 데카르트 곱

::: {.callout-note appearance="simple" icon="false"}

::: {#def-cartesian_product}

#### 데카르트곱

집합 $A$ 와 $B$ 에 대해 $A$ 와 $B$ 의 원소로 이루어진 새로운 집합 $A\times B$ 를 다음과 같이 정의하자.

$$
A \times B = \{(a,\,b) : a\in A,\, b \in B\}
$$

이렇게 정의된 집합을 데카르트 곱이라 한다. $\mathbb{R}\times \mathbb{R} \times \mathbb{R}$ 을 생각해보자, 

$$
\mathbb{R}\times \mathbb{R} \times \mathbb{R} = \{ (x_1,\,x_2,\,x_3) : x_1\in\mathbb{R},\, x_2\in\mathbb{R},\, x_3\in \mathbb{R}\}
$$

이다. 이것을 간략히 하여 $\mathbb{R}^3$ 로 표현 할 수 있다. 우리는 이로부터 $\mathbb{C}^4$ 가 어떤 것을 의미하는지 알 수 있을 것이다. 

집합 $V_1,\ldots,\,V_m$ 에 대해 $V=V_1 \times \cdots \times V_m$ 이라 하자. $v\in V$ 라면 $v=(v_1,\ldots,\,v_m)$ 이며 $v_i \in V_i$ 이다. 이 때 $v_i$ 를 $v$ 의 $i$ 번째 **성분**, 혹은 $i$ 번째 **좌표**라고 한다.

:::
:::

</br>


::: {.callout-warning appearance="simple" icon="false"}
보통 $\mathbb{R}^3$ 는 실수의 데카르트곱에 유클리드 거리를 부여한 3차원 실수 공간을 의미하기도 한다. 
:::

</br>

### 크로네커 델타 함수

앞으로 많이 사용될 간단하지만 유용한 함수가 있다.

::: {.callout-note appearance="simple" icon="false"}
::: {#def-kroneker_delter}
#### 크로네커 델타 함수
$i,\,j$ 가 정수일 때 다음과 같이 정의된 함수 $\delta_{ij}$ 를 크로네커 델타 함수 (Kronecker delta function)라고 한다.

$$
\delta_{ij} = \left\{\begin{array}{ll} 1 \qquad &\text{if } i = j, \\ 0 &\text{otherwise}. \end{array}\right.
$$
:::
:::

</br>

## 벡터공간과 벡터 


### 벡터공간 

벡터공간을 정의하기 위해서는 어떤 집합 $V$ 와 체(field) $\mathbb{F}$, 그리고 $V$ 의 원소끼리의 덧셈과, $V$ 의 원소와 $\mathbb{F}$ 의 원소의 곱이 정의되어야 한다. 이 때, 집합 $V$ 과 체 $\mathbb{F}$ 에 대해 아래의 성질을 만족하면 집합 $V$ 를 $\mathbb{F}$ 위에서의 **벡터공간(vector space)**  혹은 **$\mathbb{F}$-벡터공간** 이라 한다.

1. $V$ 의 원소 $v$ 와 $\mathbb{F}$ 의 원소 $a$ 의 곱은 $av$ 라 쓰며 $V$ 에 포함된다.

2. $V$ 는 덧셈에 대해 닫혀 있다.

3. $V$ 의 두 원소 사이의 덧셈에 대한 교환법칙이 성립한다. 즉 $u,\,v\in V$ 일 때 $u + v = v + u$ 이다.

4. $V$ 의 원소사이의 덧셈에 대해 결합법칙이 성립한다. 즉 $u,\,v,\,w \in V$ 일 때 $(u+v)+w = u+(v+w)$ 이다.

5. $V$ 의 원소와 두 두 스칼라 사이에 곱셈에 대한 결합법칙이 성립한다. 즉 $v\in V$ 이고 $a,\,b\in V$ 일 때 $a(bv)=(ab)v$ 이다.

6. 어떤 $0_V \in V$ 가 존재하여 모든 $v\in V$ 에 대해 $v+0_V = 0_V +v= v$ 이다.

7. 각각의 $v\in V$ 에 대해 $v+w=w+v=0_V$ 을 만족하는 $w\in V$ 가 존재한다. 이 때 $v$ 의 덧셈에 대한 역원을 $-v$ 라고 쓴다.

8. 체의 곱셈에 대한 항등원 $1_\mathbb{F}$ 에 대해 $v\in V$ 이면 $1_\mathbb{F} v = v$ 이다.

9. 다음과 같은 분배법칙을 만족한다.

$$
u,\,v \in V,\, a,\, b\in \mathbb{F} \implies a(u+v)=au + av,\, (a+b)v = av+bv
$$

이 조건을 만족하는 벡터공간 $V$ 의 원소를 **벡터 (vector)** 라 한다. 6. 에 나오는 벡터공간 $V$ 에서 덧셈에 대한 항등원인 벡터를 영벡터라 하고 $0_V$ 라 쓴다. 혼돈의 여지가 없을 경우는 단순히 $0$ 으로만 쓸 수 도 있다.


이것을 수학적으로 다시 정리하면 다음과 같다.

</br>

::: {.callout-note appearance="minimal"}

::: {#def-vector_space_2}
#### 벡터공간과 벡터

어떤 집합 $V$ 와 체 $\mathbb{F}$ 에 대해 $V$ 의 원소 사이의 덧셈과 $\mathbb{F}$ 와 $V$ 사이의 곱셈이 정의되어 있으며, 다음이 성립하면 $V$ 를 **$\mathbb{F}$ 위에서의 벡터공간** 혹은 **$\mathbb{F}$-벡터공간** 이라 한다.

&emsp;($1$) $u,\,v \in V ,\, a\in \mathbb{F} \implies u+v = v+u \in V$, $av\in V$,

&emsp;($2$) $u,\,v,\,w \in V,\, a,\, b\in \mathbb{F} \implies (u + v) + w = u+(v+w)$, $(ab)v = a(bv)$,

&emsp;($3$) $\exists 0_V\in V\, \forall v\in V,\, v + 0_V=0_V+v = v$,

&emsp;($4$) $\forall v\in V \;\exists w\in V$ s.t. $v + w = 0_V$,

&emsp;($5$) $\forall v \in V \implies 1v =v$,

&emsp;($6$)  $u,\,v \in V,\, a,\, b\in \mathbb{F} \implies a(u+v)=au + av,\, (a+b)v = av+bv$.

벡터공간 $V$ 가 정의되었을 때 벡터공간의 원소를 **벡터(vector)** 라 한다. $\mathbb{R}$ 위에서의 벡터 공간을 **실벡터공간(real vector space)** 혹은 **$\mathbb{R}$-벡터공간**, $\mathbb{C}$ 위에서의 벡터 공간을 **복소벡터공간(complex vector space)** 혹은 **$\mathbb{C}$-벡터공간** 이라 한다. 

:::

:::

</br>

::: {.callout-warning appearance="simple" icon="false"}
앞으로 $u,\,v,\,w$ 세 문자는 벡터를 나타내는 문자로 고정하며, 다른 볼드체가 아닌 수학적 문자는 특별한 언급이 없을 경우 스칼라를 의미한다. $0$ 은 문맥에 따라 스칼라 $0$ 을 의미할 수도 있고, $0$ 벡터를 의미할 수도 있다.
:::

</br>

앞으로 $\mathbb{F}$-벡터공간이라는 용어가 많이 등장할 것이다. 이 경우 하나의 명제나 문제 안에서 $\mathbb{F}$ 는 $\mathbb{R}$ 혹은 $\mathbb{C}$ 로 고정된다. 예를 들어 $\mathbb{F}$-벡터공간인 $U,\,V$ 라고 했다면 $U, V$ 는 둘 다 $\mathbb{R}$-벡터공간이거나, 둘 다 $\mathbb{C}$-벡터공간이라고 간주되어야 하며, 둘중 하나는 $\mathbb{R}$-벡터공간, 다른 하나는 $\mathbb{C}$-벡터공간이어서는 안된다.


</br>
<div class="border" style="background-color:#FFF0F5 ;padding:5px;">
::: {#prp-zero_one_vector}

벡터공간 $V$ 와 $v\in V$ 그리고 영벡터 $O_V$ 에 대해 다음이 성립한다.

&emsp;($1$) 영벡터는 유일하다.
  
&emsp;($2$) $0v = 0_V$
  
&emsp;($3$) $(-1)v = -v$
:::

</div>
</br>

::: {.proof}

($1$) 두 영벡터를 각각 $0_V$ 와 $0'_V$ 라고 하자. $0_V = 0_V+0'_V = 0'_V$.

($2$) $0v = (0+0)v = 0v + 0v$ 이므로 $0v = 0_V$ 이다.

($3$) $0_V = 0v =  (1-1)v = v + (-v)$. 이므로 $v$ 의 덧셈에 대한 역원인 $-v$ 는 $(-1)v$ 이다. $\square$

:::

</br>


### 중요한 벡터공간들

아래의 보기는 앞으로 자주 등장할 벡터공간이다. 

<div class="border" style="background-color:#F2F4F4  ;padding:5px;">

::: {#exm-vectorspace_F}
$\mathbb{F}$ 는 $\mathbb{F}$-벡터공간이다.
:::
</div></br>

<div class="border" style="background-color:#F2F4F4  ;padding:5px;">

::: {#exm-vectorspace_Rn}
데카르트 곱 $\mathbb{R}^2 = \{ (x,\,y): x\in \mathbb{R},\, y\in \mathbb{R}\}$ 을 생각하자. 덧셈과 스칼라곱을 $(x_1,\, y_1) + (x_2,\,y_2) = (x_1+x_2,\, y_1+y_2)$, $a(x,\, y) = (ax,\, ay)$ 로 정의하면 $\mathbb{R}^2$ 가 $\mathbb{R}$ 위의 벡터공간임을 쉽게 알 수 있다. 이로부터 임의의 0이 아닌 자연수 $n$ 에 대해 $\mathbb{R}^n$ 이 $\mathbb{R}$-벡터공간이고, $\mathbb{C}^n$ 이 $\mathbb{C}$-벡터공간임을 알 수 있다. 
:::

</div></br>

<div class="border" style="background-color:#F2F4F4  ;padding:5px;">

::: {#exm-vectorspace_CnRn}
합과 스칼라곱이 아래와 같이 정의된 데카르트곱 $\mathbb{R}^n$ 과 $\mathbb{C}^n$ 을 생각하자.

$$
(x_1,\ldots,\,x_n) + a(y_1,\ldots,\,y_n) = (x_1 + ay_n, \ldots,\, x_n+ay_n)
$$  

이 때 $\mathbb{C}^n$ 은 $\mathbb{R}$-벡터공간이다. 그러나 $\mathbb{R}^n$ 은 $\mathbb{C}$-벡터공간이 될 수 없다. 
:::
</div></br>

<div class="border" style="background-color:#F2F4F4  ;padding:5px;">

::: {#exm-vectorspace_polynomial}
다항식 $p(x) = a_0 + a_1 x + \cdots + a_n x^n$ 을 생각하자. $a_n\ne 0$ 일 때 $p(x)$ 를 $n$ 차 다항식이라고 하며 이때의 $n$ 값을 다항식 $p(x)$ 의 **차수 (degree)** 라고 하고 $\deg (p)$ 혹은 $\deg (p(x))$ 라고 표기한다. 굳이 0차 다항식이라고 이름을 붙이지는 않지만 상수함수도 다항식에 포함된다. 앞으로 $\mathbb{F}$ 값을 계수로 갖는 변수 $t$ 에 대한 다항식의 집합을 $\mathbb{F}[t]$ 라고 표기하며, $\mathbb{F}_n[t]$ 는 $n$ 차를 포함하여 그 이하의 차수를 갖는 다항식의 집합을 의미한다. 예를 들어 $\mathbb{R}_3[t]$ 는 3차 이하의 차수를 갖는 실계수 다항식의 집합을 말한다. 0 이상의 정수 $n$ 에 대해 $\mathbb{F}_n[t]$ 은 $\mathbb{F}$-벡터공간이다. 또한 $\mathbb{F}[t]$ 도 벡터공간이다.
:::

</div></br>

<div class="border" style="background-color:#F2F4F4  ;padding:5px;">

::: {#exm-vectorspace_matrix}
실계수를 갖는 $m \times n$ 행렬의 집합을 $\mathcal{M}_{m \times n}(\mathbb{R})$ 이이라고 하기로 하였다. $\boldsymbol{A},\,\boldsymbol{B}\in \mathcal{M}_{m \times n}(\mathbb{R})$ 일 때 두 행렬을 더하면 그 결과는 같은 크기의 행렬이며 더하여 나온 행렬의 성분은 같은 위치에서의 $\boldsymbol{A}$ 와 $\boldsymbol{B}$ 의 성분의 합으로 정의하자. 즉,

$$
(\boldsymbol{A}+\boldsymbol{B})_{ij} = (\boldsymbol{A})_{ij} + (\boldsymbol{B})_{ij}
$$
이라 정의한다. 스칼라와 행렬의 곱셈은 행렬의 각 성분의 스칼라곱으로 정의하자. 즉, 

$$
(a\boldsymbol{A})_{ij} = a(\boldsymbol{A})_{ij}
$$

이라 정의하자. 그렇다면 $\mathcal{M}_{m \times n}(\mathbb{R})$ 은 $\mathbb{R}$-벡터공간이다. $\mathcal{M}_{m \times n}(\mathbb{C})$ 이 $\mathbb{C}$-벡터공간임은 쉽게 보일 수 있다. 즉 체 $\mathbb{F}$ 를 원소로 갖는 $m\times n$ 행렬의 집합을 $\mathcal{M}_{m \times n}(\mathbb{F})$ 이라 하면 $\mathcal{M}_{m \times n}(\mathbb{F})$ 은 $\mathbb{F}$-벡터공간이다.
:::

</div></br>

<div class="border" style="background-color:#F2F4F4  ;padding:5px;">

::: {#exm-vectorspace_row_column}

#### 행벡터와 열벡터

@exm-vectorspace_matrix 에서 $\mathcal{M}_{m\times n}(\mathbb{F})$ 은 벡터공간임을 보였다. 이중에서 특히 $\mathcal{M}_{n \times 1}(\mathbb{F})$ 의 원소를 **열벡터**라고 한다. 특별히 열벡터공간은 $\mathcal{M}_{n}(\mathbb{F})$ 라고 쓰기로 하자. $\mathcal{M}_{1 \times n}(\mathbb{F})$ 의 원소를 **행벡터** 라고 한다.

:::

</div></br>

<div class="border" style="background-color:#F2F4F4  ;padding:5px;">

::: {#exm-continuous_function}
$C_{(a,\,b)}$ 를 $(a,\,b)$ 구간에서 연속인 실함수의 집합이라고 하자. 이 때 $C_{(a,\,b)}$ 는 $\mathbb{R}$-벡터공간이다. 실수 영역 전체에서 연속인 함수의 집합 $C_{\mathbb{R}}$ 역시 $\mathbb{R}$-벡터공간이다.
:::

</div></br>

## 부분공간과 직합

### 부분공간 

::: {.callout-note appearance="simple" icon="false"}
::: {#def-subspace}

#### 부분공간 

$V$ 가 $\mathbb{F}$-벡터공간이라 하자. $U$ 가 $V$ 의 부분분집합이며, $\mathbb{F}$-벡터공간일 때 $U$ 를 $V$ 의 **부분공간 (subspace)** 혹은 **부분벡터공간** 이라 한다.
:::
:::

$U$ 가 $V$ 의 부분공간 일 때 $U\le V$ 라 표기하겠다.

</br>
<div class="border" style="background-color:#F2F4F4  ;padding:5px;">

::: {#exm-subspace_0}
벡터공간 $V$ 는 자기 자신의 부분공간이다. $V$ 가 벡터공간일 때 $\{0_V\}$ 도 $V$ 의 부분공간이다.
:::

</div></br>

<div class="border" style="background-color:#F2F4F4  ;padding:5px;">

::: {#exm-intersection_of_two_spaces}

$U,\,V$ 가 벡터공간일 때 $U \cap V$ 도 벡터공간이다.
:::
</div></br>

<div class="border" style="background-color:#F2F4F4  ;padding:5px;">

::: {#exm-subspace_1}
앞서 언급한 벡터공간 $\mathbb{R}^2$ 에 대해 $A= \{ (x,\,0) : x\in \mathbb{R} \}$ 은 $\mathbb{R}^2$ 의 부분집합이며 벡터공간이므로 부분벡터공간이다. $B=\{(x,\, x) : x\in \mathbb{R}\}$ 역시 $\mathbb{R}^2$ 의 부분벡터공간임은 쉽게 알 수 있다.
:::
</div>
</br>

<div class="border" style="background-color:#F2F4F4  ;padding:5px;">

::: {#exm-subspace_2}
@exm-vectorspace_polynomial 에서 정의한 $\mathbb{R}_n[t]$ 을 생각하자. $m \le n$ 일 때, $\mathbb{R}_m[t]$ 는 $\mathbb{R}_n[t]$ 의 부분공간이다.
:::

</div></br>

<div class="border" style="background-color:#F2F4F4  ;padding:5px;">

::: {#exm-subspace_2}
$\mathbb{C}^2$ 는 $\mathbb{C}$-벡터공간이다. $\mathbb{R}^2$ 는 $\mathbb{C}^2$ 의 부분집합이지만 $\mathbb{C}$-벡터공간이 아니므로 ($i(1,\,1) = (i,\, ,i) \not\in \mathbb{R}^2$) $\mathbb{C}^2$ 의 부분공간이 아니다. 그러나, $\mathbb{C}^2$ 는 $\mathbb{R}$-벡터공간이기도 하다. 그렇다면 $\mathbb{R}^2$ 는 $\mathbb{R}$- 벡터공간 $\mathbb{C}^2$ 의 부분공간이 된다.


요컨데, $\mathbb{C}$ 위에서의 $\mathbb{C}^2$ 와 $\mathbb{R}$ 위에서의 $\mathbb{C}^2$ 는 다른 벡터공간이며, 부분집합이 부분공간인지 아닌지를 따질 때에 어떤 체(field) 위에서의 벡터공간인지가 중요하다. 엄밀하게 말하면 체 $\mathbb{F}$ 위에서의 벡터공간 $V$ 에서 벡터합 $+$ 와 벡터의 스칼라곱 $\cdot$ 이 정의되었을 때 $(V,\,\mathbb{F},\, +,\, \cdot)$ 과 같이 써야한다. 여기서는 이렇게 까지는 하지 않겠다.
:::

</div></br>

::: {.callout-warning appearance="simple" icon="false"}
명제, 정리, 보조정리, 따름정리 등에 대한 증명이 아주 쉬운 경우는 언급도 없이 증명을 생략 할 수 있다.
:::

</br>

<div class="border" style="background-color:#FFF0F5 ;padding:5px;">

::: {#prp-subspace_1}

벡터공간 $V$ 에 대해 $U\le V$ 이고 $W \le U$ 이면 $W \le V$ 이다.

:::

</div></br>

### 합공간과 직합 {#sec-direct_sum}

::: {.callout-note appearance="simple" icon="false"}
::: {#def-sum_of_subspace}

#### 합공간

$V_1,\,V_2,\ldots,\,V_m$ 이 모두 $V$ 의 부분공간 일 때 $V_1+\cdots + V_m$ 을 다음과 같이 정의하며 $V_1,\ldots,\,V_m$ 에 의한 **부분공간의 합** 혹은 **합공간** 이라 한다.

$$
V_1 + \cdots + V_m = \{v_1 + \cdots + v_m : v_1\in V_1,\ldots,\,v_m\in V_m\}
$$
:::

:::

</br>
<div class="border" style="background-color:#FFF0F5 ;padding:5px;">

::: {#prp-sum_of_subspace}

$V_1 \le V,\, V_2 \le V$ 일 때 $V_1+ V_2 \le V$ 이다. 따라서 $V$ 의 부분공간 $V_1, \ldots,\,V_m$ 의 합공간도 $V$ 의 부분공간이다.

:::

</div></br>

::: {.callout-note appearance="simple" icon="false"}

::: {#def-directsum}

#### 직합

$V_1,\,V_2,\ldots,\,V_m$ 이 모두 $V$ 의 부분공간 일 때 $V_0=V_1 + \cdots + V_m$ 라 하자. 

모든 $v\in V_0$ 를 $v=v_1 + \cdots + v_m,\, v_i \in V_i,\, i=1,\ldots, m$ 로 나타내는 방법이 한가지 뿐일 때 이를 $V_1,\ldots,\,V_m$ 의 **직합(direct sum)** 이라 하고 $V_1 \oplus \cdots \oplus V_m$ 으로 쓰거나 ${\displaystyle \bigoplus_{i=1}^m} V_i$ 로 쓴다.
:::
:::

</br>

<div class="border" style="background-color:#FFF0F5 ;padding:5px;">

::: {#thm-directsum}

#### 직합의 조건

$V$ 의 부분공간 $V_1,\ldots,\,V_m$ 에 대해 다음은 동치이다.

&emsp;($1$) $V_1+ \cdots + V_m = V_1 \oplus \cdots \oplus V_m$ 이다.
  
&emsp;($2$) $v_i\in V_i$ 에 대해 $v_1+\cdots + v_m = 0_V$ 인 경우는 $v_1 = \cdots = v_m = 0_V$ 뿐이다.

:::
</div></br>

::: {.proof}

(1 $\implies$ 2) 직합의 정의에 의해 자명하다.

(2 $\implies$ 1) $0_V =v_1 + \cdots + v_m,\, v_i\in V_i$ 이 한가지로만 표현된다고 하자. 만약 어떤 $v\in V$ 가 두가지 방법으로 $v = v_1 + \cdots + v_m = v'_1 + \cdots + v'_m,\, v_i,\, v'_i \in V_i$ 표현된다면 $0_V= (v_1 -v'_1) + \cdots + (v_m - v'_m)$ 이므로 $u_i = u'_i,\, i=1,\ldots, m$ 이다. 즉 $v$ 를 $v_i$ 의 합으로 나타내는 방법은 한가지 뿐이므로 $V_1 + \cdots + V_m$ 은 직합이다. $\square$
:::

</br>
<div class="border" style="background-color:#FFF0F5 ;padding:5px;">
::: {#prp-condition_for_direct_sum}


$V_1,\,V_2$ 가 $V$ 의 부분공간일 때 $V_1+ V_2 = V_1\oplus V_2$ 일 필요충분조건은 $V_1 \cap V_2 = \{0_V\}$ 이다.
:::
</div></br>

::: {.proof}

$V_1+V_2 = V_1 \oplus V_2$ 임을 가정하자. $v\in V_1 \cap V_2$ 라면 $v\in V_1,\, (-v)\in V_2$ 이며 $v\ne 0$ 이면 @thm-directsum 에 위배된다. 따라서 $V_1 \cap V_2 = \{0_V\}$ 이다.

$V_1 \cap V_2= \{0_V\}$ 라고 하자. 어떤 $v_1\in V_1,\, v_2\in V_2$ 에 대해 $v_1+v_2=0$ 이라고 하자. $v_2=(-v_1)\in V_1$ 이므로 $v_1=v_2=0$ 일 수 밖에 없다. 따라서 $V_1+V_2 = V_1\oplus V_2$ 이다. $\square$

:::

</br>

## 벡터공간의 기저와 차원

### 선형결합과 Span {#sec-linear_combinatin_and_span}

::: {.callout-note appearance="simple" icon="false"}
::: {#def-linear_combination_and_span}

#### 선형결합과 Span

$V$ 가 $\mathbb{F}$-벡터공간 일 때, $a_1,\ldots,\,a_m \in \mathbb{F}$, $\{v_1,\ldots,\,v_m\}\subset V$ 에 대해

$$
v = a_1 v_1 + \cdots + a_m v_m
$$

이라면, $v$ 는 $\{v_1,\ldots,v_m\}$ 의 **선형결합** 이라고 하고, $\{v_1,\ldots,\,v_m\}$ 가 $v$ 를 **span** 한다라고 한다. 또한 $\{v_1,\ldots,\,v_m\}$ 으로 span 할 수 있는 모든 벡터의 집합을 $\text{span} (v_1,\ldots,\,v_m)$ 이라 표현한다. 즉,

$$
\text{span}(v_1,\ldots,\,v_m) = \{a_1v_1 + \cdots + a_m v_m \mid a_1,\ldots,a_m \in \mathbb{F}\}
$$

이다.

:::

:::

</br>

<div class="border" style="background-color:#FFF0F5 ;padding:5px;">
::: {#prp-span_minimal_subspace}

$\mathbb{F}$-벡터공간 $V$ 에 대해 $v_1,\ldots,\,v_m\in V$ 일 때 $\text{span}(v_1,\ldots,\,v_m)$ 은 $V$ 의 부분공간이며 또한 $v_1,\ldots,\,v_m$ 을 포함하는 가장 작은 $V$ 의 부분공간이다.

:::

</div></br>

::: {.proof}

우선 $V_1$ 이 $v_1,\ldots,\,v_m$ 을 포함하는 $V$ 의 부분공간임을 보이는 것은 쉽다. 어떤 $V$ 의 부분공간 $V_2$ 가 $v_1,\ldots,\,v_m$ 을 포함하는 $V$ 의 부분공간이며, $V_1$ 의 진부분집합이라면 $V_1$ 에는 포함되지만 $V_2$ 에는 포함되지 않는 $v_1,\ldots,v_m$ 의 선형결합이 있어야 하며 이는 $V_2$ 가 벡터공간이라는 것에 위배된다. 따라서 $\text{span}(v_1,\ldots,\,v_m)$ 은 $v_1,\ldots,\,v_m$ 을 포함하는 가장 작은 $V$ 의 부분공간이다. $\square$

:::

</br>


::: {.callout-note appearance="minimal" icon="false"}

::: {#def-generated_vector_space}

#### 집합으로 부터 생성된 부분공간

벡터공간 $V$ 의 부분집합 $U$ 를 생각하자. $U$ 는 부분벡터공간일 수도 있고 아닐 수도 있다. 우리는 $U$ 에 속하는 모든 벡터의 선형결합으로 이루어지는 집합을 생각 할 수 있다. 이 집합을 $U$ 에 의해 **생성된 부분공간** 이라고 한다. 이것을 이제 $\langle U \rangle$ 이라 쓰자. 아직 우리는 이것이 부분공간이라는 것을 보이지 않았지만 쉽게 보일 수 있다.

:::

:::

</br>
<div class="border" style="background-color:#F0FFFF  ;padding:5px;">
::: {#exr-generated_subspace}

$U$ 가 벡터공간 $V$ 의 부분집합일 때 $\langle U \rangle = \text{span}(U)$ 는 $V$ 의 부분공간임을 보여라. $U$ 가 $V$ 의 부분공간이라면 $U = \langle U \rangle$ 임을 보여라.

:::
</div>

</br>


### 유한차원 벡터공간과 무한차원 벡터공간, 선형독립과 선형종속

::: {.callout-note appearance="simple" icon="false"}
::: {#def-finite_dimensional_vector_space}

#### 유한차원 벡터공간
벡터 공간 $V$ 를 유한개의 벡터의 span 으로 표현 할 수 있을 때 $V$ 를 **유한차원 벡터공간** 이라 한다. 유한차원 벡터공간이 아닌 벡터공간을 **무한차원 벡터공간** 이라 한다.
:::
:::

</br>


<div class="border" style="background-color:#F2F4F4  ;padding:5px;">

::: {#exm-fdvs1}
$\mathbb{R}$-벡터공간 $\mathbb{R}^2$ 를 생각하자. 모든 $r\in \mathbb{R}^2$ 는 $(1,\,0)$ 과 $(0,\,1)$ 의 선형결합으로 표현 될 수 있다는 것을 보일 수 있다. 따라서 $\mathbb{R}^2$ 는 유한차원 벡터공간이다. $A=\{(x,\,x) : x\in \mathbb{R}\}$ 은 $\mathbb{R}^2$ 의 부분공간이며, $(1,\,1)$ 의 선형결합으로 표현할 수 있다. 따라서 $A$ 도 유한차원 벡터공간이다.
:::
</div>
</br>

::: {.callout-note appearance="simple" icon="false"}
::: {#def-independency}
#### 선형독립과 선형종속

벡터공간 $V$ 의 부분집합 $\{v_1,\ldots,\,v_m\}$ 에 대해 

$$
a_1 v_1 + \cdots + a_m v_m = 0_V \implies a_1 = \cdots = a_m = 0
$$

이면 $\{v_1,\ldots,\,v_m\}$ 를 **선형 독립**이라 한다. 선형 독립이 아닌 벡터의 집합을 **선형 종속** 이라 한다.
:::
:::


</br>

뒤에 나오겠지만 선형 독립인 벡터의 집합은 벡터공간을 이해하는데 매우 중요하다. 우리는 선형독립인 벡터들에 대해 다음을 보일 수 있다.

</br><div class="border" style="background-color:#F0FFFF  ;padding:5px;">

::: {#exr-zero_vector_dependent}
$0$ 벡터가 포함된 벡터의 집합은 선형종속이다.
:::
</div></br>

::: {.solution}
벡터공간 $V$ 의 임의의 벡터의 집합 $\{v_1,\ldots,\,v_m\}$ 에 대해

$$
c \cdot 0_V + 0 v_1 + \cdots + 0 v_m = 0
$$

은 모든 $c\in \mathbb{F}$ 에 대해 성립한다. $\square$
:::

</br>
<div class="border" style="background-color:#FFF0F5 ;padding:5px;">

::: {#prp-unique_span}
$\mathbb{F}$-벡터공간 $V$ 의 부분집합 $\{v_1,\ldots,\,v_n\}$ 이 선형독립이고 $v\in \text{span}(v_1,\ldots,v_n)$ 일 때, $v$ 를 $\{v_1,\ldots,\,v_n\}$ 의 선형결합으로 표현하는 방법은 유일하다.
:::
</div></br>

::: {.proof}
우선 @def-independency 에 따라 $0_V$ 을 $\{v_1,\ldots,\,v_n\}$ 의 선형결합으로 표현하는 방법이 유일하다. $v\in \text{span}(v_1,\ldots,\,v_n)$ 일 때,

$$
\begin{aligned}
v &= a_1 v_1 + \cdots + a_n v_n \\ &= b_1v_1 + \cdots + b_n v_n
\end{aligned}
$$

이라면 $(a_1-b_1)v_1 + \cdots (a_n-b_n)v_n = 0_V$ 이므로 $a_1=b_1,\cdots, a_n =b_n$ 이다. 즉, $v$ 를 $\{v_1,\ldots,\,v_n\}$ 의 선형결합으로 표현하는 방법은 유일하다. $\square$

:::


</br>

이제 벡터들의 집합이 선형 독립인지 종속인지가 그 $\text{span}$ 에 미치는 영향을 알아보자. 우선 $\{v_1,\ldots,\,v_m\}$ 이 선형 종속이라고 하자. 
$$
a_1v_1 + \cdots + a_m v_m = 0
$$

을 만족시키는 $a_1,\ldots,\,a_m$ 중 $0$ 이 아닌 것이 최소한 하나 이상 포함되어 있다. $a_j \ne 0$ 이라면, 

$$
v_j = -\dfrac{1}{a_j} (a_1 v_1 + \cdots + a_{j-1}v_{j-1} + a_{j+1}v_{j+1} + \cdots + a_m v_m)
$$

이므로,

$$
\text{span} (v_1, \ldots, v_m) = \text{span} (v_1,\ldots,v_{j-1},\,v_{j+1}, \ldots, v_{m})
$$

이다. 우리는 이것을 확장하여 다음을 증명한다.

</br>
<div class="border" style="background-color:#FFF0F5 ;padding:5px;">
::: {#prp-vector_dependency_and_span}
벡터공간 $V$ 와 $V_0 = \{v_1,\ldots,\,v_n\} \subset V$ 에 대해 다음은 동치이다.

&emsp; ($1$) $V_0$ 가 선형 종속이다

&emsp; ($2$) $\text{span}(V_0) = \text{span}(V_0-\{v_k\})$ 인 $v_k \in V_0$ 가 존재한다.
:::
</div></br>

::: {.proof}
 (1 $\implies$ 2) 앞에서 보였다.

(2 $\implies$ 1) $v_k \in \text{span}(V_0) =\text{span}(V_0-\{v_k\})$ 이므로 $v_k =  c_1 v_1 + \cdots + c_{k-1}v_{k-1}  + c_{k+1}v_{k+1} + \cdots + c_n v_n$ 이다. 따라서 $V_0$ 는 선형 종속이다. $\square$
:::

</br>

위의 명제로부터 다음을 알 수 있다.
</br>
<div class="border" style="background-color:#FFF0F5 ;padding:5px;">

::: {#cor-vector_independency_and_span}
벡터공간 $V$ 와 $V_0 = \{v_1,\ldots,\,v_n\} \subset V$ 에 대해 다음은 동치이다.

&emsp; (1) $V_0$ 가 선형 독립이다

&emsp; (2) 모든 $v_i\in V_0$ 에 대해 $\text{span}(V_0) \ne \text{span}(V_0-\{v_i\})$ 이다.
:::
</div>
</br>
<div class="border" style="background-color:#F2F4F4  ;padding:5px;">
::: {#exm-linear_dependency_of_polynomials}

$\mathbb{F}_n[t]$ 에서 $\{1,\,t,\ldots,\,t^n\}$ 이 선형독립임을 보이자. 

$$
a_0 + a_1 t+ \cdots + a_n t^n = 0
$$

이라는 것은 모든 $t\in \mathbb{F}$ 에 대해 $p(t) = a_0 + a_1 t + \cdots + a_nt^n=0$ 이라는 의미이다. 가장 쉽게 증명하는 것은 $p(t)$ 가 상수함수이며 무한번 미분 가능한 함수임을 이용하는 것.

:::

</div>

</br>

### 벡터공간의 기저 와 순서 기저 

::: {.callout-note appearance="simple" icon="false"}
::: {#def-basis}
#### 기저

선형 독립인 $\{v_1,\ldots,\,v_m\}$ 가 벡터공간 $V$ 를 span 할 때  $V$ 의 **기저 (basis)** 라 한다. 
:::
:::

</br>

기저의 정의와 @prp-unique_span 으로부터, 다음을 알 수 있다.

</br>
<div class="border" style="background-color:#FFF0F5 ;padding:5px;">

::: {#prp-unique}
$v\in V$ 를 $V$ 의 기저인 $\{v_1,\ldots,\,v_m\}$ 의 선형결합으로 표현하는 방법은 유일하다.
:::

</div></br>

보통 집합은 원소가 나열되는 순서가 중요하지 않지만 기저를 다룰 경우 기저를 이루는 벡터의 순서가 중요할 수 있다. 순서가 정해진 기저를 **순서 기저(ordered basis)** 라고 한다. 대부분의 경우 기저를 표현할 때, 기저의 순서가 꼭 필요하지 않더라도 순서기저로 이해해도 상관 없으며 앞으로 특별한 언급이 없을 경우 기저를 순서기저로 간주할 경우 $(v_1,\,v_2,\ldots)$ 와 같이 표현하도록 한다. 다만 순서가 중요하지 않을 경우나 혼동의 여지가 없을 경우에는 $\{v_1,\,v_2,\ldots\}$ 와 같이 쓸수도 있도록 하자.

</br>

### Span 하는 벡터로부터 기저를 추출하기

유한개의 벡터의 집합 $\{u_1,\ldots,u_m\}$ 이 벡터공간 $V$ 를 span 하면 $V$ 는 유한차원 벡터공간이다. 만약 이 $\{u_i\}$ 가 선형종속이면 적절한 벡터를 제거하여 $V$ 를 span 하게 할 수 있다(@prp-vector_dependency_and_span). 더 이상 제거할 수 없을 때 이 집합은 선형 독립(@cor-vector_independency_and_span)이며 $V$ 의 기저이다. 우리는 이로부터 다음을 알 수 있다.

</br><div class="border" style="background-color:#FFF0F5 ;padding:5px;">

::: {#thm-finitebasis}
유한차원 벡터공간은 유한개의 벡터로 이루어진 기저를 갖는다. 
:::

</div>
</br>
무한차원 벡터공간이 기저를 갖는다는 것을 선택공리를 통해서 증명할 수 있지만 여기서는 다루지 않는다.

</br>

### 유한차원 벡터공간의 차원

우리는 이제 기저(basis) 라는 개념을 통해 어떤 벡터공간은 유한개의 벡터의 선형결합으로 모두 표현할 수 있다는 것을 알게되었다. 기저는 벡터공간을 설명하는데 매우 중요하며 앞으로 벡터와 벡터공간의 성질, 특히 유한차원 벡터공간의 성질은 많은 경우 기저를 이용하여 보이게 된다. 또한 기저를 통해 차원(dimension) 이라는, 벡터공간의 아주 중요한 성질을 말할 수 있게 된다.

</br>
<div class="border" style="background-color:#FFF0F5 ;padding:5px;">
::: {#lem-basis_expansion}
유한차원 벡터공간 $V$ 의 부분집합 $\mathcal{B}_0=\{u_1,\ldots,\,u_m\}$ 이 선형독립일 때 $\mathcal{B}_0$ 를 포함하는 $V$ 의 기저가 존재한다.
:::

</div></br>

::: {.proof}

우선 선형 독립인 벡터의 집합 $W=\{ w_1,\ldots,\,w_n \}\subset V$ 와 어떤 $v \in V$ 의 합집합이 선형 종속이 되면 $\text{span}(W\cup \{v\}) = \text{span}(W)$ 가 됨을 보이자. $c_1 w_1 + \cdots + c_n w_n + cv = 0$ 라 하자. $c=0$ 이면 $W$ 가 선형 독립이므로 $c_1 = \cdots = c_n=0$ 이며 $W\cup \{v\}$ 가 선형 종속이라는 가정에 위배된다. 따라서 $c\ne 0$ 이며 $v\in \text{span}(W)$ 이다. 즉  $\text{span}(W\cup \{v\}) = \text{span}(W)$  이다. 즉 선형 독립인 벡터의 집합에 어떤 벡터 벡터를 추가하여 선형 종속이 되면 그 span 에 변화가 없다.

$V$ 가 유한차원 벡터공간이므로 $V$ 기저 $V_0 = \{v_1,\ldots,\,v_n\}$ 를 생각 할 수 있다. $\mathcal{B}_i$ 를 $\mathcal{B}_{i-1}$, $i=1,\ldots,\,n$ 에 대해 다음과 같이 정의하자.

$$
\mathcal{B}_{i} = \left\{\begin{array}{ll} 
\mathcal{B}_{i-1} \cup \{v_i\} \qquad & \text{if }\mathcal{B}_{i-1} \cup \{ v_i \} \text{ 가 선형 독립}, \\ 
\mathcal{B}_{i-1} \qquad & \text{if }\mathcal{B}_{i-1} \cup \{ v_i \} \text{ 가 선형 종속}.
\end{array}\right.
$$

이렇게 되면 
$$
\text{span}(\mathcal{B}_n) = \text{span}(\mathcal{B}_{n-1} \cup \{v_i\})  = \cdots = \text{span}(\mathcal{B}_0 \cup \{v_1,\ldots,\,v_i\}) = \text{span}(V_0) = V
$$ 

이므로, $\mathcal{B}_n$ 은 $V$ 의 기저이다. $\square$

:::

</br>

다음 보조정리는 선형독립인 벡터의 집합과 벡터공간을 span 하는 벡터의 집합의 크기에 어떤 관련이 있음을 말한다. 

</br><div class="border" style="background-color:#FFF0F5 ;padding:5px;">
::: {#lem-number_of_basis}
유한차원 벡터공간 $V$ 에 속하는 선형독립인 벡터 $\{v_1,\ldots,\,v_m\}$ 을 생각하자. 벡터의 집합 $\{u_1,\ldots,\,u_n\}$ 이 $V$ 를 span 할 때, $V$ 에 포함되는 선형독립인 벡터의 갯수는 벡터공간을 span 하는 벡터의 갯수보다 항상 작거나 같다.
:::

</div></br>

::: {.proof}
$\mathcal{B}_0=\{u_1,\ldots,\,u_n\}$ 라 하자. $\text{span}(\mathcal{B}_0)=V$ 이므로 $\mathcal{B}_0 \cup \{v_1\}$ 도 $V$ 를 span 한다. 또한 $v_1 \in \text{span}(\mathcal{B}_0)$ 이므로 $\mathcal{B}_0 \cup \{v_1\}$ 은 선형 종속이다. 이제 $\{u_i\}$ 가운데 하나를 $\mathcal{B}_0\cup \{v_1\}$ 에서 제거하여 $V$ 를 span 하도록 할 수 있다. 이것을 $\mathcal{B}_1$ 이라 하자. 이렇게 $V$ 를 span 하는 $\mathcal{B}_i$ 에 $v_i$ 를 넣고 $\mathcal{B}_i$ 에 남아있는 $u_i$ 가운데 span 에 영향을 주지 않는 것을 골라 하나씩 뺄 수 있다. 만약 $n<m$ 이라면 선형독립인 $\{v_1,\ldots,\,v_m\}$ 에서 몇개를 빼서 $V$ 를 span 할 수 있다는 뜻이므로 모순이다. 따라서 $m \le n$ 이다. 즉 $V$ 에서 정의된 선형독립 인 벡터집합의 벡터의 개수는 $V$ 를 span 할 수 있는 벡터의 숫자보다 항장 작거나 같다. $\square$
:::

</br>

이로부터 우리는 유한차원 벡터공간에 대해 아주 중요한 결론을 얻을 수 있다.

</br><div class="border" style="background-color:#FFF0F5 ;padding:5px;">

::: {#thm-basis_equality}
유한차원 벡터공간 $V$ 의 기저를 이루는 벡터의 개수는 항상 동일하다.
:::
</div></br>

::: {.proof}
$\mathcal{B}_1 = (v_1,\ldots,\,v_m)$ 과 $\mathcal{B}_2 = (v'_1,\ldots,\,v'_n)$ 가 유한차원 벡터공간 $V$ 의 기저라 하자. $\mathcal{B}_1$ 이 선형독립인 벡터의 집합이고 $\mathcal{B}_2$ 가 $V$ 를 span 하므로 $m\le n$ 이다. 또한 같은 논리도 $n \le m$ 이다. 즉 $m=n$ 이며, 따라서 두 기저에 포함된 벡터의 갯수는 같다. $\square$
:::

</br>

::: {.callout-note appearance="simple" icon="false"}
::: {#def-dimension}

### 벡터공간의 차원 

벡터공간 $V$ 의 기저에 포함된 벡터의 개수를 $V$ 의 **차원(dimension)** 이라고 하며 $\dim (V)$ 로 표현한다.

::: 
:::

</br><div class="border" style="background-color:#FFF0F5 ;padding:5px;">

::: {#cor-dim_subspace}

$W$ 가 $V$ 의 부분공간이면 $\dim (W) \le \dim (V)$ 이고 $\dim (W)= \dim (V)$ 이면 $V=W$ 이다.

:::

</div></br>

::: {.proof}

$W$ 가 $V$ 의 부분공간 일 때 $W$ 의 어떤 기저 $\mathcal{B}_W$ 를 잡았다면, 이 $\mathcal{B}_W$ 는 $V$ 에 포함되는 선형독립인 벡터이므로 여기에 선형독립이 되도록 벡터를 추가하여 $V$ 의 기저를 구성 할 수 있다. 따라서 $W$ 가 $V$ 의 부분공간이면

$$
\dim (W) \le \dim (V)
$$

이다. $\dim (W)=\dim (V)$ 이면 $W$ 의 기저가 $V$ 의 기저가 되므로 $W=V$ 이다. $\square$

:::

</br><div class="border" style="background-color:#F2F4F4  ;padding:5px;">

::: {#exm-dimension_of_matrix_space}

우리는 @exm-vectorspace_matrix 에서 $\mathbb{F}$ 의 의 원소를 성분으로 갖는 행렬의 집합 $\mathcal{M}_{m\times n}(\mathbb{F})$ 가 벡터공간이라는 것을 알았다. $1 \le i \le m$, $1 \le j \le n$ 에 대해 $\boldsymbol{E}^{(i,j)}$ 을 $i$ 행 $j$ 열 성분은 $1$ 이며 나머지 성분은 모두 $0$ 인 $m \times n$ 행렬이라 하자. 즉 $\mathbb{F}^{2 \times 3}$ 에서 $\boldsymbol{E}^{(2, 1)} = \begin{bmatrix} 0 & 0 & 0 \\ 1 & 0 & 0\end{bmatrix}$ 이다. $\mathbb{F}^{m \times n}$ 에서 $\mathcal{B}=\left\{\boldsymbol{E}^{(i, j)} : 1\le i \le m,\, 1 \le j \le n\right\}$ 는 선형독립이다. 또한 $\mathcal{B}$ 가 $\mathcal{M}_{m\times n}(\mathbb{F})$ 을 span 한다. $\mathcal{B}$ 의 원소의 갯수는 $mn$ 이므로 $\dim (\mathcal{M}_{m\times n}(\mathbb{F}))=mn$ 이다.

:::

</div></br>

### 합공간의 차원

</br><div class="border" style="background-color:#FFF0F5 ;padding:5px;">
::: {#prp-dim_sum}
$U_1,\,U_2$ 가 유한차원 부분공간 $V$ 의 부분공간일 때 다음이 성립한다.
$$
\dim (U_1 + U_2) = \dim (U_1) + \dim (U_2) - \dim (U_1 \cap U_2).
$$

:::

</div></br>

::: {.proof}
두 벡터공간 $U,\,V$ 의 교집합은 $U$ 와 $V$ 각각의 부분공간이다. (즉 벡터공간이다. @exm-intersection_of_two_spaces) $\dim (U_1 \cap U_2) = m$ 이라 할 때 $U_1 \cap U_2$ 의 기저 $\{w_1,\ldots,\,w_m\}$ 을 잡는다. 이를 확장하여 $U_1$ 의 기저 $\{w_1,\ldots,\,w_m,\,u_1,\ldots,\,u_k\}$  와 $U_2$ 의 기저 $\{ w_1,\ldots,\,w_m,\,u_1,\ldots,u_n \}$ 을 구성 할 수 있다.

$\dim (U_1) = m+k$, $\dim (U_2) = m+n$ 이며 $\dim (U_1+U_2)= m+n+k$ 이므로 위의 식이 성립한다. $\square$

:::

</br> 

이로부터 다음 명제가 자연스럽게 유도된다.
</br>
<div class="border" style="background-color:#FFF0F5 ;padding:5px;">

::: {#prp-dimension_of_direct_sum}

유한차원 벡터공간 $V$ 와 그 부분공간 $U_1,\,U_2$ 에 대해 $V=U_1\oplus U_2$ 이면 $\dim (V) = \dim(U_1) + \dim (U_2)$ 이다.

:::

</div>

</br>

## 벡터의 행렬표현

여기서는 벡터를 행렬로 표현하는 방법에 대해 다룬다.

### 벡터의 행렬표현 

::: {.callout-note appearance="simple" icon="false"}
::: {#def-matrix_representation_of_vector}

#### 벡터의 행렬표현과 좌표

$n$ 차원 $\mathbb{F}$-벡터공간 $V$ 의 어떤 [순서기저](#벡터공간의-기저-basis-와-순서-기저-ordered-basis) $\mathcal{B} = (v_i)$ 에 대해 $v=\sum_i a_i v_i$ 라고 하자. 이 때 $v\in V$ 를 $\mathcal{B}$ 기저에 대해 $n \times 1$ 행렬로 다음과 같이 표현하는 것을 벡터 $v$ 의 기저 $\mathcal{B}$ 에 대한 **행렬 표현** 이라 하고 $[v]_{\mathcal{B}}$ 라 표기한다.

$$
[v]_\mathcal{B} = \begin{bmatrix} a_1 \\ \vdots \\ a_n\end{bmatrix}
$$

이 때 $(a_1,\ldots,\,a_n)$ 을 $v$ 의 $\mathcal{B}$ 기저에서의 **좌표(coordinate)** 라 한다. 
:::
:::

</br>

$n$ 차원 벡터를 행렬로 표형할때는 일반적으로 위와 같은 $n \times 1$ 행렬를 사용한다. 또한 열벡터를 아래에서 위로 길게 보이는 것을 피하기 위해 $[v]_\mathcal{B} = \begin{bmatrix} a_1 & \cdots & a_n \end{bmatrix}^T$ 처럼 전치행렬을 사용하여 표현하기도 한다. 여기서 항상 조심해야 할 것은 벡터의 행렬표현은 특정한 순서기저에서의 행렬표현라는 것이다. 기저가 바뀌면 행렬표현도 바뀐다. 

</br>


### 열벡터와 표준 기저

::: {.callout-note appearance="simple" icon="false"}
::: {#def-standard_basis}

#### 표준기저와 표준기저벡터

유클리드공간 $\mathbb{F}^{n}$ 에서의 **표준기저벡터** $\hat{e}_i$ 는 $i$ 번째 성분은 1이고 나머지 성분은 0 인 벡터이다. 즉  $\hat{e}_i$ 의 $j$-번째 성분 $(\hat{e}_i)_j$ 는

$$
(\hat{e}_i)_{j} = \delta_{ij}
$$

가 된다. 즉 $\mathbb{R}^3$ 에서의 $\hat{e}_2=(0, 1, 0)$ 이다. $\mathbb{F}^n$ 에서의 표준 기저 벡터의 집합 $\{\hat{e}_1,\,\hat{e}_2,\ldots,\,\hat{e}_n\}$ 은 $\mathbb{F}^n$ 의 기저이다. 이 기저를 **표준기저 (standard basis)** 라고 한다.

열벡터의 벡터공간 $\mathcal{M}_n (\mathbb{F})$ 의 표준기저벡터 $\boldsymbol{e}_i$ 는 $i$ 번째 성분만 $1$ 이며 나머지 성분은 $0$ 인 $n \times 1$ 행렬이다. $\mathbb{F}^n$ 에서와 마찬가지로 $\{\boldsymbol{e}_1,\ldots,\boldsymbol{e}_n\}$ 이 $\mathcal{M}_{n}(\mathbb{F})$ 의 기저이며 이를 $\mathcal{M}_n(\mathbb{F})$ 의 표준기저라고 한다.

:::
:::

</br>
<div class="border" style="background-color:#F2F4F4  ;padding:5px;">
::: {#exm-standard_basis}
위에서 정의한 표준기저가 실제 벡터공간 $\mathbb{F}^{n}$ 의 기저임을 보여라.
:::

</div></br>

<div class="border" style="background-color:#F2F4F4  ;padding:5px;">
::: {#exm-stadard_basis_2}

벡터공간 $V$ 의 기저 $\mathcal{B}_V=(v_i)$ 에 대해 기저의 행렬표현은 표준기저이다. 즉 $[v_i]_{\mathcal{B}_V} = \boldsymbol{e}_i$ 이다.

:::

</div></br>

<div class="border" style="background-color:#F2F4F4  ;padding:5px;">
::: {#exm-matrix_representation_of_vectors}
$\mathbb{R}^2$ 에서 $\mathcal{B}_1 = ((1, 0),\, (0, 1))$ 이 표준기저이다. 이 이외에도 $\mathcal{B}_2 = ( (1, 1),\, (1, -1) )$ 도 기저가 될 수 있다. $v=(3,\,1)$ 은 $3(1, 0) + 1(0,1)$ 이므로 $[v]_{\mathcal{B}_1}=\begin{bmatrix} 3 \\ 1\end{bmatrix}$ 이다. 또한 $v=2(1,1)+(1, -1)$ 이므로 $[v]_{\mathcal{B}_2} =\begin{bmatrix} 2 \\ 1 \end{bmatrix}$ 이다.
:::

</div></br>
<div class="border" style="background-color:#F2F4F4  ;padding:5px;">
::: {#exm-sum_of_vector_in_matrix_representation}
$n$ 차원 벡터공간 $V$ 에 대해 $u,\,v\in V,\,c \in \mathbb{F}$ 라 하자. $V$ 의 한 순서기저 $\mathcal{B} = (v_1,\ldots,v_n)$ 에 대해 $v=\sum_i a_i v_i$, $u=\sum_i b_i v_i$ 일 때, 

$$
[u+c v]_{\mathcal{B}} = \left[\sum_{i} (a_i + c b_i) v_i \right]_{\mathcal{B}} = \begin{bmatrix} a_1 + c b_i \\ \vdots \\ a_n + c b_n\end{bmatrix}
$$

이다.
:::

</div></br>

::: {.callout-warning appearance="simple" icon="false"}
우리는 아직 행렬의 덧셈을 정의하지 않았고 단지 두 벡터의 합과 스칼라곱이 벡터의 행렬표현에서 어떻게 되는지를 알아본 것이다. 위의 @exm-sum_of_vector_in_matrix_representation 을 잘 보면 (최소한) $n\times 1$ 행렬의 덧셈과 스칼라곱을 어떻게 자연스럽게 정의 할 수 있을지 판단 할 수 있을 것이다. 다음 장에서 일반적인 행렬의 덧셈과 스칼라곱을 제대로 정의 할 것이다.

:::

</br>

## 연습문제 {.unnumbered}

<div class="border" style="background-color:#F0FFFF  ;padding:5px;">

::: {#exr-union_of_two_subspaces}

벡터공간 $V$ 의 두 부분공간 $U_1$, $U_2$ 에 대해 $(U_1 \cup U_2) \le V$ 일 필요충분조건은 $U_1 \le U_2$ 이거나 $U_2 \le U_1$ 인 것을 보여라.
:::
</div></br>

::: {.solution}

$U_1 \le U_2$ 일 때 $(U_1 \cup U_2) \le V$ 인 것은 자명하다. $u_1 \in U_1-U_2,\, u_2\in U_2-U_1$ 이라 하자. $u_1+u_2 \not\in U_1 \cup U_2$ 이므로 $U_1 \cup U_2$ 는 부분공간이 될 수 없다.

:::

</br>
<div class="border" style="background-color:#F0FFFF  ;padding:5px;">
::: {#exr-basis_or_direct_sum}

$U, V$ 가 벡터공간 $W$ 의 부분공간이며 $W=U \oplus V$ 라고 하자. $(u_1,\ldots,\,u_n)$ 이 $U$ 의 기저이고 $(v_1, \ldots,\,v_m)$ 이 $V$ 의 기저이면 $(u_1,\ldots,\,u_n,\,v_1,\ldots,\,v_m)$ 은 $W$ 의 기저임을 보여라.
:::

</div></br>

::: {.solution}

직합의 조건에 의해 $0=u+v,\,u\in U,\,v\in V$ 는 $u=v=0$ 뿐이다. 따라서 $(u_1,\ldots,\,u_n,\,v_1,\ldots,\,v_m)$ 은 선형독립이므로 $U\oplus V$ 의 기저이다.


:::

</br>

